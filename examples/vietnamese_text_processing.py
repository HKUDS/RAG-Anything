#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Vietnamese Text Processing Example for RAG-Anything
V√≠ d·ª• x·ª≠ l√Ω t√†i li·ªáu Text ti·∫øng Vi·ªát v·ªõi RAG-Anything

T·∫≠p trung v√†o x·ª≠ l√Ω c√°c ƒë·ªãnh d·∫°ng:
- TXT: File vƒÉn b·∫£n thu·∫ßn t√∫y
- MD: File Markdown
- DOCX: File Word
- PDF: File PDF ch·ª©a text

Kh√¥ng x·ª≠ l√Ω: Image, Audio, Video, Table ph·ª©c t·∫°p, Equation
"""

import asyncio
import os
from pathlib import Path
from dotenv import load_dotenv

from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc


async def main():
    """Main function ƒë·ªÉ x·ª≠ l√Ω t√†i li·ªáu ti·∫øng Vi·ªát"""

    # Load environment variables t·ª´ .env.vietnamese
    env_file = Path(__file__).parent.parent / ".env.vietnamese"
    if env_file.exists():
        load_dotenv(env_file)
        print(f"‚úÖ ƒê√£ load config t·ª´: {env_file}")
    else:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y {env_file}, s·ª≠ d·ª•ng config m·∫∑c ƒë·ªãnh")

    # L·∫•y API configuration
    api_key = os.getenv("OPENAI_API_KEY", "your-api-key")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

    if api_key == "your-api-key" or api_key == "your_openai_api_key_here":
        print("\n‚ùå L·ªói: Vui l√≤ng c·∫≠p nh·∫≠t OPENAI_API_KEY trong file .env.vietnamese")
        print("Ch·ªânh s·ª≠a file .env.vietnamese v√† thay th·∫ø 'your_openai_api_key_here' b·∫±ng API key c·ªßa b·∫°n\n")
        return

    # T·∫°o RAGAnything configuration - T·∫ÆT multimodal processing
    config = RAGAnythingConfig(
        working_dir=os.getenv("WORKING_DIR", "./rag_storage_vietnamese"),
        parser=os.getenv("PARSER", "mineru"),
        parse_method=os.getenv("PARSE_METHOD", "auto"),
        parser_output_dir=os.getenv("OUTPUT_DIR", "./output_vietnamese"),

        # T·∫ÆT t·∫•t c·∫£ t√≠nh nƒÉng multimodal - CH·ªà X·ª¨ L√ù TEXT
        enable_image_processing=False,
        enable_table_processing=False,
        enable_equation_processing=False,

        # Context extraction cho ti·∫øng Vi·ªát
        context_window=2,
        max_context_tokens=3000,

        display_content_stats=True,
    )

    print("\n" + "="*60)
    print("üáªüá≥ RAG-Anything - Vietnamese Text Processing")
    print("="*60)
    print(f"üìÅ Working directory: {config.working_dir}")
    print(f"üìÑ Parser: {config.parser}")
    print(f"üîß Parse method: {config.parse_method}")
    print(f"üñºÔ∏è  Image processing: {config.enable_image_processing}")
    print(f"üìä Table processing: {config.enable_table_processing}")
    print(f"üßÆ Equation processing: {config.enable_equation_processing}")
    print("="*60 + "\n")

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    print("‚öôÔ∏è  ƒêang kh·ªüi t·∫°o RAGAnything...")
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        embedding_func=embedding_func,
        # Kh√¥ng c·∫ßn vision_model_func v√¨ ƒë√£ t·∫Øt image processing
    )
    print("‚úÖ Kh·ªüi t·∫°o RAGAnything th√†nh c√¥ng!\n")

    # V√≠ d·ª• 1: X·ª≠ l√Ω m·ªôt file vƒÉn b·∫£n ti·∫øng Vi·ªát
    print("üìù V√≠ d·ª• 1: X·ª≠ l√Ω file vƒÉn b·∫£n ti·∫øng Vi·ªát")
    print("-" * 60)

    # T·∫°o m·ªôt file test n·∫øu ch∆∞a c√≥
    test_file = Path("./test_data/vietnamese_sample.txt")
    test_file.parent.mkdir(exist_ok=True)

    if not test_file.exists():
        with open(test_file, "w", encoding="utf-8") as f:
            f.write("""Tr√≠ tu·ªá nh√¢n t·∫°o v√† RAG (Retrieval-Augmented Generation)

RAG l√† m·ªôt ki·∫øn tr√∫c m·ªõi trong lƒ©nh v·ª±c x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, k·∫øt h·ª£p kh·∫£ nƒÉng t√¨m ki·∫øm th√¥ng tin v·ªõi kh·∫£ nƒÉng sinh vƒÉn b·∫£n c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn.

∆Øu ƒëi·ªÉm c·ªßa RAG:
1. C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa th√¥ng tin
2. Gi·∫£m thi·ªÉu hi·ªán t∆∞·ª£ng "hallucination" c·ªßa LLM
3. Cho ph√©p c·∫≠p nh·∫≠t ki·∫øn th·ª©c m√† kh√¥ng c·∫ßn train l·∫°i m√¥ h√¨nh
4. TƒÉng t√≠nh minh b·∫°ch v√† kh·∫£ nƒÉng truy xu·∫•t ngu·ªìn g·ªëc th√¥ng tin

C√°c th√†nh ph·∫ßn ch√≠nh:
- Document Parser: Ph√¢n t√≠ch v√† tr√≠ch xu·∫•t n·ªôi dung t·ª´ t√†i li·ªáu
- Embedding Model: Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector
- Vector Database: L∆∞u tr·ªØ v√† t√¨m ki·∫øm vector
- LLM: Sinh c√¢u tr·∫£ l·ªùi d·ª±a tr√™n context ƒë∆∞·ª£c truy xu·∫•t

·ª®ng d·ª•ng trong ti·∫øng Vi·ªát:
RAG ƒë·∫∑c bi·ªát h·ªØu √≠ch cho x·ª≠ l√Ω t√†i li·ªáu ti·∫øng Vi·ªát, gi√∫p tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n kho t√†i li·ªáu n·ªôi b·ªô, h·ªó tr·ª£ nghi√™n c·ª©u, v√† x√¢y d·ª±ng chatbot chuy√™n ng√†nh.
""")
        print(f"‚úÖ ƒê√£ t·∫°o file test: {test_file}")

    # X·ª≠ l√Ω file
    try:
        print(f"\nüìÑ ƒêang x·ª≠ l√Ω file: {test_file}")
        await rag.process_document_complete(
            file_path=str(test_file),
            output_dir=config.parser_output_dir,
            parse_method="txt",
            display_stats=True,
        )
        print("‚úÖ X·ª≠ l√Ω file th√†nh c√¥ng!\n")
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω file: {e}\n")
        return

    # V√≠ d·ª• 2: Truy v·∫•n th√¥ng tin b·∫±ng ti·∫øng Vi·ªát
    print("\nüîç V√≠ d·ª• 2: Truy v·∫•n th√¥ng tin b·∫±ng ti·∫øng Vi·ªát")
    print("-" * 60)

    queries = [
        "RAG l√† g√¨?",
        "∆Øu ƒëi·ªÉm c·ªßa RAG l√† g√¨?",
        "RAG c√≥ nh·ªØng th√†nh ph·∫ßn ch√≠nh n√†o?",
        "L√†m th·∫ø n√†o ƒë·ªÉ √°p d·ª•ng RAG cho ti·∫øng Vi·ªát?",
    ]

    for query in queries:
        print(f"\n‚ùì C√¢u h·ªèi: {query}")
        try:
            result = await rag.aquery(query, mode="hybrid")
            print(f"üí¨ Tr·∫£ l·ªùi: {result}\n")
            print("-" * 60)
        except Exception as e:
            print(f"‚ùå L·ªói khi truy v·∫•n: {e}\n")

    # V√≠ d·ª• 3: X·ª≠ l√Ω folder ch·ª©a nhi·ªÅu file
    print("\nüìÇ V√≠ d·ª• 3: X·ª≠ l√Ω folder ch·ª©a nhi·ªÅu file ti·∫øng Vi·ªát")
    print("-" * 60)
    print(f"ƒê·ªÉ x·ª≠ l√Ω folder, s·ª≠ d·ª•ng:")
    print(f"""
    await rag.process_folder_complete(
        folder_path="./your_vietnamese_documents",
        output_dir="{config.parser_output_dir}",
        file_extensions=[".txt", ".md", ".docx", ".pdf"],
        recursive=True,
        max_workers=2
    )
    """)

    print("\n" + "="*60)
    print("‚úÖ Ho√†n th√†nh demo x·ª≠ l√Ω t√†i li·ªáu ti·∫øng Vi·ªát!")
    print("="*60 + "\n")


if __name__ == "__main__":
    print("\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω t√†i li·ªáu Text ti·∫øng Vi·ªát v·ªõi RAG-Anything\n")
    asyncio.run(main())
