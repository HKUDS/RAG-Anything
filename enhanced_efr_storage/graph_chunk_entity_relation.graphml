<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d11" for="edge" attr.name="created_at" attr.type="long" />
  <key id="d10" for="edge" attr.name="file_path" attr.type="string" />
  <key id="d9" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d8" for="edge" attr.name="keywords" attr.type="string" />
  <key id="d7" for="edge" attr.name="description" attr.type="string" />
  <key id="d6" for="edge" attr.name="weight" attr.type="double" />
  <key id="d5" for="node" attr.name="created_at" attr.type="long" />
  <key id="d4" for="node" attr.name="file_path" attr.type="string" />
  <key id="d3" for="node" attr.name="source_id" attr.type="string" />
  <key id="d2" for="node" attr.name="description" attr.type="string" />
  <key id="d1" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d0" for="node" attr.name="entity_id" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="Patrick Lewis">
      <data key="d0">Patrick Lewis</data>
      <data key="d1">person</data>
      <data key="d2">Patrick Lewis is one of the researchers involved in the development and exploration of retrieval-augmented generation models for knowledge-intensive NLP tasks.&lt;SEP&gt;Patrick Lewis is involved in various studies on language models and their contextual understanding.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Ethan Perez">
      <data key="d0">Ethan Perez</data>
      <data key="d1">person</data>
      <data key="d2">Ethan Perez is a co-author of the paper discussing retrieval-augmented generation for knowledge-intensive NLP tasks.&lt;SEP&gt;Ethan Perez is a researcher mentioned in the context of finding generalizable evidence in Q&amp;A models.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Aleksandra Piktus">
      <data key="d0">Aleksandra Piktus</data>
      <data key="d1">person</data>
      <data key="d2">Aleksandra Piktus is a researcher contributing to the paper on retrieval-augmented generation models.&lt;SEP&gt;Aleksandra Piktus is a co-author associated with research into language models.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Fabio Petroni">
      <data key="d0">Fabio Petroni</data>
      <data key="d1">person</data>
      <data key="d2">Fabio Petroni is associated with the development of RAG models for language generation.&lt;SEP&gt;Fabio Petroni is a researcher involved in multiple linguistic studies, including knowledge bases and language models.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Vladimir Karpukhin">
      <data key="d0">Vladimir Karpukhin</data>
      <data key="d1">person</data>
      <data key="d2">Vladimir Karpukhin is a participant in the research on retrieval-augmented generation for NLP tasks.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Naman Goyal">
      <data key="d0">Naman Goyal</data>
      <data key="d1">person</data>
      <data key="d2">Naman Goyal collaborates on the research project about retrieval-augmented generation.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Heinrich Küttler">
      <data key="d0">Heinrich Küttler</data>
      <data key="d1">person</data>
      <data key="d2">Heinrich Küttler is one of the contributors to the research discussing RAG models in knowledge-intensive NLP tasks.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Mike Lewis">
      <data key="d0">Mike Lewis</data>
      <data key="d1">person</data>
      <data key="d2">Mike Lewis is involved in the research and development of retrieval-augmented generation techniques.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866189</data>
    </node>
    <node id="Wen-tau Vih">
      <data key="d0">Wen-tau Vih</data>
      <data key="d1">person</data>
      <data key="d2">Wen-tau Vih is a researcher contributing to the field of retrieval-augmented generation for NLP.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866190</data>
    </node>
    <node id="Tim Rocktäschel">
      <data key="d0">Tim Rocktäschel</data>
      <data key="d1">person</data>
      <data key="d2">Tim Rocktäschel is a researcher associated with the exploration of hybrid models in NLP.&lt;SEP&gt;Tim Rocktäschel is a co-author on research focusing on language models as knowledge bases.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866190</data>
    </node>
    <node id="Sebastian Riedel">
      <data key="d0">Sebastian Riedel</data>
      <data key="d1">person</data>
      <data key="d2">Sebastian Riedel is one of the researchers contributing to the paper on retrieval-augmented generation.&lt;SEP&gt;Sebastian Riedel is mentioned in research papers involving knowledge bases and language understanding.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866190</data>
    </node>
    <node id="Douwe Kiela">
      <data key="d0">Douwe Kiela</data>
      <data key="d1">person</data>
      <data key="d2">Douwe Kiela participates in the research related to retrieval-augmented generation models.&lt;SEP&gt;Douwe Kiela is recognized as part of the research team involved in Q&amp;A model development.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866191</data>
    </node>
    <node id="Facebook AI Research">
      <data key="d0">Facebook AI Research</data>
      <data key="d1">organization</data>
      <data key="d2">Facebook AI Research is involved in the development of new methods and models for NLP tasks, including retrieval-augmented generation.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866191</data>
    </node>
    <node id="University College London">
      <data key="d0">University College London</data>
      <data key="d1">organization</data>
      <data key="d2">University College London is associated with researchers contributing to the advancements in retrieval-augmented generation.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866191</data>
    </node>
    <node id="New York University">
      <data key="d0">New York University</data>
      <data key="d1">organization</data>
      <data key="d2">New York University is the institution where some of the contributors to the retrieval-augmented generation research are based.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866191</data>
    </node>
    <node id="Retrieval-Augmented Generation (RAG)">
      <data key="d0">Retrieval-Augmented Generation (RAG)</data>
      <data key="d1">category</data>
      <data key="d2">Retrieval-Augmented Generation (RAG) refers to a method that combines pre-trained parametric and non-parametric memory for enhanced language generation tasks.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866191</data>
    </node>
    <node id="Wikipedia">
      <data key="d0">Wikipedia</data>
      <data key="d1">organization</data>
      <data key="d2">Wikipedia is used as a non-parametric memory source accessed by the retrieval-augmented generation models for factual knowledge.&lt;SEP&gt;Wikipedia is a large online encyclopedia used as a non-parametric knowledge source for various applications, including open-domain question answering.&lt;SEP&gt;Wikipedia is a widely used online encyclopedia that provides factual information and is often referenced in knowledge-intensive tasks.&lt;SEP&gt;Wikipedia is a free online encyclopedia that serves as a vast external knowledge source for various queries and information, often utilized in AI models for text generation tasks.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-ed49c26a398a6bba5d1b396a04a8fc38&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Natural Questions">
      <data key="d0">Natural Questions</data>
      <data key="d1">category</data>
      <data key="d2">Natural Questions is a prominent dataset and benchmarking task in the field of open-domain question answering (QA), where it serves multiple key purposes in the evaluation and development of retrieval-augmented generation (RAG) models. Specifically designed to assess the effectiveness of retrieval-based question-answering systems, this dataset provides a fertile ground for training and evaluating AI models that function in natural language contexts.

As one of the four widely recognized open-domain QA datasets, Natural Questions consists of a substantial corpus featuring 79,169 training instances. This extensive dataset is invaluable for researchers and developers aiming to enhance the capabilities and performance of various models, such as T5 and RAG-Sequence. The dataset's structure allows for rigorous testing and benchmarking, making it an essential tool for measuring the accuracy of retrieval-augmented models and their overall effectiveness in responding to natural language inquiries.

Natural Questions not only supports the core functionality of QA systems but also offers insights into the advancements in retrieval-based methods that generate state-of-the-art results. The dataset serves as a benchmark in numerous research papers, demonstrating its significance in pushing the boundaries of what is possible in question answering. By utilizing Natural Questions, researchers can systematically explore and validate model performance, contributing to the overarching goal of developing more robust and effective AI systems capable of understanding and responding to human queries in a meaningful and accurate manner. 

In summary, Natural Questions is a critical resource in the open-domain QA landscape, characterized by its large training instance set and its role as a benchmark for evaluating the performance of cutting-edge retrieval systems. Its contributions to research and development within this domain underline its importance for advancing the state of question-answering technology.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-9b9de140312f67e7f2d6598149a691f8&lt;SEP&gt;chunk-d70c6f37764e4792ca46bea09a315724&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295&lt;SEP&gt;chunk-6b046b3a3d5c9333bae80b4874d68e8a&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866490</data>
    </node>
    <node id="WebQuestions">
      <data key="d0">WebQuestions</data>
      <data key="d1">category</data>
      <data key="d2">WebQuestions is another open domain QA task that RAG models have been evaluated on with state-of-the-art performance.&lt;SEP&gt;WebQuestions is a dataset employed in the assessment of open-domain question answering techniques, including RAG.&lt;SEP&gt;WebQuestions is a dataset utilized in QA tasks with 3418 training instances.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="CuratedTrec">
      <data key="d0">CuratedTrec</data>
      <data key="d1">category</data>
      <data key="d2">CuratedTrec is also an open domain QA task where the retrieval-augmented generation models have set state-of-the-art results.&lt;SEP&gt;CuratedTrec is a dataset for open-domain question answering that is used along with others to evaluate RAG's effectiveness.&lt;SEP&gt;CuratedTrec involves processing answer annotations in the form of regular expressions for use in answer-generation models.&lt;SEP&gt;CuratedTrec is a QA dataset with 635 training instances, the lowest among the listed datasets.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="Dense Passage Retriever">
      <data key="d0">Dense Passage Retriever</data>
      <data key="d1">organization</data>
      <data key="d2">Dense Passage Retriever (DPR) is a pre-trained neural retriever that provides latent documents based on input sequences for retrieval-augmented generation models.</data>
      <data key="d3">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866192</data>
    </node>
    <node id="BART">
      <data key="d0">BART</data>
      <data key="d1">organization</data>
      <data key="d2">BART, which stands for Bidirectional and Auto-Regressive Transformers, is a pre-trained sequence-to-sequence (seq2seq) transformer model that excels in various language generation tasks. It utilizes a denoising objective during its training process, which enhances its ability to generate coherent and contextually relevant text. This model is particularly significant when used in conjunction with retrieval-augmented generation (RAG), leveraging the strengths of both BART and BERT for improved text processing and information synthesis.

BART is recognized for generating factually accurate responses, making it a valuable tool for tasks such as question generation. It serves as a baseline model in this domain, achieving a BLEU-1 score of 15.1; however, this performance is considered lower than that of the RAG-Token variant, indicating that while BART is effective, it can be outperformed in metrics related to response quality and accuracy.

Despite its strengths, BART has been noted for generating outputs with lower diversity, especially evident in specific applications, such as the Jeopardy Question Generation (QGen) task. This limitation highlights the need for diversity-promoting decoding strategies when using BART, which can help alleviate the tendency toward repetitive or less varied responses.

In the context of RAG, BART is used as a comparative benchmark for generating answers. However, outputs generated by BART can often be uncertain or only partially accurate, depending on the complexity and context of the queries it handles. In scenarios where the retrieval component of the RAG model fails or is less effective, BART's performance remains comparable, underscoring its robustness as a foundational model for text generation.

Overall, BART represents an important contribution to the field of natural language processing due to its innovative design and capabilities in facilitating the integration of knowledge sources into coherent text generation. Its effectiveness in various tasks—including text generation and question formulation—coupled with its incorporation into more complex systems like RAG, establishes BART as a significant entity in advanced AI-driven language understanding and production.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921&lt;SEP&gt;chunk-d70c6f37764e4792ca46bea09a315724&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295&lt;SEP&gt;chunk-9602588f9a41c6c9eaeca67413aaf7ae&lt;SEP&gt;chunk-ed49c26a398a6bba5d1b396a04a8fc38&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-5a0294c30c4299ee3e2c0f5a634e94c0&lt;SEP&gt;chunk-1dd05d174cc46f951f0f9378efa364a9&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866473</data>
    </node>
    <node id="T5">
      <data key="d0">T5</data>
      <data key="d1">organization</data>
      <data key="d2">T5 is a pre-trained transformer model referenced as a comparison in the exploration of retrieval-augmented generation approaches.&lt;SEP&gt;T5 is a model noted for its performance across various NLP tasks, specifically in a pre-trained encoder-decoder architecture.&lt;SEP&gt;T5 is a standard closed-book model in the context of open-domain question answering, serving as a benchmark for comparative analysis against newer models like RAG.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="MS-MARCO">
      <data key="d0">MS-MARCO</data>
      <data key="d1">category</data>
      <data key="d2">MS-MARCO is a dataset used for generating questions in knowledge-intensive generation experiments discussed in the paper.&lt;SEP&gt;MS-MARCO is a benchmark task used to evaluate the performance of models in generating relevant responses based on queries.&lt;SEP&gt;MS-MARCO is one of the task types referenced in the table, involving definitions and information retrieval related to questions posed.&lt;SEP&gt;MS-MARCO is a dataset comprised of 153726 training instances, the highest among the datasets mentioned.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-5a0294c30c4299ee3e2c0f5a634e94c0&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="Jeopardy">
      <data key="d0">Jeopardy</data>
      <data key="d1">event</data>
      <data key="d2">Jeopardy question generation refers to the process of using RAG models to create answers for two types of questions, showcasing the model's capabilities.&lt;SEP&gt;Jeopardy is a quiz show format that often requires the generation of specific questions and answers based on provided information.&lt;SEP&gt;Jeopardy refers to a question generation task where various models are evaluated based on their performance in generating questions.</data>
      <data key="d3">chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="DPR">
      <data key="d0">DPR</data>
      <data key="d1">organization</data>
      <data key="d2">DPR is a retrieval component that follows a bi-encoder architecture for document retrieval, often utilized in question-answering tasks.&lt;SEP&gt;DPR (Dense Passage Retrieval) is a model for retrieving passages relevant to specific queries, commonly used in open-domain QA tasks.&lt;SEP&gt;DPR is another model focusing on retrieval-augmented approaches within open-domain QA, providing comparative insights against RAG models.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="RAG-Sequence Model">
      <data key="d0">RAG-Sequence Model</data>
      <data key="d1">category</data>
      <data key="d2">The RAG-Sequence model utilizes a single retrieved document to generate a complete target sequence.&lt;SEP&gt;The RAG-Sequence Model is a probabilistic framework used in Natural Language Processing for generating output sequences based on input queries and retrieved context.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="RAG-Token Model">
      <data key="d0">RAG-Token Model</data>
      <data key="d1">category</data>
      <data key="d2">The RAG-Token model generates each target token using potentially different retrieved documents, allowing for varied context.</data>
      <data key="d3">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866193</data>
    </node>
    <node id="TriviaQA">
      <data key="d0">TriviaQA</data>
      <data key="d1">category</data>
      <data key="d2">TriviaQA is a dataset for training and evaluating question-answering systems, designed to provide varied and challenging questions.&lt;SEP&gt;TriviaQA is another dataset used for testing the capabilities of the RAG model in open-domain question answering.&lt;SEP&gt;TriviaQA is a dataset utilized in the field of QA, allowing for the training of models on trivia questions.&lt;SEP&gt;TriviaQA is a large-scale dataset designed for distant supervision challenges in reading comprehension, as discussed in a paper presented at the 55th Annual Meeting of the Association for Computational Linguistics.&lt;SEP&gt;TriviaQA is an open-domain QA dataset that provides a framework for evaluating question-answering models with public development datasets.&lt;SEP&gt;TriviaQA is a dataset for open-domain QA that includes 78786 training instances and has more test instances than training.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-9b9de140312f67e7f2d6598149a691f8&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-ef47fd07a7377b94f11ee0a4348cf1b1&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="BERTBASE">
      <data key="d0">BERTBASE</data>
      <data key="d1">category</data>
      <data key="d2">BERTBASE is a model used for encoding queries and documents in the retrieval process, facilitating effective information retrieval.</data>
      <data key="d3">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866193</data>
    </node>
    <node id="Non-Parametric Memory">
      <data key="d0">Non-Parametric Memory</data>
      <data key="d1">category</data>
      <data key="d2">Non-Parametric Memory refers to the document index used in the retrieval process, retaining information that can be accessed dynamically.</data>
      <data key="d3">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866193</data>
    </node>
    <node id="Latent Variable">
      <data key="d0">Latent Variable</data>
      <data key="d1">category</data>
      <data key="d2">Latent Variable denotes a concept used in the models to treat the retrieved document as an unobserved variable during generation.</data>
      <data key="d3">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866193</data>
    </node>
    <node id="Top-K Documents">
      <data key="d0">Top-K Documents</data>
      <data key="d1">category</data>
      <data key="d2">Top-K Documents signify a selection process where the K highest-ranked documents are retrieved for generating output sequences.</data>
      <data key="d3">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866194</data>
    </node>
    <node id="Stochastic Gradient Descent">
      <data key="d0">Stochastic Gradient Descent</data>
      <data key="d1">category</data>
      <data key="d2">Stochastic Gradient Descent is an optimization technique used for training machine learning models by minimizing error in parameter estimation.&lt;SEP&gt;Stochastic Gradient Descent is an optimization algorithm used for training machine learning models, referenced in the context of model training.</data>
      <data key="d3">chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866194</data>
    </node>
    <node id="RAG">
      <data key="d0">RAG</data>
      <data key="d1">organization</data>
      <data key="d2">RAG is a model designed for open-domain question answering and knowledge-driven tasks, integrating retrieval with generation capabilities.&lt;SEP&gt;RAG is an advanced model that employs retrieval-augmented generation techniques to enhance question answering and document summarization.&lt;SEP&gt;RAG is identified as a model that effectively learns to retrieve relevant information for various NLP tasks.&lt;SEP&gt;RAG (Retrieval-Augmented Generation) models are designed for training with mixed precision and utilize document indexing for various QA tasks.&lt;SEP&gt;RAG is a generative model that outperformed BART in terms of factuality and specificity in the Jeopardy Question Generation Task.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-9602588f9a41c6c9eaeca67413aaf7ae&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="SEQUOIA">
      <data key="d0">SEQUOIA</data>
      <data key="d1">category</data>
      <data key="d2">SEQUOIA is a paradigm in question answering that RAG is compared with, focusing on the ability to generate text from knowledge.</data>
      <data key="d3">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866194</data>
    </node>
    <node id="FAISS">
      <data key="d0">FAISS</data>
      <data key="d1">organization</data>
      <data key="d2">FAISS is a library for efficient similarity search and clustering of dense vectors, utilized in constructing a MIPS index for retrieval.&lt;SEP&gt;FAISS is a library designed for efficient similarity search and clustering of dense vectors, utilized for Maximum Inner Product Search.</data>
      <data key="d3">chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866194</data>
    </node>
    <node id="BERT">
      <data key="d0">BERT</data>
      <data key="d1">organization</data>
      <data key="d2">BERT is a transformer-based model used for natural language processing tasks, mentioned in the context of training for various knowledge-intensive tasks.&lt;SEP&gt;BERT is a model for pre-training deep bidirectional transformers for language understanding.&lt;SEP&gt;BERT is a model used for obtaining dense vector representations of documents and input queries in natural language processing tasks.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="Adam">
      <data key="d0">Adam</data>
      <data key="d1">category</data>
      <data key="d2">Adam is an optimization algorithm used for training models, mentioned within the context of model updates during training.</data>
      <data key="d3">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866194</data>
    </node>
    <node id="RAG-Sequence">
      <data key="d0">RAG-Sequence</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Sequence refers to a specific implementation of the RAG model that utilizes a distinct approach for decoding sequences during question answering.&lt;SEP&gt;RAG-Sequence is a variant of the RAG model that specifically performs well on natural language generation tasks.&lt;SEP&gt;RAG-Sequence is a hybrid model that achieves a score of 44.5 on Natural Questions, indicating strong open-domain QA performance without requiring extensive trainable parameters.&lt;SEP&gt;RAG-Sequence is another retrieval-augmented generation model known for achieving a score of 44.5 in the NQ metric, indicative of its strong performance in generative capabilities with retrieval.&lt;SEP&gt;RAG-Sequence is a retrieval-based model that shows consistent performance improvement over traditional models across diverse tasks.&lt;SEP&gt;RAG-Sequence is another retrieval-augmented model that showed significant effectiveness in generating diverse outputs for both tasks.&lt;SEP&gt;RAG-Sequence is noted for demonstrating superior performance in several metrics compared to RAG-Token and is particularly impactful in NLP tasks.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-1dd05d174cc46f951f0f9378efa364a9&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="RAG-Token">
      <data key="d0">RAG-Token</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Token refers to another implementation of the RAG model with autoregressive capabilities for generating text outputs.&lt;SEP&gt;RAG-Token is another variant of the RAG model, noted for its performance in generating questions.&lt;SEP&gt;RAG-Token is a model whose generations are less diverse than AG-Sequence's, indicating differences in their decoding mechanisms.&lt;SEP&gt;RAG-Token is a retrieval-augmented generation model that achieved high scores in open-domain QA tasks, particularly excelling in the NQ score of 44.1.&lt;SEP&gt;RAG-Token is a model that achieves a BLEU-1 score of 17.3 on Jeopardy question generation, outperforming the baseline model BART.&lt;SEP&gt;RAG-Token is a retrieval-augmented model that demonstrated notable improvements in generating diverse outputs compared to BART.&lt;SEP&gt;RAG-Token is a retrieval-augmented generation model variant that is assessed in the context of its performance across various tasks.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921&lt;SEP&gt;chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-1dd05d174cc46f951f0f9378efa364a9&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="MIPS">
      <data key="d0">MIPS</data>
      <data key="d1">category</data>
      <data key="d2">MIPS (Maximum Inner Product Search) is a method for efficient similarity search in high-dimensional spaces, utilized in building indices for retrieval.</data>
      <data key="d3">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866195</data>
    </node>
    <node id="Document Encoder">
      <data key="d0">Document Encoder</data>
      <data key="d1">category</data>
      <data key="d2">The Document Encoder is a component of the RAG framework that computes embeddings for documents, as part of the retrieval process.</data>
      <data key="d3">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866195</data>
    </node>
    <node id="RAG Models">
      <data key="d0">RAG Models</data>
      <data key="d1">organization</data>
      <data key="d2">RAG Models represent a system used for question answering, known for combining generation flexibility and performance in open-domain tasks.&lt;SEP&gt;RAG Models refer to hybrid generation models that utilize both parametric and non-parametric memory to achieve state-of-the-art results in open-domain question answering.&lt;SEP&gt;RAG Models, including RAG-Token and RAG-Sequence, are retrieval-augmented generation models that provide answers to various tasks, demonstrating greater accuracy than other models.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493&lt;SEP&gt;chunk-9b9de140312f67e7f2d6598149a691f8&lt;SEP&gt;chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="MSMARCO NLG task v2.1">
      <data key="d0">MSMARCO NLG task v2.1</data>
      <data key="d1">event</data>
      <data key="d2">The MSMARCO NLG task v2.1 is an evaluative event in natural language generation that involves answering knowledge-intensive questions.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866195</data>
    </node>
    <node id="SearchQA">
      <data key="d0">SearchQA</data>
      <data key="d1">organization</data>
      <data key="d2">SearchQA is an organization that provides a dataset for evaluating the generation of questions in open-domain settings.&lt;SEP&gt;SearchQA is a dataset designed for question answering augmented with context from search engines.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad&lt;SEP&gt;chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866195</data>
    </node>
    <node id="FEVER">
      <data key="d0">FEVER</data>
      <data key="d1">category</data>
      <data key="d2">FEVER is a task focused on fact verification, determining the veracity of claims supported by Wikipedia.&lt;SEP&gt;FEVER is an evaluation framework that assesses fact verification models through classification tasks using provided claims and evidence.&lt;SEP&gt;FEVER is a task focused on entity-centric claims that benefit significantly from word overlap-based retrieval.&lt;SEP&gt;FEVER (Fact Extraction and Verification) is a classification task designed to determine the support status of given claims.&lt;SEP&gt;FEVER is a set of tasks focused on fact verification, assessed through models' performance.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921&lt;SEP&gt;chunk-9b9de140312f67e7f2d6598149a691f8&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="TQA Wiki test set">
      <data key="d0">TQA Wiki test set</data>
      <data key="d1">event</data>
      <data key="d2">The TQA Wiki test set is a dataset used for evaluating performance on question answering tasks related to TQA.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866196</data>
    </node>
    <node id="BART Model">
      <data key="d0">BART Model</data>
      <data key="d1">organization</data>
      <data key="d2">The BART model is a language model employed for comparison in the context of question generation tasks.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866196</data>
    </node>
    <node id="SQuAD-tuned Q-BLEU-1 Metric">
      <data key="d0">SQuAD-tuned Q-BLEU-1 Metric</data>
      <data key="d1">category</data>
      <data key="d2">The SQuAD-tuned Q-BLEU-1 metric is a variant of BLEU used to measure the quality of generated questions by emphasizing entity matching.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866196</data>
    </node>
    <node id="TQA">
      <data key="d0">TQA</data>
      <data key="d1">category</data>
      <data key="d2">TQA (Textual Question Answering) is a task evaluated through various datasets, including the TQA Wiki test set, to measure performance in answering questions based on textual inputs.&lt;SEP&gt;TQA is a test set utilized to assess models in open-domain question answering, highlighting their effectiveness and robustness in understanding varied queries.&lt;SEP&gt;TQA (Trivia Question Answering) is a performance evaluation task for models aimed at assessing their ability to answer trivia questions accurately.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8&lt;SEP&gt;chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866473</data>
    </node>
    <node id="Jeopardy Question Generation">
      <data key="d0">Jeopardy Question Generation</data>
      <data key="d1">category</data>
      <data key="d2">Jeopardy Question Generation is a specific task aimed at creating questions in a unique format based on factual statements about entities.&lt;SEP&gt;Jeopardy Question Generation is a dataset with 97392 training instances and focuses on generating questions.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="Open-Domain QA Tasks">
      <data key="d0">Open-Domain QA Tasks</data>
      <data key="d1">event</data>
      <data key="d2">Open-Domain QA Tasks refer to a category of tasks that involve answering questions from a wide range of topics without specific limitations on the content.&lt;SEP&gt;Open-Domain QA Tasks refer to the evaluation scenarios in which various models, including T5, RAG, REALM, and DPR, are assessed on their ability to answer questions using a broad range of knowledge.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="Parametric Knowledge">
      <data key="d0">Parametric Knowledge</data>
      <data key="d1">category</data>
      <data key="d2">Parametric Knowledge describes a type of knowledge utilized by models like RAG to generate responses even when correct answers are not directly found in retrieved documents.</data>
      <data key="d3">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866197</data>
    </node>
    <node id="American Literature">
      <data key="d0">American Literature</data>
      <data key="d1">category</data>
      <data key="d2">American Literature refers to the body of written or literary works produced in the United States, which includes classic novels.</data>
      <data key="d3">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866197</data>
    </node>
    <node id="Lost Generation">
      <data key="d0">Lost Generation</data>
      <data key="d1">category</data>
      <data key="d2">The Lost Generation is a term referring to a group of American expatriate writers in the 1920s, known for their disillusionment and creativity.</data>
      <data key="d3">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866197</data>
    </node>
    <node id="A Farewell to Arms">
      <data key="d0">A Farewell to Arms</data>
      <data key="d1">category</data>
      <data key="d2">A Farewell to Arms is a novel published in 1929, known for its portrayal of war and love, based on wartime experiences of its author.&lt;SEP&gt;A Farewell to Arms is another novel analyzed for its role in language generation and relevance to queries.&lt;SEP&gt;A Farewell to Arms is another notable novel by Hemingway, exploring love and war.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97&lt;SEP&gt;chunk-0e88be2ccc273f5476f809546920b89f&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="The Sun Also Rises">
      <data key="d0">The Sun Also Rises</data>
      <data key="d1">category</data>
      <data key="d2">The Sun Also Rises is a novel published in 1926, notable for its depiction of the post-World War I expatriate experience.&lt;SEP&gt;The Sun Also Rises is a novel, part of the analysis, indicating its significance in language generation and retrieval tasks.&lt;SEP&gt;The Sun Also Rises is a novel authored by Hemingway, examining themes of post-war disillusionment.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97&lt;SEP&gt;chunk-0e88be2ccc273f5476f809546920b89f&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="NQ">
      <data key="d0">NQ</data>
      <data key="d1">category</data>
      <data key="d2">NQ refers to the Natural Questions dataset, which is used for evaluating the accuracy of question-answering models.&lt;SEP&gt;NQ refers to a specific metric used to evaluate the performance of models in open-domain question answering tasks, specifically quantifying their accuracy in extracting correct answers.&lt;SEP&gt;NQ (Natural Questions) is a task for which performance metrics were evaluated, serving as a measure of model efficacy in understanding questions.</data>
      <data key="d3">chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866473</data>
    </node>
    <node id="Open MS-MARCO NLG">
      <data key="d0">Open MS-MARCO NLG</data>
      <data key="d1">event</data>
      <data key="d2">Open MS-MARCO NLG is a natural language generation task focused on generating answers from open-domain questions, evaluated using BLEU and ROUGE scores.</data>
      <data key="d3">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866197</data>
    </node>
    <node id="AG-Sequence">
      <data key="d0">AG-Sequence</data>
      <data key="d1">organization</data>
      <data key="d2">AG-Sequence is an organization known for its diverse generations compared to other models, particularly RAG-Token and BART.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="DrQA">
      <data key="d0">DrQA</data>
      <data key="d1">organization</data>
      <data key="d2">DrQA is referenced in relation to building indexes from Wikipedia dumps for retrieval tasks.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="Open-Domain QA">
      <data key="d0">Open-Domain QA</data>
      <data key="d1">category</data>
      <data key="d2">Open-Domain QA is a category of tasks where retrieval mechanisms are crucial for performance improvements.&lt;SEP&gt;Open-Domain QA refers to the capability of answering questions on any topic using information extracted from a wide range of sources.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493&lt;SEP&gt;chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="GLUE benchmarks">
      <data key="d0">GLUE benchmarks</data>
      <data key="d1">category</data>
      <data key="d2">GLUE benchmarks are a set of standard tasks for evaluating the performance of language models.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="GPT-2">
      <data key="d0">GPT-2</data>
      <data key="d1">organization</data>
      <data key="d2">GPT-2 is a pre-trained language model recognized for achieving strong performance on generative and discriminative tasks.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="Latent Variable Approach">
      <data key="d0">Latent Variable Approach</data>
      <data key="d1">category</data>
      <data key="d2">Latent Variable Approach is an optimization method mentioned in the context of enhancing retrieval processes in NLP tasks.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="Parameter-Only Models">
      <data key="d0">Parameter-Only Models</data>
      <data key="d1">category</data>
      <data key="d2">Parameter-Only Models refer to models that require further training to be updated in behavior as the world changes, unlike RAG.</data>
      <data key="d3">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866198</data>
    </node>
    <node id="Kyunghyun Cho">
      <data key="d0">Kyunghyun Cho</data>
      <data key="d1">person</data>
      <data key="d2">Kyunghyun Cho is mentioned as a contributor who provided productive discussions and advice related to the work.&lt;SEP&gt;Kyunghyun Cho is an author noted for their contributions to neural machine translation.&lt;SEP&gt;Kyunghyun Cho is one of the authors of the paper discussing search engine guided neural machine translation at the AAAI Conference.&lt;SEP&gt;Kyunghyun Cho is a notable researcher associated with passage re-ranking methodologies in natural language processing.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493&lt;SEP&gt;chunk-23a7f06b95f84637f32c50a9f98890ad&lt;SEP&gt;chunk-ef47fd07a7377b94f11ee0a4348cf1b1&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="Sewon Min">
      <data key="d0">Sewon Min</data>
      <data key="d1">person</data>
      <data key="d2">Sewon Min is noted for their contributions in discussions and advice in the context of the research on RAG models.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="NSF Graduate Research Fellowship">
      <data key="d0">NSF Graduate Research Fellowship</data>
      <data key="d1">category</data>
      <data key="d2">The NSF Graduate Research Fellowship is a program that supports graduate students in research-related fields, mentioned as a source of support for EP.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="FAIR PhD Program">
      <data key="d0">FAIR PhD Program</data>
      <data key="d1">category</data>
      <data key="d2">The FAIR PhD Program is a research fellowship mentioned as a source of support for PL.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="Machine Translation">
      <data key="d0">Machine Translation</data>
      <data key="d1">category</data>
      <data key="d2">Machine Translation refers to the automated translation of text between languages and is mentioned as a successful domain for similar approaches.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="Semantic Parsing">
      <data key="d0">Semantic Parsing</data>
      <data key="d1">category</data>
      <data key="d2">Semantic Parsing involves converting natural language into a structured format and is mentioned in the context of successful approaches.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="Retrieve-and-Edit Approaches">
      <data key="d0">Retrieve-and-Edit Approaches</data>
      <data key="d1">category</data>
      <data key="d2">Retrieve-and-Edit approaches involve retrieving similar training input-output pairs for a given input and editing them to produce a final output, showcasing similarities to RAG methods.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="Knowledge-Intensive Dialog">
      <data key="d0">Knowledge-Intensive Dialog</data>
      <data key="d1">category</data>
      <data key="d2">Knowledge-Intensive Dialog refers to dialog systems where generators are conditioned on retrieved text, indicating a requirement for deep information retrieval.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866199</data>
    </node>
    <node id="TF-IDF">
      <data key="d0">TF-IDF</data>
      <data key="d1">category</data>
      <data key="d2">TF-IDF stands for Term Frequency-Inverse Document Frequency, a retrieval method mentioned as an alternative to the end-to-end learnt retrieval used in RAG models.</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Danqi Chen">
      <data key="d0">Danqi Chen</data>
      <data key="d1">person</data>
      <data key="d2">Danqi Chen is an author noted for their contributions in the field of computational linguistics.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Adam Fisch">
      <data key="d0">Adam Fisch</data>
      <data key="d1">person</data>
      <data key="d2">Adam Fisch is an author who co-wrote significant research in computational linguistics.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Jason Weston">
      <data key="d0">Jason Weston</data>
      <data key="d1">person</data>
      <data key="d2">Jason Weston is a well-known researcher in artificial intelligence and machine learning.&lt;SEP&gt;Jason Weston is a contributor to the research focused on Q&amp;A systems and generalizable evidence.&lt;SEP&gt;Jason Weston is recognized for his contributions to language model research.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-23a7f06b95f84637f32c50a9f98890ad&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Antoine Bordes">
      <data key="d0">Antoine Bordes</data>
      <data key="d1">person</data>
      <data key="d2">Antoine Bordes is an author recognized for their work in AI and machine learning.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics">
      <data key="d0">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</data>
      <data key="d1">event</data>
      <data key="d2">This event is a conference where research papers in computational linguistics are presented.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Vancouver, Canada">
      <data key="d0">Vancouver, Canada</data>
      <data key="d1">geo</data>
      <data key="d2">Vancouver is the location where the 55th Annual Meeting of the Association for Computational Linguistics took place in July 2017.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866200</data>
    </node>
    <node id="Association for Computational Linguistics">
      <data key="d0">Association for Computational Linguistics</data>
      <data key="d1">organization</data>
      <data key="d2">The Association for Computational Linguistics is an organization dedicated to advancing the study of computational linguistics.&lt;SEP&gt;The Association for Computational Linguistics is a professional organization that supports research in computational linguistics and organizes conferences.&lt;SEP&gt;The Association for Computational Linguistics is a professional organization that publishes works and holds conferences related to computational linguistics.&lt;SEP&gt;The Association for Computational Linguistics is the organization that facilitated the conferences and publications mentioned.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad&lt;SEP&gt;chunk-ef47fd07a7377b94f11ee0a4348cf1b1&lt;SEP&gt;chunk-6b046b3a3d5c9333bae80b4874d68e8a&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Eunsol Choi">
      <data key="d0">Eunsol Choi</data>
      <data key="d1">person</data>
      <data key="d2">Eunsol Choi is an author contributing to significant research in question answering systems.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Daniel Hewlett">
      <data key="d0">Daniel Hewlett</data>
      <data key="d1">person</data>
      <data key="d2">Daniel Hewlett is a co-author known for their work in language processing.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Jakob Uszkoreit">
      <data key="d0">Jakob Uszkoreit</data>
      <data key="d1">person</data>
      <data key="d2">Jakob Uszkoreit is an author contributing to research in natural language processing.&lt;SEP&gt;Jakob Uszkoreit is mentioned as a contributor to the research paper 'Natural Questions: a Benchmark for Question Answering Research.'&lt;SEP&gt;Jakob Uszkoreit is recognized for contributions to transformer models in language processing.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-23a7f06b95f84637f32c50a9f98890ad&lt;SEP&gt;chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Illia Polosukhin">
      <data key="d0">Illia Polosukhin</data>
      <data key="d1">person</data>
      <data key="d2">Illia Polosukhin is an author recognized for their contributions in machine learning.&lt;SEP&gt;Illia Polosukhin is a researcher who co-authored the paper 'Natural Questions: a Benchmark for Question Answering Research.'&lt;SEP&gt;Illia Polosukhin is known for work advancing neural architecture in language processing.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-23a7f06b95f84637f32c50a9f98890ad&lt;SEP&gt;chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Alexandre Lacoste">
      <data key="d0">Alexandre Lacoste</data>
      <data key="d1">person</data>
      <data key="d2">Alexandre Lacoste is an author involved in AI research.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Jonathan Berant">
      <data key="d0">Jonathan Berant</data>
      <data key="d1">person</data>
      <data key="d2">Jonathan Berant is known for their research contributions in natural language understanding.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866201</data>
    </node>
    <node id="Christopher Clark">
      <data key="d0">Christopher Clark</data>
      <data key="d1">person</data>
      <data key="d2">Christopher Clark is an author noted for work in reading comprehension in AI.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Matt Gardner">
      <data key="d0">Matt Gardner</data>
      <data key="d1">person</data>
      <data key="d2">Matt Gardner is an author who contributes to machine comprehension research.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Noah Carter">
      <data key="d0">Noah Carter</data>
      <data key="d1">person</data>
      <data key="d2">Noah Carter is an author contributing in AI and language processing fields.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Wizard of Wikipedia">
      <data key="d0">Wizard of Wikipedia</data>
      <data key="d1">category</data>
      <data key="d2">Wizard of Wikipedia refers to a knowledge-powered conversational agent framework.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Hierarchical Neural Story Generation">
      <data key="d0">Hierarchical Neural Story Generation</data>
      <data key="d1">category</data>
      <data key="d2">Hierarchical neural story generation pertains to methods for generating structured narratives using neural networks.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Matthew Dunn">
      <data key="d0">Matthew Dunn</data>
      <data key="d1">person</data>
      <data key="d2">Matthew Dunn is an author who contributed to the field of artificial intelligence research.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Levent Sagun">
      <data key="d0">Levent Sagun</data>
      <data key="d1">person</data>
      <data key="d2">Levent Sagun is an author recognized for their contributions in machine learning and AI.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="Mike Higgins">
      <data key="d0">Mike Higgins</data>
      <data key="d1">person</data>
      <data key="d2">Mike Higgins is an author involved in research related to AI and computational methods.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866202</data>
    </node>
    <node id="V. Ugur Guney">
      <data key="d0">V. Ugur Guney</data>
      <data key="d1">person</data>
      <data key="d2">V. Ugur Guney is an author contributing to AI-related research.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="Volkan Cirik">
      <data key="d0">Volkan Cirik</data>
      <data key="d1">person</data>
      <data key="d2">Volkan Cirik is an author known for their work in AI and language processing.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="When will AI exceed human performance? evidence from AI experts">
      <data key="d0">When will AI exceed human performance? evidence from AI experts</data>
      <data key="d1">category</data>
      <data key="d2">This category refers to research discussing predictions about AI surpassing human capabilities, involving expert opinions.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="Search Engine Guided Neural Machine Translation">
      <data key="d0">Search Engine Guided Neural Machine Translation</data>
      <data key="d1">category</data>
      <data key="d2">This category encompasses work related to enhancing neural machine translation using information from search engines.</data>
      <data key="d3">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="Jiatao Gu">
      <data key="d0">Jiatao Gu</data>
      <data key="d1">person</data>
      <data key="d2">Jiatao Gu is an author associated with the research presented at the AAAI Conference on Artificial Intelligence, 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="Yong Wang">
      <data key="d0">Yong Wang</data>
      <data key="d1">person</data>
      <data key="d2">Yong Wang is an author who collaborated on the paper related to search engine guided neural machine translation, presented at AAAI 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="Victor O.K. Li">
      <data key="d0">Victor O.K. Li</data>
      <data key="d1">person</data>
      <data key="d2">Victor O.K. Li is an author of the paper on search engine guided neural machine translation, presented at AAAI 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866203</data>
    </node>
    <node id="AAAI Conference on Artificial Intelligence">
      <data key="d0">AAAI Conference on Artificial Intelligence</data>
      <data key="d1">event</data>
      <data key="d2">The AAAI Conference on Artificial Intelligence is an annual event where research findings in artificial intelligence are presented.&lt;SEP&gt;The AAAI Conference is a prominent venue for discussions and advancements in artificial intelligence research.&lt;SEP&gt;The AAAI Conference is a notable event for discussions on artificial intelligence advancements.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c&lt;SEP&gt;chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="Transactions of the Association for Computational Linguistics">
      <data key="d0">Transactions of the Association for Computational Linguistics</data>
      <data key="d1">category</data>
      <data key="d2">Transactions of the Association for Computational Linguistics is a publication venue for sharing research in computational linguistics.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="Advances in Neural Information Processing Systems">
      <data key="d0">Advances in Neural Information Processing Systems</data>
      <data key="d1">category</data>
      <data key="d2">Advances in Neural Information Processing Systems is a conference that presents significant research advances in neural computation and machine learning.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="Kelvin Guu">
      <data key="d0">Kelvin Guu</data>
      <data key="d1">person</data>
      <data key="d2">Kelvin Guu is an author associated with the research on generating sentences by editing prototypes, published in the Transactions of the Association for Computational Linguistics, 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="Tatsunori B. Hashimoto">
      <data key="d0">Tatsunori B. Hashimoto</data>
      <data key="d1">person</data>
      <data key="d2">Tatsunori B. Hashimoto is a co-author of the paper on generating sentences by editing prototypes in the Transactions of the Association for Computational Linguistics, 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="Yonatan Oren">
      <data key="d0">Yonatan Oren</data>
      <data key="d1">person</data>
      <data key="d2">Yonatan Oren is an author who collaborated on the research for generating sentences by editing prototypes in the Transactions of the Association for Computational Linguistics, 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="Percy Liang">
      <data key="d0">Percy Liang</data>
      <data key="d1">person</data>
      <data key="d2">Percy Liang is a co-author of the paper on generating sentences by editing prototypes, published in Transactions of the Association for Computational Linguistics, 2018.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866204</data>
    </node>
    <node id="REALM">
      <data key="d0">REALM</data>
      <data key="d1">organization</data>
      <data key="d2">REALM refers to the retrieval-augmented language model pre-training method discussed in a paper by Kelvin Guu and others, aimed at enhancing language model performance.&lt;SEP&gt;REALM is a synthetic model that utilizes external document retrieval, showing competitive performance in QA tasks but is outperformed by RAG models.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="Dense Passage Retrieval for Open-Domain Question Answering">
      <data key="d0">Dense Passage Retrieval for Open-Domain Question Answering</data>
      <data key="d1">category</data>
      <data key="d2">Dense passage retrieval is a method for open-domain question answering discussed in a paper presented in arXiv, focusing on the retrieval mechanisms to improve question answering tasks.</data>
      <data key="d3">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866205</data>
    </node>
    <node id="Tom Kwiatkowski">
      <data key="d0">Tom Kwiatkowski</data>
      <data key="d1">person</data>
      <data key="d2">Tom Kwiatkowski is an author involved in research relevant to question answering and has contributed to the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866205</data>
    </node>
    <node id="Jennimaria Palomaki">
      <data key="d0">Jennimaria Palomaki</data>
      <data key="d1">person</data>
      <data key="d2">Jennimaria Palomaki is one of the researchers who contributed to the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866205</data>
    </node>
    <node id="Olivia Redfield">
      <data key="d0">Olivia Redfield</data>
      <data key="d1">person</data>
      <data key="d2">Olivia Redfield is a researcher featured in the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866205</data>
    </node>
    <node id="Michael Collins">
      <data key="d0">Michael Collins</data>
      <data key="d1">person</data>
      <data key="d2">Michael Collins is a contributor to the research paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866205</data>
    </node>
    <node id="Ankur Parikh">
      <data key="d0">Ankur Parikh</data>
      <data key="d1">person</data>
      <data key="d2">Ankur Parikh participated in the research presented in the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866205</data>
    </node>
    <node id="Chris Alberti">
      <data key="d0">Chris Alberti</data>
      <data key="d1">person</data>
      <data key="d2">Chris Alberti is involved in the research paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866206</data>
    </node>
    <node id="Danielle Epstein">
      <data key="d0">Danielle Epstein</data>
      <data key="d1">person</data>
      <data key="d2">Danielle Epstein is one of the authors of the research paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866206</data>
    </node>
    <node id="Matthew Kelcey">
      <data key="d0">Matthew Kelcey</data>
      <data key="d1">person</data>
      <data key="d2">Matthew Kelcey is mentioned as a contributor to the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866206</data>
    </node>
    <node id="Jacob Devlin">
      <data key="d0">Jacob Devlin</data>
      <data key="d1">person</data>
      <data key="d2">Jacob Devlin is one of the researchers contributing to the work in the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866206</data>
    </node>
    <node id="Kenton Lee">
      <data key="d0">Kenton Lee</data>
      <data key="d1">person</data>
      <data key="d2">Kenton Lee actively contributed to multiple research papers, including works presented at the Association for Computational Linguistics.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866206</data>
    </node>
    <node id="Kristina N. Toutanova">
      <data key="d0">Kristina N. Toutanova</data>
      <data key="d1">person</data>
      <data key="d2">Kristina N. Toutanova is a research contributor involved in the work associated with question answering.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866206</data>
    </node>
    <node id="Llion Jones">
      <data key="d0">Llion Jones</data>
      <data key="d1">person</data>
      <data key="d2">Llion Jones is noted as a researcher in the context of the paper 'Natural Questions: a Benchmark for Question Answering Research.'&lt;SEP&gt;Llion Jones is involved in transformative research within natural language processing.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="Ming-Wei Chang">
      <data key="d0">Ming-Wei Chang</data>
      <data key="d1">person</data>
      <data key="d2">Ming-Wei Chang is an author contributing to the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="Andrew Dai">
      <data key="d0">Andrew Dai</data>
      <data key="d1">person</data>
      <data key="d2">Andrew Dai is involved in research relevant to question answering, mentioned in the context of the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="Quoc Le">
      <data key="d0">Quoc Le</data>
      <data key="d1">person</data>
      <data key="d2">Quoc Le is a researcher involved in the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="Slav Petrov">
      <data key="d0">Slav Petrov</data>
      <data key="d1">person</data>
      <data key="d2">Slav Petrov is one of the authors contributing to the paper 'Natural Questions: a Benchmark for Question Answering Research.'</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="ArXiv">
      <data key="d0">ArXiv</data>
      <data key="d1">organization</data>
      <data key="d2">ArXiv is an open-access repository where various papers, including those referenced, are published.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="Transactions of the Association of Computational Linguistics">
      <data key="d0">Transactions of the Association of Computational Linguistics</data>
      <data key="d1">event</data>
      <data key="d2">This event pertains to the publication of significant research in computational linguistics, including the mentioned papers.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866207</data>
    </node>
    <node id="Guillaume Lample">
      <data key="d0">Guillaume Lample</data>
      <data key="d1">person</data>
      <data key="d2">Guillaume Lample is a researcher who contributed to a paper on large memory layers with product keys, indicating his involvement in advancements in machine learning.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866208</data>
    </node>
    <node id="Alexandre Sablayrolles">
      <data key="d0">Alexandre Sablayrolles</data>
      <data key="d1">person</data>
      <data key="d2">Alexandre Sablayrolles is a co-author of the paper discussing large memory layers with product keys, highlighting his work in the field of neural networks.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866208</data>
    </node>
    <node id="Marc Aurelio Ranzato">
      <data key="d0">Marc Aurelio Ranzato</data>
      <data key="d1">person</data>
      <data key="d2">Marc’ Aurelio Ranzato is mentioned as a researcher associated with the paper about large memory layers, contributing to the research on neural information processing.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866208</data>
    </node>
    <node id="Ludovic Denoyer">
      <data key="d0">Ludovic Denoyer</data>
      <data key="d1">person</data>
      <data key="d2">Ludovic Denoyer contributed to the research presented in the paper regarding large memory layers with product keys.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866208</data>
    </node>
    <node id="Herve Jegou">
      <data key="d0">Herve Jegou</data>
      <data key="d1">person</data>
      <data key="d2">Herve Jegou is a researcher involved in the publication discussing advances in memory layers within neural networks.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866208</data>
    </node>
    <node id="Advances in Neural Information Processing Systems 32">
      <data key="d0">Advances in Neural Information Processing Systems 32</data>
      <data key="d1">event</data>
      <data key="d2">Advances in Neural Information Processing Systems 32 is a publication that includes significant papers on topics like large memory layers in machine learning.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866208</data>
    </node>
    <node id="Florence, Italy">
      <data key="d0">Florence, Italy</data>
      <data key="d1">geo</data>
      <data key="d2">Florence, Italy is the location where the 57th Annual Meeting of the Association for Computational Linguistics was held, indicating its role as a venue for significant discussions in computational linguistics.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="A diversity-promoting objective function for neural conversation models">
      <data key="d0">A diversity-promoting objective function for neural conversation models</data>
      <data key="d1">category</data>
      <data key="d2">This category refers to a specific research paper that focuses on enhancing diversity in neural conversation models, contributing to the field of natural language processing.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="Robust neural machine translation with joint textual and phonetic embedding">
      <data key="d0">Robust neural machine translation with joint textual and phonetic embedding</data>
      <data key="d1">category</data>
      <data key="d2">This category refers to a research paper addressing advancements in neural machine translation methodologies.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="IEC">
      <data key="d0">IEC</data>
      <data key="d1">event</data>
      <data key="d2">IEC, highlighted in the context of ICLR, refers to a conference where deep learning and robustness in AI are discussed, emphasizing its importance in the tech community.</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="Gregory Diamos">
      <data key="d0">Gregory Diamos</data>
      <data key="d1">person</data>
      <data key="d2">Gregory Diamos is a researcher credited with work in mixed precision training, as referenced in a publication from ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="Erich Elsen">
      <data key="d0">Erich Elsen</data>
      <data key="d1">person</data>
      <data key="d2">Erich Elsen is a researcher associated with the mixed precision training paper presented at ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="David Garcia">
      <data key="d0">David Garcia</data>
      <data key="d1">person</data>
      <data key="d2">David Garcia is a contributor to the mixed precision training research noted in ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="Boris Ginsburg">
      <data key="d0">Boris Ginsburg</data>
      <data key="d1">person</data>
      <data key="d2">Boris Ginsburg is mentioned as a researcher involved in the mixed precision training publication from ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866209</data>
    </node>
    <node id="Michael Houston">
      <data key="d0">Michael Houston</data>
      <data key="d1">person</data>
      <data key="d2">Michael Houston is a co-author of the study on mixed precision training presented at ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Oleksii Kuchaiev">
      <data key="d0">Oleksii Kuchaiev</data>
      <data key="d1">person</data>
      <data key="d2">Oleksii Kuchaiev is one of the authors listed in the mixed precision training research for ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Ganesh Venkatesh">
      <data key="d0">Ganesh Venkatesh</data>
      <data key="d1">person</data>
      <data key="d2">Ganesh Venkatesh is a researcher who contributed to the mixed precision training paper noted in ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Hao Wu">
      <data key="d0">Hao Wu</data>
      <data key="d1">person</data>
      <data key="d2">Hao Wu is a co-author mentioned in the context of the mixed precision training study from ICLR, 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Nikita Moghe">
      <data key="d0">Nikita Moghe</data>
      <data key="d1">person</data>
      <data key="d2">Nikita Moghe is one of the researchers cited in a publication focusing on conversation systems presented at the 2018 Empirical Methods in Natural Language Processing conference.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Siddhartha Arora">
      <data key="d0">Siddhartha Arora</data>
      <data key="d1">person</data>
      <data key="d2">Siddhartha Arora is a co-author of a paper on conversation systems shared at the 2018 Conference on Empirical Methods in Natural Language Processing.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Suman Banerjee">
      <data key="d0">Suman Banerjee</data>
      <data key="d1">person</data>
      <data key="d2">Suman Banerjee is a researcher involved in the development of background knowledge for conversation systems, as reported in a 2018 conference publication.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Mitesh M. Khapra">
      <data key="d0">Mitesh M. Khapra</data>
      <data key="d1">person</data>
      <data key="d2">Mitesh M. Khapra is cited in multiple research publications including work on conversation systems and question generation metrics.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866210</data>
    </node>
    <node id="Tri Nguyen">
      <data key="d0">Tri Nguyen</data>
      <data key="d1">person</data>
      <data key="d2">Tri Nguyen is mentioned as a researcher who contributed to the passage re-ranking with BERT paper.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866211</data>
    </node>
    <node id="Mir Rosenberg">
      <data key="d0">Mir Rosenberg</data>
      <data key="d1">person</data>
      <data key="d2">Mir Rosenberg is a co-author of the paper on passage re-ranking with BERT technology.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866211</data>
    </node>
    <node id="Xia Song">
      <data key="d0">Xia Song</data>
      <data key="d1">person</data>
      <data key="d2">Xia Song is cited as one of the contributors to the research involving passage re-ranking with BERT.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866211</data>
    </node>
    <node id="Jianfeng Gao">
      <data key="d0">Jianfeng Gao</data>
      <data key="d1">person</data>
      <data key="d2">Jianfeng Gao is a researcher mentioned in the context of the MS MARCO machine reading comprehension dataset.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866211</data>
    </node>
    <node id="Saurabh Tiwary">
      <data key="d0">Saurabh Tiwary</data>
      <data key="d1">person</data>
      <data key="d2">Saurabh Tiwary is acknowledged as a contributor to the research on the MS MARCO dataset.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866211</data>
    </node>
    <node id="Rangan Majumder">
      <data key="d0">Rangan Majumder</data>
      <data key="d1">person</data>
      <data key="d2">Rangan Majumder is a co-author involved in the development of the machine reading comprehension dataset, MS MARCO.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866211</data>
    </node>
    <node id="Li Deng">
      <data key="d0">Li Deng</data>
      <data key="d1">person</data>
      <data key="d2">Li Deng is recognized as a contributor to the MS MARCO project focused on machine reading comprehension.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Rodrigo Nogueira">
      <data key="d0">Rodrigo Nogueira</data>
      <data key="d1">person</data>
      <data key="d2">Rodrigo Nogueira is mentioned in connection to the paper on passage re-ranking with BERT.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Siddharth Karamcheti">
      <data key="d0">Siddharth Karamcheti</data>
      <data key="d1">person</data>
      <data key="d2">Siddharth Karamcheti is a co-author of a study concerning Q&amp;A models and evidence extraction.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Rob Fergus">
      <data key="d0">Rob Fergus</data>
      <data key="d1">person</data>
      <data key="d2">Rob Fergus is a researcher linked to the study about learning to convince Q&amp;A models.&lt;SEP&gt;Rob Fergus is a noted researcher in the field of artificial intelligence and language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Yuxiang Wu">
      <data key="d0">Yuxiang Wu</data>
      <data key="d1">person</data>
      <data key="d2">Yuxiang Wu is recognized for contributions in the realm of language models and their applications.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Alexander Miller">
      <data key="d0">Alexander Miller</data>
      <data key="d1">person</data>
      <data key="d2">Alexander Miller is a researcher involved in exploring language models as knowledge bases and their factual predictions.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Noam Shazeer">
      <data key="d0">Noam Shazeer</data>
      <data key="d1">person</data>
      <data key="d2">Noam Shazeer is a participant in the exploration of language models and their capabilities.&lt;SEP&gt;Noam Shazeer is an author involved in research on language models and transfer learning.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Adam Roberts">
      <data key="d0">Adam Roberts</data>
      <data key="d1">person</data>
      <data key="d2">Adam Roberts is mentioned in connection with studies on the limitations of language model implementations.&lt;SEP&gt;Adam Roberts is known for his work on language models and their knowledge encapsulation.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866212</data>
    </node>
    <node id="Katherine Lee">
      <data key="d0">Katherine Lee</data>
      <data key="d1">person</data>
      <data key="d2">Katherine Lee is involved in research geared towards understanding the limits of language models.&lt;SEP&gt;Katherine Lee is an author who collaborates on research concerning language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866213</data>
    </node>
    <node id="Sharan Narang">
      <data key="d0">Sharan Narang</data>
      <data key="d1">person</data>
      <data key="d2">Sharan Narang is a contributor to research collating findings about language models.&lt;SEP&gt;Sharan Narang is one of the authors contributing to studies on language model performance.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866213</data>
    </node>
    <node id="Michael Matena">
      <data key="d0">Michael Matena</data>
      <data key="d1">person</data>
      <data key="d2">Michael Matena is acknowledged for research into the capabilities of language models.&lt;SEP&gt;Michael Matena has contributed to research on language models and their applications.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866213</data>
    </node>
    <node id="Yanqi Zhou">
      <data key="d0">Yanqi Zhou</data>
      <data key="d1">person</data>
      <data key="d2">Yanqi Zhou is recognized for contributions to studies on language model technologies.&lt;SEP&gt;Yanqi Zhou is involved in research regarding language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866213</data>
    </node>
    <node id="Wei Li">
      <data key="d0">Wei Li</data>
      <data key="d1">person</data>
      <data key="d2">Wei Li is a researcher involved in understanding and testing language model functionalities.&lt;SEP&gt;Wei Li is a researcher who has co-authored works in the domain of language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866213</data>
    </node>
    <node id="Peter J. Liu">
      <data key="d0">Peter J. Liu</data>
      <data key="d1">person</data>
      <data key="d2">Peter J. Liu is mentioned in connection with exploring language models and their limits.&lt;SEP&gt;Peter J. Liu is an author associated with advancements in language modeling.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="ICLR">
      <data key="d0">ICLR</data>
      <data key="d1">event</data>
      <data key="d2">ICLR, or the International Conference on Learning Representations, is a conference that published work on mixed precision training in 2018.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="2018 Conference of the North American Chapter of the Association for Computational Linguistics">
      <data key="d0">2018 Conference of the North American Chapter of the Association for Computational Linguistics</data>
      <data key="d1">event</data>
      <data key="d2">This conference is noted for showcasing research and tooling in the field of natural language processing.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="Proceedings of the Workshop on Cognitive Computation">
      <data key="d0">Proceedings of the Workshop on Cognitive Computation</data>
      <data key="d1">event</data>
      <data key="d2">Workshop focused on integrating neural and symbolic approaches, highlighted in the context of NIPS 2016.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="2019 Conference of the North American Chapter of the Association for Computational Linguistics">
      <data key="d0">2019 Conference of the North American Chapter of the Association for Computational Linguistics</data>
      <data key="d1">event</data>
      <data key="d2">This 2019 conference presented various demonstrations and methodologies in computational linguistics.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="Hong Kong">
      <data key="d0">Hong Kong</data>
      <data key="d1">geo</data>
      <data key="d2">Hong Kong is the location mentioned where the EMNLP and IJCNLP conferences took place in November 2019.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="Brussels, Belgium">
      <data key="d0">Brussels, Belgium</data>
      <data key="d1">geo</data>
      <data key="d2">Brussels, Belgium is the location where the 2018 Conference on Empirical Methods in Natural Language Processing was conducted.&lt;SEP&gt;Brussels is a geographical location where the 2018 EMNLP Workshop occurred.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c&lt;SEP&gt;chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866214</data>
    </node>
    <node id="fairseq">
      <data key="d0">fairseq</data>
      <data key="d1">category</data>
      <data key="d2">fairseq is a fast, extensible toolkit for sequence modeling mentioned in the context of NAT and research demonstrations.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866215</data>
    </node>
    <node id="MS MARCO">
      <data key="d0">MS MARCO</data>
      <data key="d1">category</data>
      <data key="d2">MS MARCO is a dataset designed for human generated machine reading comprehension.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866215</data>
    </node>
    <node id="url">
      <data key="d0">url</data>
      <data key="d1">category</data>
      <data key="d2">URLs are provided for various research papers, directing readers to relevant academic resources.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866215</data>
    </node>
    <node id="NIPS 2016">
      <data key="d0">NIPS 2016</data>
      <data key="d1">event</data>
      <data key="d2">The 30th Annual Conference on Neural Information Processing Systems (NIPS 2016) co-located with the Workshop on Cognitive Computation.</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866215</data>
    </node>
    <node id="lya Sutskever">
      <data key="d0">lya Sutskever</data>
      <data key="d1">person</data>
      <data key="d2">Lya Sutskever is an author noted for contributions to language models and their capabilities.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866215</data>
    </node>
    <node id="Colin Raffel">
      <data key="d0">Colin Raffel</data>
      <data key="d1">person</data>
      <data key="d2">Colin Raffel is an author who has co-written works on transfer learning in language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866215</data>
    </node>
    <node id="Stephen Robertson">
      <data key="d0">Stephen Robertson</data>
      <data key="d1">person</data>
      <data key="d2">Stephen Robertson is recognized for his work in information retrieval frameworks.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Hugo Zaragoza">
      <data key="d0">Hugo Zaragoza</data>
      <data key="d1">person</data>
      <data key="d2">Hugo Zaragoza is a researcher known for contributions to the BM25 relevance framework.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Irene Solaiman">
      <data key="d0">Irene Solaiman</data>
      <data key="d1">person</data>
      <data key="d2">Irene Solaiman is an author focusing on the social implications of language model releases.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Miles Brundage">
      <data key="d0">Miles Brundage</data>
      <data key="d1">person</data>
      <data key="d2">Miles Brundage is involved in examining the impacts of language models on society.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Jack Clark">
      <data key="d0">Jack Clark</data>
      <data key="d1">person</data>
      <data key="d2">Jack Clark has contributed to discussions on language model strategies and societal impacts.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Amanda Askell">
      <data key="d0">Amanda Askell</data>
      <data key="d1">person</data>
      <data key="d2">Amanda Askell is an author researching the effects of language models on societal norms.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Ariel Herbert-Voss">
      <data key="d0">Ariel Herbert-Voss</data>
      <data key="d1">person</data>
      <data key="d2">Ariel Herbert-Voss is noted for work relating to language models and their societal implications.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866216</data>
    </node>
    <node id="Jeff Wu">
      <data key="d0">Jeff Wu</data>
      <data key="d1">person</data>
      <data key="d2">Jeff Wu is a researcher who has collaborated on projects concerning language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Alec Radford">
      <data key="d0">Alec Radford</data>
      <data key="d1">person</data>
      <data key="d2">Alec Radford has contributed to advancements in natural language processing and models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Jian-Bing Wang">
      <data key="d0">Jian-Bing Wang</data>
      <data key="d1">person</data>
      <data key="d2">Jian-Bing Wang is engaged in research concerning language models and their applications.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Sainbayar Sukhbaatar">
      <data key="d0">Sainbayar Sukhbaatar</data>
      <data key="d1">person</data>
      <data key="d2">Sainbayar Sukhbaatar is known for work on memory networks and language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Arthur Szlam">
      <data key="d0">Arthur Szlam</data>
      <data key="d1">person</data>
      <data key="d2">Arthur Szlam is a researcher focused on memory networks and language processing.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="James Thorne">
      <data key="d0">James Thorne</data>
      <data key="d1">person</data>
      <data key="d2">James Thorne is an author involved in the creation of fact extraction datasets.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Andreas Vlachos">
      <data key="d0">Andreas Vlachos</data>
      <data key="d1">person</data>
      <data key="d2">Andreas Vlachos has contributed to research on language models and dataset creation.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Christos Christodoulopoulos">
      <data key="d0">Christos Christodoulopoulos</data>
      <data key="d1">person</data>
      <data key="d2">Christos Christodoulopoulos is involved in creating benchmarks for natural language understanding.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866217</data>
    </node>
    <node id="Arpit Mittal">
      <data key="d0">Arpit Mittal</data>
      <data key="d1">person</data>
      <data key="d2">Arpit Mittal has collaborated in research pertaining to natural language processing.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Ashish Vaswani">
      <data key="d0">Ashish Vaswani</data>
      <data key="d1">person</data>
      <data key="d2">Ashish Vaswani is known for his work on attention mechanisms in language models.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Niki Parmar">
      <data key="d0">Niki Parmar</data>
      <data key="d1">person</data>
      <data key="d2">Niki Parmar has contributed to advances in language processing techniques.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Aidan N Gomez">
      <data key="d0">Aidan N Gomez</data>
      <data key="d1">person</data>
      <data key="d2">Aidan N Gomez is noted for his research on language models and attention mechanisms.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Łukasz Kaiser">
      <data key="d0">Łukasz Kaiser</data>
      <data key="d1">person</data>
      <data key="d2">Łukasz Kaiser is a researcher engaged in the development of neural networks for language.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Ashwin Vijayakumar">
      <data key="d0">Ashwin Vijayakumar</data>
      <data key="d1">person</data>
      <data key="d2">Ashwin Vijayakumar is noted for his research in artificial intelligence and complex scene descriptions.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Michael Cogswell">
      <data key="d0">Michael Cogswell</data>
      <data key="d1">person</data>
      <data key="d2">Michael Cogswell has contributed to advancements in natural language processing techniques.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Ramprasaath Selvaraju">
      <data key="d0">Ramprasaath Selvaraju</data>
      <data key="d1">person</data>
      <data key="d2">Ramprasaath Selvaraju focuses on methodologies in machine learning applications.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866218</data>
    </node>
    <node id="Qing Sun">
      <data key="d0">Qing Sun</data>
      <data key="d1">person</data>
      <data key="d2">Qing Sun is involved in interdisciplinary approaches in artificial intelligence research.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866219</data>
    </node>
    <node id="Stefan Lee">
      <data key="d0">Stefan Lee</data>
      <data key="d1">person</data>
      <data key="d2">Stefan Lee is known for work related to AI and machine learning description methodologies.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866219</data>
    </node>
    <node id="David Crandall">
      <data key="d0">David Crandall</data>
      <data key="d1">person</data>
      <data key="d2">David Crandall has contributed to advancements in understanding complex scenes using AI.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866219</data>
    </node>
    <node id="Dhruv Batra">
      <data key="d0">Dhruv Batra</data>
      <data key="d1">person</data>
      <data key="d2">Dhruv Batra has worked on developing intelligent systems capable of scene understanding.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866219</data>
    </node>
    <node id="R^3">
      <data key="d0">R^3</data>
      <data key="d1">event</data>
      <data key="d2">R^3 is associated with reinforced ranker-reader strategies in question-answering systems.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866219</data>
    </node>
    <node id="James H. Thorne">
      <data key="d0">James H. Thorne</data>
      <data key="d1">person</data>
      <data key="d2">James H. Thorne is involved in research and has published works related to language models and their applications.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Shuohang Wang">
      <data key="d0">Shuohang Wang</data>
      <data key="d1">person</data>
      <data key="d2">Shuohang Wang is a researcher contributing to the development of question-answering systems in the context of language models.&lt;SEP&gt;Shuohang Wang is an author who contributed to multiple works regarding question answering and machine learning.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Mo Yu">
      <data key="d0">Mo Yu</data>
      <data key="d1">person</data>
      <data key="d2">Mo Yu is involved in artificial intelligence research focusing on language processing and understanding.&lt;SEP&gt;Mo Yu is an author collaborating on research related to open-domain question answering.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Xiaoxiao Guo">
      <data key="d0">Xiaoxiao Guo</data>
      <data key="d1">person</data>
      <data key="d2">Xiaoxiao Guo is a researcher engaged in exploring methodologies in language model development.&lt;SEP&gt;Xiaoxiao Guo is an author involved in question answering research projects.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Zhiguo Wang">
      <data key="d0">Zhiguo Wang</data>
      <data key="d1">person</data>
      <data key="d2">Zhiguo Wang is a contributor to research in the area of question-answering systems.&lt;SEP&gt;Zhiguo Wang is an author who contributed to research on answer reranking in question answering systems.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Tim Klinger">
      <data key="d0">Tim Klinger</data>
      <data key="d1">person</data>
      <data key="d2">Tim Klinger is involved in artificial intelligence research and methodologies within natural language processing.&lt;SEP&gt;Tim Klinger is an author collaborating on question answering and related NLP research.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Wei Zhang">
      <data key="d0">Wei Zhang</data>
      <data key="d1">person</data>
      <data key="d2">Wei Zhang contributes to studies focusing on the performance of language models.&lt;SEP&gt;Wei Zhang is an author contributing to various research papers on question answering.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866220</data>
    </node>
    <node id="Shiyu Chang">
      <data key="d0">Shiyu Chang</data>
      <data key="d1">person</data>
      <data key="d2">Shiyu Chang is a researcher engaged in the development of AI techniques in natural language understanding.&lt;SEP&gt;Shiyu Chang is a contributor to works focused on question answering methodology.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866221</data>
    </node>
    <node id="Gerry Tesauro">
      <data key="d0">Gerry Tesauro</data>
      <data key="d1">person</data>
      <data key="d2">Gerry Tesauro is recognized for his contributions to neural networks and artificial intelligence.&lt;SEP&gt;Gerry Tesauro is a co-author on research discussing machine learning aspects of question answering.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866221</data>
    </node>
    <node id="Bowen Zhou">
      <data key="d0">Bowen Zhou</data>
      <data key="d1">person</data>
      <data key="d2">Bowen Zhou is involved in advancements in question-answering systems and machine learning.&lt;SEP&gt;Bowen Zhou is an author contributing to question answering research.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866221</data>
    </node>
    <node id="Jing Jiang">
      <data key="d0">Jing Jiang</data>
      <data key="d1">person</data>
      <data key="d2">Jing Jiang is noted for his work in the field of natural language processing and question-answering systems.&lt;SEP&gt;Jing Jiang is an author involved in various works on machine learning and question answering.</data>
      <data key="d3">chunk-621349422796d54fe59c686c4614e2ce&lt;SEP&gt;chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866221</data>
    </node>
    <node id="Curran Associates, Inc.">
      <data key="d0">Curran Associates, Inc.</data>
      <data key="d1">organization</data>
      <data key="d2">Curran Associates, Inc. is associated with producing and disseminating research outputs and publications.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866221</data>
    </node>
    <node id="Memory Networks">
      <data key="d0">Memory Networks</data>
      <data key="d1">event</data>
      <data key="d2">Memory networks refer to a model discussed for their application in AI and natural language processing.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866221</data>
    </node>
    <node id="Reinforced Ranker-Reader">
      <data key="d0">Reinforced Ranker-Reader</data>
      <data key="d1">event</data>
      <data key="d2">Reinforced ranker-reader is a model developed for enhanced performance in open-domain question answering.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="Huggingfaces Transformers">
      <data key="d0">Huggingfaces Transformers</data>
      <data key="d1">event</data>
      <data key="d2">Huggingface’s Transformers is a framework known for state-of-the-art natural language processing applications.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="ICLR 2015">
      <data key="d0">ICLR 2015</data>
      <data key="d1">event</data>
      <data key="d2">ICLR 2015 is an international conference focused on learning representations in machine learning and AI.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="AAAI Symposium on Educational Advances in Artificial Intelligence">
      <data key="d0">AAAI Symposium on Educational Advances in Artificial Intelligence</data>
      <data key="d1">event</data>
      <data key="d2">This symposium addresses advancements in educational applications of artificial intelligence.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="Hong Kong, China">
      <data key="d0">Hong Kong, China</data>
      <data key="d1">geo</data>
      <data key="d2">Hong Kong is a geographical location where significant conferences and research discussions were held.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="Thomas Wolf">
      <data key="d0">Thomas Wolf</data>
      <data key="d1">person</data>
      <data key="d2">Thomas Wolf is an author who contributed to research on natural language processing, specifically associated with Huggingface’s Transformers.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="Lysandre Debut">
      <data key="d0">Lysandre Debut</data>
      <data key="d1">person</data>
      <data key="d2">Lysandre Debut is an author contributing to the Huggingface’s Transformers project focused on advancements in NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="Victor Sanh">
      <data key="d0">Victor Sanh</data>
      <data key="d1">person</data>
      <data key="d2">Victor Sanh is an author contributing to the development of natural language processing models under Huggingface’s Transformers.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866222</data>
    </node>
    <node id="Julien Chaumond">
      <data key="d0">Julien Chaumond</data>
      <data key="d1">person</data>
      <data key="d2">Julien Chaumond is an author who participated in the creation of Huggingface’s Transformers, impacting NLP technologies.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Clement Delangue">
      <data key="d0">Clement Delangue</data>
      <data key="d1">person</data>
      <data key="d2">Clement Delangue is an author associated with Huggingface’s Transformers, contributing to advancements in NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Anthony Moi">
      <data key="d0">Anthony Moi</data>
      <data key="d1">person</data>
      <data key="d2">Anthony Moi is an author who participated in the development of Huggingface’s Transformers, enhancing NLP capabilities.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Pierric Cistac">
      <data key="d0">Pierric Cistac</data>
      <data key="d1">person</data>
      <data key="d2">Pierric Cistac is an author contributing to Huggingface’s Transformers, focusing on NLP applications.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Tim Rault">
      <data key="d0">Tim Rault</data>
      <data key="d1">person</data>
      <data key="d2">Tim Rault is an author who contributed to research work related to Huggingface’s Transformers in NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Rémi Louf">
      <data key="d0">Rémi Louf</data>
      <data key="d1">person</data>
      <data key="d2">Rémi Louf is an author involved in the Huggingface project aimed at improving natural language processing.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Morgan Funtowicz">
      <data key="d0">Morgan Funtowicz</data>
      <data key="d1">person</data>
      <data key="d2">Morgan Funtowicz is an author associated with Huggingface’s Transformers, enhancing NLP technologies.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Joe Davison">
      <data key="d0">Joe Davison</data>
      <data key="d1">person</data>
      <data key="d2">Joe Davison is an author contributing to Huggingface’s Transformers, focusing on natural language processing techniques.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Sam Shleifer">
      <data key="d0">Sam Shleifer</data>
      <data key="d1">person</data>
      <data key="d2">Sam Shleifer is an author who worked on the development of Huggingface’s Transformers, which is significant in NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866223</data>
    </node>
    <node id="Patrick von Platen">
      <data key="d0">Patrick von Platen</data>
      <data key="d1">person</data>
      <data key="d2">Patrick von Platen is an author involved in the Huggingface’s Transformers project, contributing to NLP research.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Clara Ma">
      <data key="d0">Clara Ma</data>
      <data key="d1">person</data>
      <data key="d2">Clara Ma is an author contributing to Huggingface’s Transformers, which are key tools for NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Yacine Jernite">
      <data key="d0">Yacine Jernite</data>
      <data key="d1">person</data>
      <data key="d2">Yacine Jernite is an author who has contributed to the Huggingface’s Transformers project, impacting NLP applications.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Julien Plu">
      <data key="d0">Julien Plu</data>
      <data key="d1">person</data>
      <data key="d2">Julien Plu is an author associated with Huggingface’s Transformers, focusing on NLP advancements.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Canwen Xu">
      <data key="d0">Canwen Xu</data>
      <data key="d1">person</data>
      <data key="d2">Canwen Xu is an author contributing to Huggingface’s Transformers, enhancing capabilities in natural language processing.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Teven Le Scao">
      <data key="d0">Teven Le Scao</data>
      <data key="d1">person</data>
      <data key="d2">Teven Le Scao is an author who worked on advancements for Huggingface’s Transformers, contributing to NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Sylvain Gugger">
      <data key="d0">Sylvain Gugger</data>
      <data key="d1">person</data>
      <data key="d2">Sylvain Gugger is an author who participated in the development of Huggingface’s Transformers for NLP applications.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866224</data>
    </node>
    <node id="Mariama Drame">
      <data key="d0">Mariama Drame</data>
      <data key="d1">person</data>
      <data key="d2">Mariama Drame is an author contributing to Huggingface’s Transformers, improving NLP technologies.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866225</data>
    </node>
    <node id="Quentin Lhoest">
      <data key="d0">Quentin Lhoest</data>
      <data key="d1">person</data>
      <data key="d2">Quentin Lhoest is an author involved in the Huggingface’s Transformers project, focusing on advancements in NLP.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866225</data>
    </node>
    <node id="Alexander M. Rush">
      <data key="d0">Alexander M. Rush</data>
      <data key="d1">person</data>
      <data key="d2">Alexander M. Rush is an author who contributed to Huggingface’s Transformers, enhancing natural language processing capabilities.</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866225</data>
    </node>
    <node id="Fairseq">
      <data key="d0">Fairseq</data>
      <data key="d1">organization</data>
      <data key="d2">Fairseq is a framework used for training various models, including RAG and BART, and is associated with mixed precision floating-point arithmetic.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866225</data>
    </node>
    <node id="HuggingFace Transformers">
      <data key="d0">HuggingFace Transformers</data>
      <data key="d1">organization</data>
      <data key="d2">HuggingFace Transformers is an open-source platform that provides implementations for various machine learning models, including RAG.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866225</data>
    </node>
    <node id="Wiki Test Set">
      <data key="d0">Wiki Test Set</data>
      <data key="d1">event</data>
      <data key="d2">The Wiki Test Set is a specific dataset used for evaluating performance on question-answering tasks, noted for being simpler to answer from Wikipedia.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866225</data>
    </node>
    <node id="NVIDIA V100 GPUs">
      <data key="d0">NVIDIA V100 GPUs</data>
      <data key="d1">category</data>
      <data key="d2">NVIDIA V100 GPUs are high-performance graphics processing units used for distributed training of machine learning models.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866226</data>
    </node>
    <node id="BERT-base">
      <data key="d0">BERT-base</data>
      <data key="d1">category</data>
      <data key="d2">BERT-base is a transformer model that encodes text and is used in various natural language processing tasks, including question answering.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866226</data>
    </node>
    <node id="BART-large">
      <data key="d0">BART-large</data>
      <data key="d1">category</data>
      <data key="d2">BART-large is a sequence-to-sequence model used for generating text and has numerous applications in natural language understanding.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866226</data>
    </node>
    <node id="NULL Document">
      <data key="d0">NULL Document</data>
      <data key="d1">category</data>
      <data key="d2">The NULL document refers to a mechanism in RAG for handling cases where no useful information can be retrieved for a query.</data>
      <data key="d3">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866226</data>
    </node>
    <node id="T5-11B">
      <data key="d0">T5-11B</data>
      <data key="d1">organization</data>
      <data key="d2">T5-11B is the best performing closed-book open-domain QA model, characterized by having 11 Billion trainable parameters.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866226</data>
    </node>
    <node id="T5-large">
      <data key="d0">T5-large</data>
      <data key="d1">organization</data>
      <data key="d2">T5-large is a model with 770M parameters that is closest in size to the authors' models.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866226</data>
    </node>
    <node id="Retrieval Component Collapse">
      <data key="d0">Retrieval Component Collapse</data>
      <data key="d1">event</data>
      <data key="d2">Retrieval Component Collapse describes a situation where the retrieval mechanism fails, returning the same documents regardless of input.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866227</data>
    </node>
    <node id="H Retrieval Collapse">
      <data key="d0">H Retrieval Collapse</data>
      <data key="d1">category</data>
      <data key="d2">H Retrieval Collapse is a phenomenon where the retrieval component in a machine learning model fails to return diverse documents, leading to a collapse in performance.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866227</data>
    </node>
    <node id="story generation">
      <data key="d0">story generation</data>
      <data key="d1">event</data>
      <data key="d2">Story generation is described as a task where the retrieval component of a model may collapse, affecting the output of the generator.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866227</data>
    </node>
    <node id="Perez et al.">
      <data key="d0">Perez et al.</data>
      <data key="d1">person</data>
      <data key="d2">Perez et al. refers to the researchers who found issues with spurious retrieval results when optimizing a retrieval component.</data>
      <data key="d3">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866227</data>
    </node>
    <node id="EP">
      <data key="d0">EP</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d2">EP has received support from the NSF Graduate Research Fellowship for their research work.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866251</data>
    </node>
    <node id="PL">
      <data key="d0">PL</data>
      <data key="d3">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d2">PL is supported by the FAIR PhD program in their research pursuits.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866251</data>
    </node>
    <node id="Large Memory Layers with Product Keys">
      <data key="d0">Large Memory Layers with Product Keys</data>
      <data key="d3">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d2">Guillaume Lample is a co-author of the research paper discussing large memory layers, indicating his involvement in that area of study.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866277</data>
    </node>
    <node id="Mixed precision training">
      <data key="d0">Mixed precision training</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Gregory Diamos is a co-author cited in the paper discussing mixed precision training."|&gt;"research contribution, academic collaboration</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866282</data>
    </node>
    <node id="Towards exploiting background knowledge for building conversation systems">
      <data key="d0">Towards exploiting background knowledge for building conversation systems</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Nikita Moghe is a co-author cited in the conversation systems paper presented in 2018."|&gt;"research contribution, academic collaboration</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866284</data>
    </node>
    <node id="MS MARCO dataset">
      <data key="d0">MS MARCO dataset</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Tri Nguyen contributed to the research regarding the machine reading comprehension dataset MS MARCO."|&gt;"research contribution, academic collaboration</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866286</data>
    </node>
    <node id="Passage re-ranking with BERT">
      <data key="d0">Passage re-ranking with BERT</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Rodrigo Nogueira is credited with co-authoring the paper on passage re-ranking with BERT."|&gt;"research contribution, academic collaboration</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866289</data>
    </node>
    <node id="Finding generalizable evidence">
      <data key="d0">Finding generalizable evidence</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Ethan Perez is cited for his involvement in the research on learning to convince Q&amp;A models."|&gt;"research contribution, academic collaboration</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866290</data>
    </node>
    <node id="Language models as knowledge bases">
      <data key="d0">Language models as knowledge bases</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Fabio Petroni is cited as a significant contributor to the research on language models and their factual basis."|&gt;"research contribution, academic collaboration</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866291</data>
    </node>
    <node id="The 2019 Conference of the North American Chapter of the Association for Computational Linguistics">
      <data key="d0">The 2019 Conference of the North American Chapter of the Association for Computational Linguistics</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Hong Kong is the location where the 2019 conference was held."|&gt;"event location, conference organization</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866301</data>
    </node>
    <node id="The 2018 Conference on Empirical Methods in Natural Language Processing">
      <data key="d0">The 2018 Conference on Empirical Methods in Natural Language Processing</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">Brussels, Belgium is the city that hosted the 2018 NLP conference."|&gt;"event location, conference organization</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866302</data>
    </node>
    <node id="association for computational linguistics">
      <data key="d0">association for computational linguistics</data>
      <data key="d3">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d2">fairseq is referenced in the context of academic demonstrations at the Association for Computational Linguistics."|&gt;"toolkit utilization, research showcase</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866304</data>
    </node>
    <node id="Wanjun Zhong">
      <data key="d0">Wanjun Zhong</data>
      <data key="d3">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d2">Wanjun Zhong's research contributes to methodologies discussed in Huggingface’s Transformers framework.</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866317</data>
    </node>
    <node id="RAG System Process Diagram (image)">
      <data key="d0">RAG System Process Diagram (image)</data>
      <data key="d1">image</data>
      <data key="d2">This diagram illustrates the functional components of a retrieval-augmented generation system, integrating both parametric and non-parametric memory. It visually supports the discussion of RAG models for enhancing NLP tasks through a combined approach detailed in the surrounding text.</data>
      <data key="d3">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="RAG-Sequence Probability Equation (equation)">
      <data key="d0">RAG-Sequence Probability Equation (equation)</data>
      <data key="d1">equation</data>
      <data key="d2">This equation defines the probability distribution of a generated sequence based on latent document retrieval in the RAG-Sequence model, facilitating enhanced contextual text generation in knowledge-intensive NLP tasks.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="RAG-Token Probability Model (equation)">
      <data key="d0">RAG-Token Probability Model (equation)</data>
      <data key="d1">equation</data>
      <data key="d2">This equation represents the probability model for generating a sequence of tokens using retrieval-augmented generation (RAG) where each token's generation integrates information from both the input and retrieved documents, showcasing how RAG combines parametric and non-parametric memory for enhanced language tasks.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Conditional Document Retrieval Probability (equation)">
      <data key="d0">Conditional Document Retrieval Probability (equation)</data>
      <data key="d1">equation</data>
      <data key="d2">This equation captures the conditional probability of document retrieval in the RAG model, combining parametric and non-parametric memory to enhance knowledge retrieval for generation tasks in NLP.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Open-Domain QA Test Scores (table)">
      <data key="d0">Open-Domain QA Test Scores (table)</data>
      <data key="d1">table</data>
      <data key="d2">The table demonstrates the effectiveness of RAG in open-domain question answering tasks, revealing its strong performance (44.1 and 44.5) compared to traditional models like T5 and REALM, thus validating RAG's techniques of combining retrieval and generation to produce accurate responses.</data>
      <data key="d3">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="RAG Performance Results Table (table)">
      <data key="d0">RAG Performance Results Table (table)</data>
      <data key="d1">table</data>
      <data key="d2">The table showcases performance scores of RAG models in Jeopardy question generation and MAS-MARCO tasks. RAG-Token and RAG-Sequence outperform SOTA models in multiple metrics, highlighting their effectiveness in knowledge-intensive generation tasks critical to open-domain question answering.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Document Generation Heatmap Visualization (image)">
      <data key="d0">Document Generation Heatmap Visualization (image)</data>
      <data key="d1">image</data>
      <data key="d2">This image displays a heatmap visualization showing the document relevance to sentence generation for titles like 'The Sun Also Rises' and 'A Farewell to Arms', illustrating RAG's ability to utilize specific document contexts as part of its language generation model.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Comparative Model Generations for Question Answering (table)">
      <data key="d0">Comparative Model Generations for Question Answering (table)</data>
      <data key="d1">table</data>
      <data key="d2">This table highlights the performance of RAG-Token and RAG-Sequence in generating answers to various tasks compared to BART. Key findings show RAG models generate more specific and accurate responses, supporting claims in the surrounding content about the effectiveness of retrieval-augmented methods.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Human Assessments for Jeopardy Question Generation (table)">
      <data key="d0">Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d1">table</data>
      <data key="d2">This table provides a comparative assessment of the factuality and specificity of responses generated by BART and RAG models in the Jeopardy Question Generation Task, showing a preference for RAG in both metrics which aligns with claims from surrounding text about the superiority of RAG model’s generative performance.</data>
      <data key="d3">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Tri-gram Diversity Ratios in Generation Tasks (table)">
      <data key="d0">Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d1">table</data>
      <data key="d2">This table compares the ratios of distinct to total tri-grams generated by different models in MSMARCO and Jeopardy QGen tasks. It highlights RAG models' superior diversity over BART, reinforcing the document's emphasis on the effectiveness of retrieval-augmented architectures in enhancing generation diversity and factuality.</data>
      <data key="d3">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Model Performance Comparison Table for RAG-based Architectures (table)">
      <data key="d0">Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d1">table</data>
      <data key="d2">This table compares performance metrics of RAG-based models across various NLP tasks, underscoring the effectiveness of retrieval mechanisms. It indicates that RAG-Sequence consistently outperforms RAG-Token, validating claims in the surrounding content about the advantages of advanced retrieval-oriented models in enhancing generative tasks.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="RAG Performance Metrics Image (image)">
      <data key="d0">RAG Performance Metrics Image (image)</data>
      <data key="d1">image</data>
      <data key="d2">The image visually represents performance metrics for the 'RAG' models across various counts of retrieved documents, highlighting differences between the 'RAG-Token' and 'RAG-Sequence' methods in Exact Match, Answer Recall, Bleu-1, and Rouge-L metrics. This analytical visualization complements discussions on retrieval efficiency within the surrounding text.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Hemingway Sentence Evaluation Interface (image)">
      <data key="d0">Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d1">image</data>
      <data key="d2">The image is a user interface for evaluating the factual accuracy of statements about Ernest Hemingway. Annotators select which of two sentences is more factual, provided as part of a human evaluation task in NLP research.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d0">Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d1">table</data>
      <data key="d2">The table summarizes the number of training, development, and test instances across various datasets pertinent to open-domain question answering, illustrating the scale of data used for model training and evaluation.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866398</data>
    </node>
    <node id="Retrieval-Augmented Generation (RAG) System">
      <data key="d0">Retrieval-Augmented Generation (RAG) System</data>
      <data key="d1">organization</data>
      <data key="d2">The Retrieval-Augmented Generation (RAG) system is an architectural model that integrates non-parametric and parametric memory components for improving natural language processing tasks.</data>
      <data key="d3">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Query Encoder q(x)">
      <data key="d0">Query Encoder q(x)</data>
      <data key="d1">category</data>
      <data key="d2">'Query Encoder q(x)' is a component of the RAG system responsible for encoding input queries, facilitating the processing of natural language.</data>
      <data key="d3">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Image Content Analysis">
      <data key="d0">Image Content Analysis</data>
      <data key="d1">event</data>
      <data key="d2">Image Content Analysis refers to the process described in the text that involves analyzing a visual element, which in this case, is an image representation of a system architecture.</data>
      <data key="d3">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Visual Analysis">
      <data key="d0">Visual Analysis</data>
      <data key="d1">event</data>
      <data key="d2">Visual Analysis is the process outlined in the text that pertains to interpreting and explaining the components and workflow of the retrieval-augmented generation (RAG) system as depicted in the diagram.</data>
      <data key="d3">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Diagram">
      <data key="d0">Diagram</data>
      <data key="d1">category</data>
      <data key="d2">The diagram is an illustrative representation that outlines the architecture and process flow of the retrieval-augmented generation (RAG) system.</data>
      <data key="d3">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Natural Language Processing (NLP)">
      <data key="d0">Natural Language Processing (NLP)</data>
      <data key="d1">category</data>
      <data key="d2">Natural Language Processing (NLP) is a field of artificial intelligence focused on the interaction between computers and human language, often leveraging statistical methods to process and generate text.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866467</data>
    </node>
    <node id="Bayesian Principles">
      <data key="d0">Bayesian Principles</data>
      <data key="d1">category</data>
      <data key="d2">Bayesian principles involve statistical inferences based on Bayes' theorem, often applied in various domains including the RAG-Sequence model for probabilistic reasoning.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="Markov Processes">
      <data key="d0">Markov Processes</data>
      <data key="d1">category</data>
      <data key="d2">Markov processes are stochastic models that predict future events based on current states, relevant to the autoregressive nature of sequence generation in the RAG-Sequence model.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="p _ { \mathrm { R A G . S e q u e n c e } } ( y | x ) ">
      <data key="d0">p _ { \mathrm { R A G . S e q u e n c e } } ( y | x ) </data>
      <data key="d1">category</data>
      <data key="d2">This expression is a mathematical representation of the RAG-Sequence model's probability distribution related to the generation of sequences based on input and retrieved documents.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="p_{\\theta}">
      <data key="d0">p_{\\theta}</data>
      <data key="d1">category</data>
      <data key="d2">p_{\\theta} represents the generator’s probability distribution in the context of the RAG-Sequence model, used to generate output sequences based on input and retrieved context.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="p_{\\eta}">
      <data key="d0">p_{\\eta}</data>
      <data key="d1">category</data>
      <data key="d2">p_{\\eta} represents the retriever’s probability distribution in the RAG-Sequence model, which influences the selection of retrieved documents based on the input query.</data>
      <data key="d3">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="RAG-Ioken">
      <data key="d0">RAG-Ioken</data>
      <data key="d1">category</data>
      <data key="d2">RAG-Ioken is a conceptual model that refers to retrieval-augmented generation techniques utilized in computational linguistics for token generation.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="Computational Linguistics">
      <data key="d0">Computational Linguistics</data>
      <data key="d1">category</data>
      <data key="d2">Computational Linguistics is a field concerned with using computational methods to analyze and understand human language.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866468</data>
    </node>
    <node id="Probabilistic Model">
      <data key="d0">Probabilistic Model</data>
      <data key="d1">category</data>
      <data key="d2">A Probabilistic Model outlines a method for generating sequences of tokens based on probabilities and contextual inputs.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866469</data>
    </node>
    <node id="Document Index">
      <data key="d0">Document Index</data>
      <data key="d1">category</data>
      <data key="d2">Document Index refers to a non-parametric memory structure used in the RAG framework for retrieving relevant information.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866469</data>
    </node>
    <node id="Query Answering">
      <data key="d0">Query Answering</data>
      <data key="d1">category</data>
      <data key="d2">Query Answering involves techniques to respond to questions accurately, leveraging retrieval-augmented methods.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866469</data>
    </node>
    <node id="Sequence Generation">
      <data key="d0">Sequence Generation</data>
      <data key="d1">category</data>
      <data key="d2">Sequence Generation is the process of producing sequential lists of items (tokens) based on given inputs.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="Bayesian Inference">
      <data key="d0">Bayesian Inference</data>
      <data key="d1">category</data>
      <data key="d2">Bayesian Inference is a statistical method that involves updating the probability estimate as more evidence is available.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="Retrieval-Augmented Generation">
      <data key="d0">Retrieval-Augmented Generation</data>
      <data key="d1">category</data>
      <data key="d2">Retrieval-Augmented Generation (RAG) is a framework combining generative models with information retrieval to enhance the performance of tasks like question answering and summarization.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="Seq2seq Generator">
      <data key="d0">Seq2seq Generator</data>
      <data key="d1">category</data>
      <data key="d2">The Seq2seq Generator is a type of neural network architecture that transforms input sequences into output sequences, utilized within the RAG framework.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="Knowledge Retrieval">
      <data key="d0">Knowledge Retrieval</data>
      <data key="d1">category</data>
      <data key="d2">Knowledge Retrieval refers to the process of identifying and obtaining information from various sources to improve understanding or inform decisions.</data>
      <data key="d3">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="document z">
      <data key="d0">document z</data>
      <data key="d1">category</data>
      <data key="d2">Document z refers to a document represented in the equation, serving as the output of a retrieval process based on an input query.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866470</data>
    </node>
    <node id="input query x">
      <data key="d0">input query x</data>
      <data key="d1">category</data>
      <data key="d2">Input query x is the input provided to the model, representing the user's request to retrieve relevant documents.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866471</data>
    </node>
    <node id="Retrieval-Augmented Generation (RAG) model">
      <data key="d0">Retrieval-Augmented Generation (RAG) model</data>
      <data key="d1">organization</data>
      <data key="d2">The RAG model combines parametric and non-parametric memory components for improved document retrieval and generation.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866471</data>
    </node>
    <node id="maximum inner product search (MIPS)">
      <data key="d0">maximum inner product search (MIPS)</data>
      <data key="d1">category</data>
      <data key="d2">MIPS is a methodology used for efficiently retrieving documents based on the highest inner product, important for large-scale indexing.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866471</data>
    </node>
    <node id="Conditional Probability">
      <data key="d0">Conditional Probability</data>
      <data key="d1">category</data>
      <data key="d2">Conditional Probability refers to the probability of an event or outcome occurring based on the occurrence of another event or condition, as indicated in the mathematical equation.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866471</data>
    </node>
    <node id="Latent Space">
      <data key="d0">Latent Space</data>
      <data key="d1">category</data>
      <data key="d2">Latent Space is a representation space used in the context of the equation to determine the proximity of documents and queries for retrieval.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866471</data>
    </node>
    <node id="Exponential Function">
      <data key="d0">Exponential Function</data>
      <data key="d1">category</data>
      <data key="d2">The Exponential Function in the equation is used to illustrate the probabilistic relationship between document representations and input queries.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866471</data>
    </node>
    <node id="Inner Product">
      <data key="d0">Inner Product</data>
      <data key="d1">category</data>
      <data key="d2">Inner Product is a mathematical operation utilized in the equation to gauge similarity between document and query representations.</data>
      <data key="d3">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866472</data>
    </node>
    <node id="Table 1: Open-Domain QA Test Scores">
      <data key="d0">Table 1: Open-Domain QA Test Scores</data>
      <data key="d1">category</data>
      <data key="d2">Table 1 presents scores from different models in open-domain QA, highlighting their performance across various metrics and providing a structured comparison.</data>
      <data key="d3">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866473</data>
    </node>
    <node id="WQ">
      <data key="d0">WQ</data>
      <data key="d1">category</data>
      <data key="d2">WQ is another metric used in the evaluation of models for open-domain question answering, reflecting their performance in responding to questions.&lt;SEP&gt;WQ (Web Questions) is a category in which model performance was analyzed regarding their capability to process web-based questions.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866473</data>
    </node>
    <node id="CT">
      <data key="d0">CT</data>
      <data key="d1">category</data>
      <data key="d2">CT represents a specific scoring metric within the evaluation framework for question-answering models, contributing to a comprehensive analysis of their efficacy.&lt;SEP&gt;CT (Close Test) is a performance metric category that assesses model effectiveness in fill-in-the-blank type queries.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866473</data>
    </node>
    <node id="Question Generation Systems">
      <data key="d0">Question Generation Systems</data>
      <data key="d1">category</data>
      <data key="d2">Question Generation Systems involve methodologies aimed at creating questions from content, significantly impacting QA task performances.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="Table 2">
      <data key="d0">Table 2</data>
      <data key="d1">event</data>
      <data key="d2">Table 2 presents the generation and classification test scores for various models, summarizing performance metrics relevant to Jeopardy question generation.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="Structure">
      <data key="d0">Structure</data>
      <data key="d1">category</data>
      <data key="d2">Structure refers to the arrangement of the data presented in the table, defined by the headers and rows that categorize model performance.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="Jeopardy B-1">
      <data key="d0">Jeopardy B-1</data>
      <data key="d1">category</data>
      <data key="d2">Jeopardy B-1 is a performance metric related to the BLEU-1 score used to evaluate the quality of generated questions in the Jeopardy task.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866474</data>
    </node>
    <node id="MSMARCO SotA">
      <data key="d0">MSMARCO SotA</data>
      <data key="d1">category</data>
      <data key="d2">MSMARCO SotA refers to the 'State of the Art' benchmark score achieved by different models in the MS-MARCO task.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="FEVER-3">
      <data key="d0">FEVER-3</data>
      <data key="d1">category</data>
      <data key="d2">FEVER-3 is a version of the FEVER benchmark, which evaluates fact verification models on their accuracy.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="FEVER-2">
      <data key="d0">FEVER-2</data>
      <data key="d1">category</data>
      <data key="d2">FEVER-2 is another iteration of the FEVER benchmark for evaluating models focused on fact-checking tasks.</data>
      <data key="d3">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="RAG model">
      <data key="d0">RAG model</data>
      <data key="d1">organization</data>
      <data key="d2">The RAG model refers to a retrieval-augmented generation model that utilizes document contexts to assist in sentence completion and answer generation.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="Doc 1">
      <data key="d0">Doc 1</data>
      <data key="d1">event</data>
      <data key="d2">Doc 1 represents one of the documents analyzed in the heatmap, showcasing parts of the sentences related to the novels.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866475</data>
    </node>
    <node id="Doc 2">
      <data key="d0">Doc 2</data>
      <data key="d1">event</data>
      <data key="d2">Doc 2 is another document featured in the visualization, indicating the usage of 'The Sun Also Rises' within its context.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="Heatmap">
      <data key="d0">Heatmap</data>
      <data key="d1">category</data>
      <data key="d2">The heatmap is a visualization tool used to analyze the weight and importance of tokens in the context of language generation based on different documents.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="Language Generation">
      <data key="d0">Language Generation</data>
      <data key="d1">category</data>
      <data key="d2">Language generation refers to the process by which models like RAG create sentences or responses based on input contexts and learned information.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="Tokens">
      <data key="d0">Tokens</data>
      <data key="d1">category</data>
      <data key="d2">Tokens are the individual components of text used in language processing, which play a crucial role in constructing meaningful sentences by the model.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="Document Contexts">
      <data key="d0">Document Contexts</data>
      <data key="d1">category</data>
      <data key="d2">Document contexts are the various texts or content references from which models like RAG retrieve knowledge to assist in generating responses.</data>
      <data key="d3">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="Jeopardy Question">
      <data key="d0">Jeopardy Question</data>
      <data key="d1">event</data>
      <data key="d2">Jeopardy Question refers to a type of inquiry included in the comparison of various models' responses.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866476</data>
    </node>
    <node id="Scotland">
      <data key="d0">Scotland</data>
      <data key="d1">geo</data>
      <data key="d2">Scotland is mentioned in the context of queries related to currency needed in the region, indicating its relevance in the task examples.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Middle Ear">
      <data key="d0">Middle Ear</data>
      <data key="d1">category</data>
      <data key="d2">The middle ear is a category under anatomical structures that is defined in relation to questions posed to the models.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Table 3">
      <data key="d0">Table 3</data>
      <data key="d1">event</data>
      <data key="d2">Table 3 presents examples from generation tasks involving different models, illustrating their output variations for various inquiries.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Task">
      <data key="d0">Task</data>
      <data key="d1">category</data>
      <data key="d2">Task refers to the overarching categories of queries used in the model comparisons, such as defining terms or answering specific questions.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Input">
      <data key="d0">Input</data>
      <data key="d1">category</data>
      <data key="d2">Input represents the specific questions posed to the models as part of the evaluation process.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Model">
      <data key="d0">Model</data>
      <data key="d1">category</data>
      <data key="d2">Model category includes different algorithms, such as RAG-T and RAG-S, used to generate responses for various tasks.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Generation">
      <data key="d0">Generation</data>
      <data key="d1">category</data>
      <data key="d2">Generation refers to the output produced by the models in response to the input questions posed.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866477</data>
    </node>
    <node id="Dante">
      <data key="d0">Dante</data>
      <data key="d1">person</data>
      <data key="d2">Dante is referenced in the context of an epic poem, 'The Divine Comedy,' indicating a historical literary figure.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="The Divine Comedy">
      <data key="d0">The Divine Comedy</data>
      <data key="d1">category</data>
      <data key="d2">The Divine Comedy is an epic poem authored by Dante, divided into three main parts.</data>
      <data key="d3">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="Jeopardy Question Generation Task">
      <data key="d0">Jeopardy Question Generation Task</data>
      <data key="d1">event</data>
      <data key="d2">The Jeopardy Question Generation Task involves the generation of questions based on provided data, aimed at assessing the performance of different models.</data>
      <data key="d3">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="Table 4">
      <data key="d0">Table 4</data>
      <data key="d1">category</data>
      <data key="d2">Table 4 presents human assessments comparing the models BART and RAG, focusing on their performance in factuality and specificity.</data>
      <data key="d3">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="Factuality">
      <data key="d0">Factuality</data>
      <data key="d1">category</data>
      <data key="d2">Factuality is a metric used to assess the accuracy of generated outputs in the context of the Jeopardy Question Generation Task.</data>
      <data key="d3">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="Specificity">
      <data key="d0">Specificity</data>
      <data key="d1">category</data>
      <data key="d2">Specificity is a metric used to measure how detailed and precise the generated outputs are in the context of the Jeopardy Question Generation Task.</data>
      <data key="d3">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866478</data>
    </node>
    <node id="MSMARCO">
      <data key="d0">MSMARCO</data>
      <data key="d1">category</data>
      <data key="d2">MSMARCO is a collection of datasets used for training models in natural language processing, specifically for question answering tasks.</data>
      <data key="d3">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866479</data>
    </node>
    <node id="Jeopardy QGen">
      <data key="d0">Jeopardy QGen</data>
      <data key="d1">category</data>
      <data key="d2">Jeopardy QGen is a generation task that evaluates models on producing answers in the style of Jeopardy questions.</data>
      <data key="d3">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866479</data>
    </node>
    <node id="Gold">
      <data key="d0">Gold</data>
      <data key="d1">organization</data>
      <data key="d2">Gold is the benchmark model that achieved the highest ratios of distinct to total tri-grams in the evaluated tasks.</data>
      <data key="d3">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866479</data>
    </node>
    <node id="Distinction Ratio">
      <data key="d0">Distinction Ratio</data>
      <data key="d1">category</data>
      <data key="d2">Distinction Ratio refers to the measure of how many distinct tri-grams were generated compared to the total tri-grams for both MSMARCO and Jeopardy QGen tasks.</data>
      <data key="d3">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866479</data>
    </node>
    <node id="Performance Metrics">
      <data key="d0">Performance Metrics</data>
      <data key="d1">category</data>
      <data key="d2">Performance Metrics refer to the measurements used to evaluate the effectiveness of various models in generating tri-grams for the given tasks.</data>
      <data key="d3">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866479</data>
    </node>
    <node id="RAG-Token-BM25">
      <data key="d0">RAG-Token-BM25</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Token-BM25 is a model tested for its performance metrics in various natural language processing tasks.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="RAG-Sequence-BM25">
      <data key="d0">RAG-Sequence-BM25</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Sequence-BM25 is a model variant known for superior performance in retrieval-based tasks compared to RAG-Token.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="Jeopardy-QGen">
      <data key="d0">Jeopardy-QGen</data>
      <data key="d1">category</data>
      <data key="d2">Jeopardy-QGen refers to a game show-inspired question generation task where model performance is measured.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="MSMarco">
      <data key="d0">MSMarco</data>
      <data key="d1">category</data>
      <data key="d2">MSMarco is a benchmark dataset used for evaluating the accuracy and retrieval capabilities of natural language processing models.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="RAG-Token-Frozen">
      <data key="d0">RAG-Token-Frozen</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Token-Frozen is a model tested for its performance metrics in various natural language processing tasks, showing specific scores in different evaluation categories.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="RAG-Sequence-Frozen">
      <data key="d0">RAG-Sequence-Frozen</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Sequence-Frozen is another model variant that is evaluated alongside others for its performance in NLP task metrics.</data>
      <data key="d3">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="RAG-Tok">
      <data key="d0">RAG-Tok</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Tok is a retrieval-based model whose performance metrics are analyzed through various graphs, specifically focusing on exact match results.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="RAG-Seq">
      <data key="d0">RAG-Seq</data>
      <data key="d1">organization</data>
      <data key="d2">RAG-Seq is another retrieval-based model compared against RAG-Tok in performance metrics indicated in the presented graphs.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866480</data>
    </node>
    <node id="Fixed DPR">
      <data key="d0">Fixed DPR</data>
      <data key="d1">organization</data>
      <data key="d2">Fixed DPR is a retrieval model included in the performance analysis, showing different recall results compared to RAG models.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866481</data>
    </node>
    <node id="BM25">
      <data key="d0">BM25</data>
      <data key="d1">organization</data>
      <data key="d2">BM25 is a retrieval method that is plotted against RAG-Tok and RAG-Seq, displaying lower performance in the recall metrics.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866481</data>
    </node>
    <node id="K Retrieved Docs">
      <data key="d0">K Retrieved Docs</data>
      <data key="d1">category</data>
      <data key="d2">K Retrieved Docs refers to the number of documents retrieved in the performance evaluations of the models, ranging from 0 to 50.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866481</data>
    </node>
    <node id="NQ Exact Match">
      <data key="d0">NQ Exact Match</data>
      <data key="d1">event</data>
      <data key="d2">NQ Exact Match is an evaluation metric illustrated in the first graph, focusing on the exact matches from retrieved documents.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866481</data>
    </node>
    <node id="NQ Answer Recall @K">
      <data key="d0">NQ Answer Recall @K</data>
      <data key="d1">event</data>
      <data key="d2">NQ Answer Recall @K is a performance measure indicated in the second graph, detailing recall at varying numbers of retrieved documents.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866481</data>
    </node>
    <node id="Bleu-1 / Rouge-L score">
      <data key="d0">Bleu-1 / Rouge-L score</data>
      <data key="d1">event</data>
      <data key="d2">Bleu-1 / Rouge-L score is another evaluation metric shown in the third graph, tracking response quality as document quantity changes.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866481</data>
    </node>
    <node id="Solid Orange Line">
      <data key="d0">Solid Orange Line</data>
      <data key="d1">category</data>
      <data key="d2">The Solid Orange Line represents data for RAG-Tok in the 'NQ Exact Match' graph, indicating its performance metrics.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Dashed Teal Line">
      <data key="d0">Dashed Teal Line</data>
      <data key="d1">category</data>
      <data key="d2">The Dashed Teal Line depicts the performance metrics for RAG-Seq in the 'NQ Exact Match' graph, showing how it compares with RAG-Tok.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Turquoise Line">
      <data key="d0">Turquoise Line</data>
      <data key="d1">category</data>
      <data key="d2">The Turquoise Line represents the performance of Fixed DPR in the 'NQ Answer Recall @K' metrics.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Dotted Purple Line">
      <data key="d0">Dotted Purple Line</data>
      <data key="d1">category</data>
      <data key="d2">The Dotted Purple Line illustrates the performance of BM25 in the second graph, 'NQ Answer Recall @K'.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Long-Dashed Orange Line">
      <data key="d0">Long-Dashed Orange Line</data>
      <data key="d1">category</data>
      <data key="d2">The Long-Dashed Orange Line in the 'Bleu-1 / Rouge-L score' graph represents the Rouge-L score for RAG-Tok.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Densely Dashed Teal Line">
      <data key="d0">Densely Dashed Teal Line</data>
      <data key="d1">category</data>
      <data key="d2">The Densely Dashed Teal Line corresponds to the Bleu-1 score for RAG-Seq in the performance metrics.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Minimalist Background">
      <data key="d0">Minimalist Background</data>
      <data key="d1">category</data>
      <data key="d2">The Minimalist Background of the graphs emphasizes the clarity and readability of the data presented.</data>
      <data key="d3">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866482</data>
    </node>
    <node id="Hemingway">
      <data key="d0">Hemingway</data>
      <data key="d1">person</data>
      <data key="d2">Hemingway is an author known for works such as 'The Sun Also Rises' and 'A Farewell to Arms'.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866483</data>
    </node>
    <node id="Havana, Cuba">
      <data key="d0">Havana, Cuba</data>
      <data key="d1">geo</data>
      <data key="d2">Havana, Cuba is the birthplace of Hemingway, suggesting his cultural and familial background.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="Control Questions">
      <data key="d0">Control Questions</data>
      <data key="d1">event</data>
      <data key="d2">Control questions are part of a structured human evaluation study designed to ensure accurate responses in fact-checking tasks.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="Human Evaluation Study">
      <data key="d0">Human Evaluation Study</data>
      <data key="d1">organization</data>
      <data key="d2">The Human Evaluation Study involves participants assessing the factual accuracy of claims regarding various subjects, including authors.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="Sentence A">
      <data key="d0">Sentence A</data>
      <data key="d1">category</data>
      <data key="d2">Sentence A is a statement that claims 'The Sun Also Rises' is a novel by the author of 'A Farewell to Arms', highlighting one of Hemingway's works.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="Sentence B">
      <data key="d0">Sentence B</data>
      <data key="d1">category</data>
      <data key="d2">Sentence B asserts that the author of 'The Sun Also Rises' was born in Havana, Cuba, emphasizing Hemingway's birthplace.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="Fact-Checking Interface">
      <data key="d0">Fact-Checking Interface</data>
      <data key="d1">organization</data>
      <data key="d2">The Fact-Checking Interface is part of the online user interface designed to compare the factual accuracy of two sentences about Hemingway.</data>
      <data key="d3">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866484</data>
    </node>
    <node id="FEVER-3-way">
      <data key="d0">FEVER-3-way</data>
      <data key="d1">category</data>
      <data key="d2">FEVER-3-way is a dataset with 145450 training instances used in QA tasks.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="FEVER-2-way">
      <data key="d0">FEVER-2-way</data>
      <data key="d1">category</data>
      <data key="d2">FEVER-2-way is a QA dataset that contains 96966 training instances.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="Table 7">
      <data key="d0">Table 7</data>
      <data key="d1">event</data>
      <data key="d2">Table 7 presents a count of instances across various QA datasets, reflecting their structure and usage.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="Open-domain Question Answering Tasks">
      <data key="d0">Open-domain Question Answering Tasks</data>
      <data key="d1">category</data>
      <data key="d2">Open-domain question answering tasks involve utilizing datasets to generate answers to questions based on given information.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866485</data>
    </node>
    <node id="Footnotes">
      <data key="d0">Footnotes</data>
      <data key="d1">event</data>
      <data key="d2">Footnotes are references or additional notes that provide further context or clarification related to the data presented in the analysis.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866486</data>
    </node>
    <node id="Table Analysis">
      <data key="d0">Table Analysis</data>
      <data key="d1">event</data>
      <data key="d2">Table Analysis refers to the process of reviewing and interpreting data presented in a tabular format.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866486</data>
    </node>
    <node id="Data Preparation for QA Systems">
      <data key="d0">Data Preparation for QA Systems</data>
      <data key="d1">category</data>
      <data key="d2">Data Preparation for QA Systems emphasizes the importance of assembling and refining datasets to optimize the performance of question answering systems.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866486</data>
    </node>
    <node id="Statistical Insights">
      <data key="d0">Statistical Insights</data>
      <data key="d1">category</data>
      <data key="d2">Statistical Insights refer to the analysis derived from the dataset instances, which reveal patterns and trends that inform QA model efficiency.</data>
      <data key="d3">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d4">2005.11401v4.pdf</data>
      <data key="d5">1757866486</data>
    </node>
    <edge source="Patrick Lewis" target="Facebook AI Research">
      <data key="d6">9.0</data>
      <data key="d7">Patrick Lewis is affiliated with Facebook AI Research, involved in developing retrieval-augmented generation models.</data>
      <data key="d8">affiliation,research collaboration</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866229</data>
    </edge>
    <edge source="Patrick Lewis" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Patrick Lewis is recognized for his contributions to the understanding of language model frameworks."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866294</data>
    </edge>
    <edge source="Ethan Perez" target="Facebook AI Research">
      <data key="d6">8.0</data>
      <data key="d7">Ethan Perez is part of the research team at Facebook AI Research working on RAG models.</data>
      <data key="d8">affiliation,research contribution</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866230</data>
    </edge>
    <edge source="Ethan Perez" target="Finding generalizable evidence">
      <data key="d6">8.0</data>
      <data key="d7">Ethan Perez is cited for his involvement in the research on learning to convince Q&amp;A models."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866290</data>
    </edge>
    <edge source="Aleksandra Piktus" target="Facebook AI Research">
      <data key="d6">7.0</data>
      <data key="d7">Aleksandra Piktus works at Facebook AI Research, contributing to the retrieval-augmented generation research.</data>
      <data key="d8">affiliation,research contribution</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866231</data>
    </edge>
    <edge source="Aleksandra Piktus" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Aleksandra Piktus is involved in the research focused on language models and their functionalities."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866295</data>
    </edge>
    <edge source="Fabio Petroni" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Fabio Petroni is cited as a significant contributor to the research on language models and their factual basis."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866291</data>
    </edge>
    <edge source="Tim Rocktäschel" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Tim Rocktäschel is noted for his role in exploring language models and knowledge bases."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866292</data>
    </edge>
    <edge source="Sebastian Riedel" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Sebastian Riedel is mentioned in relation to research on the capabilities of language models as knowledge repositories."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866293</data>
    </edge>
    <edge source="Douwe Kiela" target="Finding generalizable evidence">
      <data key="d6">8.0</data>
      <data key="d7">Douwe Kiela is noted for his involvement in the research examining Q&amp;A model evidence."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866294</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="Natural Questions">
      <data key="d6">10.0</data>
      <data key="d7">The RAG models achieved state-of-the-art results on the Natural Questions task.</data>
      <data key="d8">performance evaluation,task achievement</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866229</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="WebQuestions">
      <data key="d6">9.0</data>
      <data key="d7">RAG models have shown impressive performance on WebQuestions, establishing their effectiveness.</data>
      <data key="d8">performance evaluation,task achievement</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866230</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="CuratedTrec">
      <data key="d6">8.0</data>
      <data key="d7">The performance of RAG models on CuratedTrec has set new benchmarks in QA tasks.</data>
      <data key="d8">performance evaluation,task achievement</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866231</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="BART">
      <data key="d6">9.0</data>
      <data key="d7">BART is utilized as the generative component in the retrieval-augmented generation framework, enhancing language generation tasks.</data>
      <data key="d8">framework component,model integration</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866232</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="Dense Passage Retriever">
      <data key="d6">10.0</data>
      <data key="d7">The Dense Passage Retriever is a key component in the RAG architecture, providing essential input for generating outputs.</data>
      <data key="d8">model functionality,retriever role</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866233</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="MS-MARCO">
      <data key="d6">8.0</data>
      <data key="d7">RAG models are used for experiments in generating responses based on the MS-MARCO dataset, highlighting their versatility in question generation.</data>
      <data key="d8">dataset application,knowledge generation</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866234</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG)" target="Jeopardy">
      <data key="d6">7.0</data>
      <data key="d7">RAG models are applied to generate responses for Jeopardy questions, demonstrating their knowledge-intensive capabilities.</data>
      <data key="d8">application scenario,knowledge demonstration</data>
      <data key="d9">chunk-be11ff19951a5da380ec7c57e9d0f774</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866235</data>
    </edge>
    <edge source="Wikipedia" target="RAG Models">
      <data key="d6">9.0</data>
      <data key="d7">RAG Models are designed to utilize factual knowledge from Wikipedia, enhancing the generation's reliability and accuracy.</data>
      <data key="d8">factual accuracy,knowledge base</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866250</data>
    </edge>
    <edge source="Wikipedia" target="RAG-Sequence Model">
      <data key="d6">8.0</data>
      <data key="d7">The RAG-Sequence Model can utilize Wikipedia as an external knowledge source during text generation to improve the context and accuracy of generated responses.</data>
      <data key="d8">knowledge integration,textual enhancement</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866494</data>
    </edge>
    <edge source="Wikipedia" target="RAG-Sequence Probability Equation (equation)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Wikipedia belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866498</data>
    </edge>
    <edge source="Natural Questions" target="DPR">
      <data key="d6">7.0</data>
      <data key="d7">DPR was trained to retrieve documents containing answers for the Natural Questions dataset, demonstrating its application in real tasks.</data>
      <data key="d8">dataset application,training context</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866234</data>
    </edge>
    <edge source="Natural Questions" target="RAG">
      <data key="d6">9.0</data>
      <data key="d7">RAG is tested and evaluated using the Natural Questions dataset to assess its question answering capabilities.</data>
      <data key="d8">dataset usage,model evaluation</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866235</data>
    </edge>
    <edge source="Natural Questions" target="RAG Models">
      <data key="d6">8.0</data>
      <data key="d7">The RAG models are trained using the Natural Questions dataset to improve their performance in question answering tasks.</data>
      <data key="d8">model improvement,training dataset</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866244</data>
    </edge>
    <edge source="Natural Questions" target="Tom Kwiatkowski">
      <data key="d6">8.0</data>
      <data key="d7">Tom Kwiatkowski is a contributing author to the benchmark paper 'Natural Questions' where question answering is discussed.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866264</data>
    </edge>
    <edge source="Natural Questions" target="Jennimaria Palomaki">
      <data key="d6">8.0</data>
      <data key="d7">Jennimaria Palomaki has contributed to the research document 'Natural Questions,' which focuses on question answering challenges.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866265</data>
    </edge>
    <edge source="Natural Questions" target="Olivia Redfield">
      <data key="d6">8.0</data>
      <data key="d7">Olivia Redfield contributed to the research paper 'Natural Questions' that benchmarks question answering techniques.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866266</data>
    </edge>
    <edge source="Natural Questions" target="Michael Collins">
      <data key="d6">8.0</data>
      <data key="d7">Michael Collins is a co-author on the research document 'Natural Questions,' which serves as a benchmark in the field.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866267</data>
    </edge>
    <edge source="Natural Questions" target="Ankur Parikh">
      <data key="d6">8.0</data>
      <data key="d7">Ankur Parikh is an author of the benchmark paper 'Natural Questions' focusing on question answering research.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866268</data>
    </edge>
    <edge source="Natural Questions" target="Chris Alberti">
      <data key="d6">8.0</data>
      <data key="d7">Chris Alberti is noted as a contributor to the work encompassed by 'Natural Questions' benchmark paper.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866270</data>
    </edge>
    <edge source="Natural Questions" target="Danielle Epstein">
      <data key="d6">8.0</data>
      <data key="d7">Danielle Epstein is listed among the authors who developed the 'Natural Questions' benchmark paper.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866270</data>
    </edge>
    <edge source="Natural Questions" target="Illia Polosukhin">
      <data key="d6">8.0</data>
      <data key="d7">Illia Polosukhin is involved as an author in the creation of the benchmark paper 'Natural Questions'.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866271</data>
    </edge>
    <edge source="Natural Questions" target="Matthew Kelcey">
      <data key="d6">8.0</data>
      <data key="d7">Matthew Kelcey co-authored 'Natural Questions,' contributing to question answering research.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866274</data>
    </edge>
    <edge source="Natural Questions" target="Jacob Devlin">
      <data key="d6">8.0</data>
      <data key="d7">Jacob Devlin is associated with the research documented in 'Natural Questions,' a benchmark for question answering.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866275</data>
    </edge>
    <edge source="Natural Questions" target="Kristina N. Toutanova">
      <data key="d6">8.0</data>
      <data key="d7">Kristina N. Toutanova's research is featured in the benchmark paper 'Natural Questions' focused on question answering systems.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866276</data>
    </edge>
    <edge source="Natural Questions" target="Llion Jones">
      <data key="d6">8.0</data>
      <data key="d7">Llion Jones is one of the authors contributing to the 'Natural Questions' benchmark for question answering research.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866277</data>
    </edge>
    <edge source="Natural Questions" target="Ming-Wei Chang">
      <data key="d6">8.0</data>
      <data key="d7">Ming-Wei Chang co-authored the benchmark paper 'Natural Questions,' contributing to the field of question answering.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866278</data>
    </edge>
    <edge source="Natural Questions" target="Andrew Dai">
      <data key="d6">8.0</data>
      <data key="d7">Andrew Dai is involved in the authorship of the 'Natural Questions' benchmark focusing on question answering.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866279</data>
    </edge>
    <edge source="Natural Questions" target="Jakob Uszkoreit">
      <data key="d6">8.0</data>
      <data key="d7">Jakob Uszkoreit contributed to the research within the context of the benchmark 'Natural Questions.'</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866280</data>
    </edge>
    <edge source="Natural Questions" target="Quoc Le">
      <data key="d6">8.0</data>
      <data key="d7">Quoc Le is noted as a contributor among the authors of 'Natural Questions' paper.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866282</data>
    </edge>
    <edge source="Natural Questions" target="Slav Petrov">
      <data key="d6">8.0</data>
      <data key="d7">Slav Petrov is a co-author of the benchmark paper 'Natural Questions' for question answering research.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866283</data>
    </edge>
    <edge source="Natural Questions" target="ArXiv">
      <data key="d6">9.0</data>
      <data key="d7">ArXiv is a platform hosting the benchmark paper 'Natural Questions,' relevant to question answering research.</data>
      <data key="d8">academic repository,research publication</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866284</data>
    </edge>
    <edge source="Natural Questions" target="TriviaQA">
      <data key="d6">15.0</data>
      <data key="d7">Both TriviaQA and Natural Questions are datasets used for training and evaluating open-domain QA models.&lt;SEP&gt;TriviaQA features more test instances than training instances, which is a notable characteristic compared to Natural Questions.</data>
      <data key="d8">QA training,data evaluation,dataset evaluation strategy,training vs testing</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866636</data>
    </edge>
    <edge source="Natural Questions" target="MS-MARCO">
      <data key="d6">8.0</data>
      <data key="d7">Natural Questions and MS-MARCO are both datasets used for training in open-domain QA tasks, highlighting different dataset sizes and complexities.</data>
      <data key="d8">QA performance,dataset comparison</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866634</data>
    </edge>
    <edge source="Natural Questions" target="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Natural Questions belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866638</data>
    </edge>
    <edge source="WebQuestions" target="RAG">
      <data key="d6">9.0</data>
      <data key="d7">WebQuestions is utilized as a dataset for assessing the performance of the RAG model in question answering tasks.</data>
      <data key="d8">dataset usage,model evaluation</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866238</data>
    </edge>
    <edge source="WebQuestions" target="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity WebQuestions belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866641</data>
    </edge>
    <edge source="CuratedTrec" target="RAG">
      <data key="d6">9.0</data>
      <data key="d7">RAG uses the CuratedTrec dataset as part of its evaluation for open-domain question answering performance.</data>
      <data key="d8">dataset usage,model evaluation</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866239</data>
    </edge>
    <edge source="CuratedTrec" target="TriviaQA">
      <data key="d6">7.0</data>
      <data key="d7">CuratedTrec and TriviaQA involve similar processes for handling answer annotations for question-answering tasks.</data>
      <data key="d8">annotation,data processing</data>
      <data key="d9">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866339</data>
    </edge>
    <edge source="CuratedTrec" target="MS-MARCO">
      <data key="d6">9.0</data>
      <data key="d7">MS-MARCO has the highest number of training instances while CuratedTrec has the lowest, showing the diversity in dataset sizes.</data>
      <data key="d8">QA dataset size,dataset disparity</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866636</data>
    </edge>
    <edge source="CuratedTrec" target="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity CuratedTrec belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866642</data>
    </edge>
    <edge source="BART" target="RAG-Sequence Model">
      <data key="d6">17.0</data>
      <data key="d7">The RAG-Sequence Model uses BART as its generator component to produce sequences based on retrieved documents.&lt;SEP&gt;BART implements the RAG-Sequence Model's concepts, enhancing its generative capacities by utilizing retrieval-augmented techniques.</data>
      <data key="d8">application in AI,generation process,model dependency,model synergy</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38&lt;SEP&gt;chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866498</data>
    </edge>
    <edge source="BART" target="RAG-Token Model">
      <data key="d6">8.0</data>
      <data key="d7">The RAG-Token Model employs BART for generating tokens based on multiple retrieved documents, allowing for diverse responses.</data>
      <data key="d8">generation process,model dependency</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866234</data>
    </edge>
    <edge source="BART" target="RAG">
      <data key="d6">27.0</data>
      <data key="d7">BART is integrated into the RAG model for generating answers and completing text based on input queries.&lt;SEP&gt;RAG outperforms BART in various tasks, indicating a competitive relationship between the two models in the area of question answering and document generation.&lt;SEP&gt;RAG has been evaluated against BART, with RAG demonstrating significantly better scores in factuality and specificity.</data>
      <data key="d8">model comparison,model function,performance,performance superiority,text generation</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-9602588f9a41c6c9eaeca67413aaf7ae&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866580</data>
    </edge>
    <edge source="BART" target="Adam">
      <data key="d6">6.0</data>
      <data key="d7">Adam is used for optimizing BART during its training phase in the RAG framework.</data>
      <data key="d8">model performance,training optimization</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866244</data>
    </edge>
    <edge source="BART" target="Open MS-MARCO NLG">
      <data key="d6">8.0</data>
      <data key="d7">BART is evaluated against the Open MS-MARCO NLG task as a benchmark for natural language generation performance.</data>
      <data key="d8">evaluation benchmark,performance comparison</data>
      <data key="d9">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866247</data>
    </edge>
    <edge source="BART" target="GLUE benchmarks">
      <data key="d6">9.0</data>
      <data key="d7">BART is noted for achieving strong results across tasks in the GLUE benchmarks, indicating its effectiveness as a language model.</data>
      <data key="d8">performance evaluation,task effectiveness</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866249</data>
    </edge>
    <edge source="BART" target="T5">
      <data key="d6">8.0</data>
      <data key="d7">T5 and BART are both pre-trained encoder-decoder models that leverage bi-directional attention to enhance performance on NLP tasks.</data>
      <data key="d8">model comparison,performance enhancement</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866250</data>
    </edge>
    <edge source="BART" target="AG-Sequence">
      <data key="d6">7.0</data>
      <data key="d7">AG-Sequence is asserted to be more diverse than BART, which relies on diversity-promoting decoding methods.</data>
      <data key="d8">decoding method,diversity comparison</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866251</data>
    </edge>
    <edge source="BART" target="RAG-Sequence Probability Equation (equation)">
      <data key="d6">10.0</data>
      <data key="d7">Entity BART belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866503</data>
    </edge>
    <edge source="BART" target="RAG-Token">
      <data key="d6">17.0</data>
      <data key="d7">RAG-Token outperforms BART on Jeopardy in terms of question generation accuracy, indicating a direct comparison between the two models.&lt;SEP&gt;RAG-Token showed improvements over BART in generating diverse outputs, indicating a better performance overall.</data>
      <data key="d8">benchmark comparison,diversity enhancement,model comparison,model performance</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866544</data>
    </edge>
    <edge source="BART" target="RAG Performance Results Table (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity BART belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866549</data>
    </edge>
    <edge source="BART" target="RAG Models">
      <data key="d6">9.0</data>
      <data key="d7">RAG Models are compared against BART to assess the accuracy and specificity of their generated responses.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866565</data>
    </edge>
    <edge source="BART" target="Comparative Model Generations for Question Answering (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity BART belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866571</data>
    </edge>
    <edge source="BART" target="Jeopardy Question Generation Task">
      <data key="d6">8.0</data>
      <data key="d7">The Jeopardy Question Generation Task assesses the performance of BART in generating questions based on provided data.</data>
      <data key="d8">performance analysis,question generation</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866578</data>
    </edge>
    <edge source="BART" target="Table 4">
      <data key="d6">9.0</data>
      <data key="d7">Table 4 provides assessments that indicate BART's lower performance relative to RAG in factuality and specificity.</data>
      <data key="d8">performance metrics,statistical comparison</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866583</data>
    </edge>
    <edge source="BART" target="Factuality">
      <data key="d6">7.0</data>
      <data key="d7">BART scored 7.1% in factuality according to Table 4, indicating its perceived accuracy in the assessments.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866585</data>
    </edge>
    <edge source="BART" target="Specificity">
      <data key="d6">7.0</data>
      <data key="d7">BART scored 16.8% in specificity according to Table 4, illustrating its level of detail in outputs.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866588</data>
    </edge>
    <edge source="BART" target="Human Assessments for Jeopardy Question Generation (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity BART belongs to Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866593</data>
    </edge>
    <edge source="BART" target="Jeopardy QGen">
      <data key="d6">7.0</data>
      <data key="d7">BART's lower performance in Jeopardy QGen indicates its lack of diversity in output generation for this task.</data>
      <data key="d8">output diversity,performance analysis</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866595</data>
    </edge>
    <edge source="BART" target="RAG-Sequence">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Sequence indicated notable enhancements in diversity compared to BART, particularly in the evaluated tasks.</data>
      <data key="d8">model comparison,performance enhancement</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866598</data>
    </edge>
    <edge source="BART" target="Performance Metrics">
      <data key="d6">7.0</data>
      <data key="d7">BART's performance metrics indicate a lack of diversity in its generated outputs, particularly highlighted in the Jeopardy QGen task.</data>
      <data key="d8">output diversity,performance analysis</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866600</data>
    </edge>
    <edge source="BART" target="Tri-gram Diversity Ratios in Generation Tasks (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity BART belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866601</data>
    </edge>
    <edge source="T5" target="GPT-2">
      <data key="d6">7.0</data>
      <data key="d7">GPT-2 demonstrates ability in generative tasks while T5 focuses on a broad range of tasks, showcasing differences in capabilities.</data>
      <data key="d8">model capabilities,performance comparison</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866249</data>
    </edge>
    <edge source="T5" target="Open-Domain QA Tasks">
      <data key="d6">8.0</data>
      <data key="d7">T5 serves as a benchmark model within Open-Domain QA Tasks, allowing for performance comparison against newer models like RAG.</data>
      <data key="d8">comparative analysis,model benchmark</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866533</data>
    </edge>
    <edge source="T5" target="NQ">
      <data key="d6">8.0</data>
      <data key="d7">T5's scores in the NQ metric serve as a baseline for comparing the performance of retrieval-augmented models like RAG.</data>
      <data key="d8">benchmark,comparative analysis</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866538</data>
    </edge>
    <edge source="T5" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity T5 belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866542</data>
    </edge>
    <edge source="MS-MARCO" target="Jeopardy">
      <data key="d6">7.0</data>
      <data key="d7">Both Jeopardy and MS-MARCO are benchmark tasks that assess models in their ability to generate relevant outputs based on provided queries.</data>
      <data key="d8">benchmark tasks,performance evaluation</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866545</data>
    </edge>
    <edge source="MS-MARCO" target="RAG Performance Results Table (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity MS-MARCO belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866551</data>
    </edge>
    <edge source="MS-MARCO" target="RAG Models">
      <data key="d6">8.0</data>
      <data key="d7">RAG Models provide answers to tasks like MS-MARCO, showing their effectiveness in generating accurate content.</data>
      <data key="d8">model efficacy,task performance</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866566</data>
    </edge>
    <edge source="MS-MARCO" target="Table 3">
      <data key="d6">8.0</data>
      <data key="d7">Table 3 provides examples related to the MS-MARCO task, showing the output from different models in response to similar queries.</data>
      <data key="d8">model outputs,task examples</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866567</data>
    </edge>
    <edge source="MS-MARCO" target="Comparative Model Generations for Question Answering (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity MS-MARCO belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866572</data>
    </edge>
    <edge source="MS-MARCO" target="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity MS-MARCO belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866644</data>
    </edge>
    <edge source="Jeopardy" target="RAG">
      <data key="d6">9.0</data>
      <data key="d7">RAG models are specifically designed to generate questions and answers, making them applicable to generating content in Jeopardy-style formats.</data>
      <data key="d8">content generation,quiz format</data>
      <data key="d9">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866248</data>
    </edge>
    <edge source="Jeopardy" target="RAG-Token">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Token is effective for generating responses in formats similar to those used in Jeopardy, showing its applicability to quiz formats.</data>
      <data key="d8">content generation,quiz format</data>
      <data key="d9">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866249</data>
    </edge>
    <edge source="Jeopardy" target="Question Generation Systems">
      <data key="d6">6.0</data>
      <data key="d7">Advancements in Question Generation Systems are linked to their performance in Jeopardy, influencing the effectiveness of QA tasks.</data>
      <data key="d8">QA methodologies,performance enhancement</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866546</data>
    </edge>
    <edge source="Jeopardy" target="RAG Performance Results Table (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866550</data>
    </edge>
    <edge source="DPR" target="RAG-Sequence Model">
      <data key="d6">9.0</data>
      <data key="d7">DPR serves as the retrieval component for the RAG-Sequence model, providing necessary documents for generation.</data>
      <data key="d8">information retrieval,model integration</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866232</data>
    </edge>
    <edge source="DPR" target="RAG-Token Model">
      <data key="d6">9.0</data>
      <data key="d7">DPR also functions in conjunction with the RAG-Token model to supply documents necessary for generating outputs.</data>
      <data key="d8">information retrieval,model integration</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866233</data>
    </edge>
    <edge source="DPR" target="TriviaQA">
      <data key="d6">7.0</data>
      <data key="d7">DPR has also been trained to retrieve documents for the TriviaQA dataset, showing its versatility in question-answering systems.</data>
      <data key="d8">dataset application,training context</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866235</data>
    </edge>
    <edge source="DPR" target="Non-Parametric Memory">
      <data key="d6">7.0</data>
      <data key="d7">DPR initializes its retrieval process using Non-Parametric Memory, creating a database of documents for querying.</data>
      <data key="d8">information storage,retrieval basis</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866236</data>
    </edge>
    <edge source="DPR" target="BERT-base">
      <data key="d6">9.0</data>
      <data key="d7">DPR uses the BERT-base model's embeddings to encode queries and passages for effective retrieval.</data>
      <data key="d8">information retrieval,model integration</data>
      <data key="d9">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866339</data>
    </edge>
    <edge source="DPR" target="Open-Domain QA Tasks">
      <data key="d6">7.0</data>
      <data key="d7">DPR is compared within Open-Domain QA Tasks, revealing its capabilities in retrieval-augmented QA against RAG models.</data>
      <data key="d8">model assessment,performance evaluation</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866535</data>
    </edge>
    <edge source="DPR" target="TQA">
      <data key="d6">7.0</data>
      <data key="d7">DPR's efficacy is evaluated within the TQA test set, demonstrating its functionality in answering domain-specific questions.</data>
      <data key="d8">evaluation metrics,model performance</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866538</data>
    </edge>
    <edge source="DPR" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity DPR belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866546</data>
    </edge>
    <edge source="RAG-Sequence Model" target="Latent Variable">
      <data key="d6">6.0</data>
      <data key="d7">RAG-Sequence Model utilizes Latent Variable concepts to manage document retrieval during text generation.</data>
      <data key="d8">model framework,processing concept</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866234</data>
    </edge>
    <edge source="RAG-Sequence Model" target="Top-K Documents">
      <data key="d6">8.0</data>
      <data key="d7">The RAG-Sequence Model retrieves Top-K Documents to generate the target sequence for improved accuracy.</data>
      <data key="d8">performance improvement,retrieval process</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866236</data>
    </edge>
    <edge source="RAG-Sequence Model" target="Natural Language Processing (NLP)">
      <data key="d6">9.0</data>
      <data key="d7">The RAG-Sequence Model is a framework that operates within the field of Natural Language Processing, enhancing the capabilities for sequence generation based on context.</data>
      <data key="d8">NLP framework,model application</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866493</data>
    </edge>
    <edge source="RAG-Sequence Model" target="Bayesian Principles">
      <data key="d6">7.0</data>
      <data key="d7">The RAG-Sequence Model applies Bayesian principles to derive probabilities and infer relationships between input and output sequences.</data>
      <data key="d8">inference method,probabilistic modeling</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866495</data>
    </edge>
    <edge source="RAG-Sequence Model" target="Markov Processes">
      <data key="d6">7.0</data>
      <data key="d7">The RAG-Sequence Model's autoregressive nature aligns with the principles of Markov processes, making use of current state predictions for sequence generation.</data>
      <data key="d8">probabilistic foundations,sequence prediction</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866497</data>
    </edge>
    <edge source="RAG-Sequence Model" target="RAG-Sequence Probability Equation (equation)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence Model belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866502</data>
    </edge>
    <edge source="RAG-Token Model" target="Stochastic Gradient Descent">
      <data key="d6">7.0</data>
      <data key="d7">The RAG-Token Model uses Stochastic Gradient Descent to optimize the training process, reducing overall prediction error.</data>
      <data key="d8">optimization,training method</data>
      <data key="d9">chunk-0c4d1e9cd488cf919d40a859d03c9295</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866235</data>
    </edge>
    <edge source="TriviaQA" target="RAG">
      <data key="d6">9.0</data>
      <data key="d7">RAG employs TriviaQA for evaluating its performance in generating answers to questions from the dataset.</data>
      <data key="d8">dataset usage,model evaluation</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866236</data>
    </edge>
    <edge source="TriviaQA" target="Kelvin Guu">
      <data key="d6">8.0</data>
      <data key="d7">Kelvin Guu is associated with the research of the TriviaQA dataset aimed at improving reading comprehension tasks through distant supervision.</data>
      <data key="d8">dataset development,research contribution</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866263</data>
    </edge>
    <edge source="TriviaQA" target="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity TriviaQA belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866639</data>
    </edge>
    <edge source="Stochastic Gradient Descent" target="BERT">
      <data key="d6">6.0</data>
      <data key="d7">BERT's training process involves Stochastic Gradient Descent for optimizing model performance.</data>
      <data key="d8">optimization,training process</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866243</data>
    </edge>
    <edge source="RAG" target="FAISS">
      <data key="d6">17.0</data>
      <data key="d7">FAISS is used by RAG to build a single MIPS index for efficient retrieval during question answering tasks.&lt;SEP&gt;RAG models utilize FAISS for efficient storing and searching of document index vectors during training.</data>
      <data key="d8">model performance,model training,retrieval efficiency,vector search</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866241</data>
    </edge>
    <edge source="RAG" target="BERT">
      <data key="d6">8.0</data>
      <data key="d7">RAG utilizes BERT as a document encoder, impacting how queries are processed and embeddings are produced.</data>
      <data key="d8">model integration,processing framework</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866242</data>
    </edge>
    <edge source="RAG" target="RAG-Sequence">
      <data key="d6">15.0</data>
      <data key="d7">RAG-Sequence is a variant of RAG that focuses on a specific decoding approach for generating responses during question answering.&lt;SEP&gt;RAG-Sequence is a part of the RAG model family, designed to improve performance on NLG tasks.</data>
      <data key="d8">decoding method,model development,model variant,performance enhancement</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866244</data>
    </edge>
    <edge source="RAG" target="RAG-Token">
      <data key="d6">23.0</data>
      <data key="d7">RAG-Token is a variant of RAG, highlighting a distinct approach to autoregressive text generation.&lt;SEP&gt;RAG-Token is another variant of RAG aimed at question generation, indicating a relationship within model innovations.&lt;SEP&gt;RAG's retrieval mechanism aims to enhance results in tasks where RAG-Token is involved, showing a relationship in model improvement.</data>
      <data key="d8">generation method,model comparison,model improvement,model variant,question generation,retrieval mechanism</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866245</data>
    </edge>
    <edge source="RAG" target="FEVER">
      <data key="d6">24.0</data>
      <data key="d7">RAG is evaluated using the FEVER framework to assess its effectiveness in fact verification tasks.&lt;SEP&gt;The performance benefits seen in FEVER claims are indicative of RAG's capability to enhance retrieval tasks.&lt;SEP&gt;The FEVER task is one of the areas RAG models are applied for, focusing on classification based on evidence extraction.</data>
      <data key="d8">evaluation method,evidence-based classification,fact verification,performance enhancement,task application,task relationship</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921&lt;SEP&gt;chunk-d3fd620aa30bf6560c0452e3e22a5b82&lt;SEP&gt;chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866246</data>
    </edge>
    <edge source="RAG" target="DrQA">
      <data key="d6">8.0</data>
      <data key="d7">DrQA is used as a foundation for RAG to build an index for efficient retrieval from Wikipedia, indicating a collaborative function.</data>
      <data key="d8">index building,retrieval collaboration</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866249</data>
    </edge>
    <edge source="RAG" target="Open-Domain QA">
      <data key="d6">9.0</data>
      <data key="d7">RAG's retrieval capabilities are crucial for improving outcomes in Open-Domain QA tasks, showcasing a direct application of the model.</data>
      <data key="d8">retrieval application,task performance</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866250</data>
    </edge>
    <edge source="RAG" target="Parameter-Only Models">
      <data key="d6">9.0</data>
      <data key="d7">RAG is contrasted with parameter-only models that need additional training to adapt, highlighting RAG's flexibility in updating knowledge.</data>
      <data key="d8">knowledge update,model flexibility</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866251</data>
    </edge>
    <edge source="RAG" target="Latent Variable Approach">
      <data key="d6">7.0</data>
      <data key="d7">The latent variable approach is identified as one of the optimization techniques for enhancing the retrieval component in the RAG model.</data>
      <data key="d8">optimization technique,retrieval improvement</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866252</data>
    </edge>
    <edge source="RAG" target="BART-large">
      <data key="d6">9.0</data>
      <data key="d7">BART-large is part of RAG's architecture, contributing to its capabilities in generating answers based on retrieved data.</data>
      <data key="d8">answer generation,architecture component</data>
      <data key="d9">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866339</data>
    </edge>
    <edge source="RAG" target="NULL Document">
      <data key="d6">7.0</data>
      <data key="d7">The NULL document mechanism is designed for RAG to address scenarios where no relevant documents are retrieved.</data>
      <data key="d8">information retrieval,mechanism design</data>
      <data key="d9">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866340</data>
    </edge>
    <edge source="RAG" target="BERT-base">
      <data key="d6">9.0</data>
      <data key="d7">RAG incorporates BERT-base for encoding input queries as part of its retrieval mechanism.</data>
      <data key="d8">input processing,retrieval mechanism</data>
      <data key="d9">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866341</data>
    </edge>
    <edge source="RAG" target="Jeopardy Question Generation Task">
      <data key="d6">9.0</data>
      <data key="d7">The Jeopardy Question Generation Task assesses the performance of RAG, which shows superior results compared to BART.</data>
      <data key="d8">performance analysis,question generation</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866579</data>
    </edge>
    <edge source="RAG" target="Table 4">
      <data key="d6">9.0</data>
      <data key="d7">Table 4 highlights RAG's superior performance metrics as compared to BART in the context of the Jeopardy Question Generation Task.</data>
      <data key="d8">performance metrics,statistical comparison</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866582</data>
    </edge>
    <edge source="RAG" target="Factuality">
      <data key="d6">9.0</data>
      <data key="d7">RAG scored 42.7% in factuality as shown in Table 4, significantly higher than BART's score.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866583</data>
    </edge>
    <edge source="RAG" target="Specificity">
      <data key="d6">9.0</data>
      <data key="d7">RAG scored 37.4% in specificity, indicating a detailed output generation compared to BART's smaller percentage.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866586</data>
    </edge>
    <edge source="RAG" target="Human Assessments for Jeopardy Question Generation (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG belongs to Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866588</data>
    </edge>
    <edge source="BERT" target="Hierarchical Neural Story Generation">
      <data key="d6">7.0</data>
      <data key="d7">BERT is often discussed in relation to advancements in neural story generation techniques."|&gt;"AI technology, language models</data>
      <data key="d8">7</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866254</data>
    </edge>
    <edge source="BERT" target="document z">
      <data key="d6">8.0</data>
      <data key="d7">BERT is responsible for generating the dense vector representation of document z for retrieval tasks.</data>
      <data key="d8">NLP model,vector representation</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866510</data>
    </edge>
    <edge source="BERT" target="input query x">
      <data key="d6">8.0</data>
      <data key="d7">BERT is used to generate the dense vector representation of the input query x for processing in retrieval systems.</data>
      <data key="d8">NLP model,query representation</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866512</data>
    </edge>
    <edge source="BERT" target="Retrieval-Augmented Generation (RAG) model">
      <data key="d6">7.0</data>
      <data key="d7">The RAG model leverages BERT for document retrieval and generation, integrating its representations into the process.</data>
      <data key="d8">document retrieval,model integration</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866513</data>
    </edge>
    <edge source="BERT" target="Conditional Document Retrieval Probability (equation)">
      <data key="d6">10.0</data>
      <data key="d7">Entity BERT belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866515</data>
    </edge>
    <edge source="RAG-Sequence" target="Open MS-MARCO NLG">
      <data key="d6">9.0</data>
      <data key="d7">RAG-Sequence outperforms BART on the Open MS-MARCO NLG task, indicating its competitive capabilities in text generation.</data>
      <data key="d8">NLG task,performance metrics</data>
      <data key="d9">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866246</data>
    </edge>
    <edge source="RAG-Sequence" target="Open-Domain QA Tasks">
      <data key="d6">9.0</data>
      <data key="d7">RAG-Sequence is analyzed in the context of Open-Domain QA Tasks, achieving high scores that highlight its effectiveness in generative capabilities.</data>
      <data key="d8">model assessment,performance evaluation</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866531</data>
    </edge>
    <edge source="RAG-Sequence" target="RAG-Token">
      <data key="d6">26.0</data>
      <data key="d7">Both RAG-Token and RAG-Sequence are retrieval-augmented generation models that achieved top scores in the same open-domain QA tasks, indicating their related methodologies.&lt;SEP&gt;RAG-Sequence demonstrates a trend of outperforming traditional models like RAG-Token in question generation tasks.&lt;SEP&gt;Both RAG models showcase the effectiveness of retrieval-augmented architectures in generating diverse outputs.</data>
      <data key="d8">architecture advantage,model comparison,model effectiveness,model performance,performance synergy,retrieval advantage</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9&lt;SEP&gt;chunk-e677e8584c8111e2fbb38897fae32287&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866534</data>
    </edge>
    <edge source="RAG-Sequence" target="TQA">
      <data key="d6">17.0</data>
      <data key="d7">RAG-Sequence shows competitive performance in the TQA metric, indicating its efficacy in answering questions accurately.&lt;SEP&gt;RAG-Sequence also performs well in the TQA task, demonstrating its capability in trivia question answering.</data>
      <data key="d8">efficiency,evaluation metrics,model performance,task performance</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866536</data>
    </edge>
    <edge source="RAG-Sequence" target="NQ">
      <data key="d6">17.0</data>
      <data key="d7">RAG-Sequence achieved an impressive score of 44.5 in the NQ metric, showcasing its strength in providing correct answers in open-domain QA tasks.&lt;SEP&gt;RAG-Sequence shows high performance specifically in the NQ task, illustrating its efficacy in handling natural questions.</data>
      <data key="d8">efficiency,model evaluation,performance metric,task performance</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98&lt;SEP&gt;chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866537</data>
    </edge>
    <edge source="RAG-Sequence" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866539</data>
    </edge>
    <edge source="RAG-Sequence" target="RAG Performance Results Table (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866554</data>
    </edge>
    <edge source="RAG-Sequence" target="Performance Metrics">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Sequence's performance metrics indicate significant improvements in diversity when compared to BART and show robust output generation.</data>
      <data key="d8">model comparison,performance enhancement</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866592</data>
    </edge>
    <edge source="RAG-Sequence" target="Tri-gram Diversity Ratios in Generation Tasks (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866597</data>
    </edge>
    <edge source="RAG-Sequence" target="RAG-Sequence-BM25">
      <data key="d6">15.0</data>
      <data key="d7">RAG-Sequence-BM25 is a model variant of RAG-Sequence, indicating a direct relationship in performance evaluation studies.&lt;SEP&gt;RAG-Sequence serves as a general model framework which includes the RAG-Sequence-BM25 variant for performance assessment."|&gt;"model framework</data>
      <data key="d8">7,model variant,performance assessment</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866599</data>
    </edge>
    <edge source="RAG-Sequence" target="WQ">
      <data key="d6">8.0</data>
      <data key="d7">The RAG-Sequence model's performance metrics in WQ showcase its robustness in processing web-based questions.</data>
      <data key="d8">efficiency,task performance</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866600</data>
    </edge>
    <edge source="RAG-Sequence" target="CT">
      <data key="d6">9.0</data>
      <data key="d7">RAG-Sequence achieves significant scores in the CT task, reflecting its proficiency in completion type queries.</data>
      <data key="d8">efficiency,task performance</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866602</data>
    </edge>
    <edge source="RAG-Sequence" target="Jeopardy-QGen">
      <data key="d6">9.0</data>
      <data key="d7">RAG-Sequence's metrics extend to Jeopardy-QGen, indicating its diverse applicability in question generation tasks.</data>
      <data key="d8">efficiency,task performance</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866603</data>
    </edge>
    <edge source="RAG-Sequence" target="MSMarco">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Sequence's performance is evaluated using MSMarco, highlighting its relevance in contemporary NLP challenges.</data>
      <data key="d8">benchmark evaluation,task relevance</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866605</data>
    </edge>
    <edge source="RAG-Sequence" target="RAG-Sequence-Frozen">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Sequence-Frozen is a specific configuration of the RAG-Sequence model, demonstrating a relationship between the two in terms of performance metrics."|&gt;"model variant</data>
      <data key="d8">8</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866606</data>
    </edge>
    <edge source="RAG-Sequence" target="Model Performance Comparison Table for RAG-based Architectures (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866613</data>
    </edge>
    <edge source="RAG-Token" target="AG-Sequence">
      <data key="d6">8.0</data>
      <data key="d7">AG-Sequence's generations are more diverse than RAG-Token's, pointing to differences in their performance and decoding processes.</data>
      <data key="d8">diversity comparison,performance metrics</data>
      <data key="d9">chunk-e08c0b053c99ea6a92ea4f3beba5f921</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866248</data>
    </edge>
    <edge source="RAG-Token" target="Open-Domain QA Tasks">
      <data key="d6">9.0</data>
      <data key="d7">RAG-Token's performance is assessed within the framework of Open-Domain QA Tasks, where it excels in scoring, particularly in the NQ metric.</data>
      <data key="d8">model assessment,performance evaluation</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866530</data>
    </edge>
    <edge source="RAG-Token" target="NQ">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Token achieved a notable score of 44.1 in the NQ metric, highlighting its effectiveness in answering questions accurately.</data>
      <data key="d8">model evaluation,performance metric</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866535</data>
    </edge>
    <edge source="RAG-Token" target="TQA">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Token's performance in the TQA test set reflects its robustness in open-domain question answering tasks.</data>
      <data key="d8">evaluation metrics,model performance</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866537</data>
    </edge>
    <edge source="RAG-Token" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Token belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866538</data>
    </edge>
    <edge source="RAG-Token" target="RAG Performance Results Table (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Token belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866548</data>
    </edge>
    <edge source="RAG-Token" target="Distinction Ratio">
      <data key="d6">8.0</data>
      <data key="d7">The distinction ratio for RAG-Token suggests a higher level of output diversity compared to BART.</data>
      <data key="d8">model evaluation,output diversity</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866591</data>
    </edge>
    <edge source="RAG-Token" target="Tri-gram Diversity Ratios in Generation Tasks (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Token belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866596</data>
    </edge>
    <edge source="RAG-Token" target="RAG-Token-Frozen">
      <data key="d6">7.0</data>
      <data key="d7">RAG-Token-Frozen is a variant of the RAG-Token model, indicating a relationship in terms of performance evaluation."|&gt;"model variant</data>
      <data key="d8">7</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866600</data>
    </edge>
    <edge source="RAG-Token" target="RAG-Token-BM25">
      <data key="d6">6.0</data>
      <data key="d7">RAG-Token is evaluated for its performance alongside RAG-Token-BM25, showing a relationship in comparative analysis."|&gt;"model comparison</data>
      <data key="d8">6</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866601</data>
    </edge>
    <edge source="RAG-Token" target="Model Performance Comparison Table for RAG-based Architectures (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Token belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866617</data>
    </edge>
    <edge source="MIPS" target="Document Encoder">
      <data key="d6">8.0</data>
      <data key="d7">The Document Encoder uses MIPS for efficient retrieval of documents in the RAG model framework.</data>
      <data key="d8">efficiency,retrieval mechanism</data>
      <data key="d9">chunk-2a058689f396f9948869181b4e35d86b</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866241</data>
    </edge>
    <edge source="RAG Models" target="MSMARCO NLG task v2.1">
      <data key="d6">8.0</data>
      <data key="d7">RAG Models are evaluated using the MSMARCO NLG task v2.1 to test their natural language generation capabilities in a knowledge-intensive setting.</data>
      <data key="d8">evaluation,performance testing</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866242</data>
    </edge>
    <edge source="RAG Models" target="FEVER">
      <data key="d6">9.0</data>
      <data key="d7">The RAG models are explored for their ability to handle classification tasks, such as those presented in the FEVER event.</data>
      <data key="d8">fact verification,model capability</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866243</data>
    </edge>
    <edge source="RAG Models" target="TQA Wiki test set">
      <data key="d6">7.0</data>
      <data key="d7">The performance of RAG Models is evaluated on the TQA Wiki test set, contributing to understanding their effectiveness in QA tasks.</data>
      <data key="d8">evaluation metric,model assessment</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866245</data>
    </edge>
    <edge source="RAG Models" target="Jeopardy Question Generation">
      <data key="d6">7.0</data>
      <data key="d7">RAG Models are studied for their capabilities in the Jeopardy Question Generation task, expanding their application in question formulation.</data>
      <data key="d8">model capabilities,task application</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866247</data>
    </edge>
    <edge source="RAG Models" target="Open-Domain QA Tasks">
      <data key="d6">9.0</data>
      <data key="d7">RAG Models are designed to handle Open-Domain QA Tasks effectively, showcasing their versatility in various question-answering contexts.</data>
      <data key="d8">application area,model versatility</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866248</data>
    </edge>
    <edge source="RAG Models" target="Parametric Knowledge">
      <data key="d6">8.0</data>
      <data key="d7">RAG Models leverage parametric knowledge to generate reasonable responses, emphasizing their functionality beyond standard extractive methods.</data>
      <data key="d8">knowledge utilization,model functionality</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866249</data>
    </edge>
    <edge source="RAG Models" target="Kyunghyun Cho">
      <data key="d6">7.0</data>
      <data key="d7">Kyunghyun Cho contributed discussions that are relevant to the development and effectiveness of RAG Models.</data>
      <data key="d8">collaboration,contribution</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866251</data>
    </edge>
    <edge source="RAG Models" target="Sewon Min">
      <data key="d6">7.0</data>
      <data key="d7">Sewon Min provided advice that supported the research and development of RAG Models.</data>
      <data key="d8">collaboration,contribution</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866253</data>
    </edge>
    <edge source="RAG Models" target="Retrieve-and-Edit Approaches">
      <data key="d6">8.0</data>
      <data key="d7">RAG Models share similarities with Retrieve-and-Edit approaches in that they retrieve and process information for generating outputs.</data>
      <data key="d8">information retrieval,methodological similarity</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866254</data>
    </edge>
    <edge source="RAG Models" target="Open-Domain QA">
      <data key="d6">9.0</data>
      <data key="d7">RAG Models have been validated for achieving state-of-the-art results in open-domain question answering tasks.</data>
      <data key="d8">application,performance</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866255</data>
    </edge>
    <edge source="RAG Models" target="Jeopardy Question">
      <data key="d6">8.0</data>
      <data key="d7">RAG Models generate responses to Jeopardy Questions, showcasing their capability in diverse inquiry formats.</data>
      <data key="d8">model versatility,task demonstration</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866567</data>
    </edge>
    <edge source="RAG Models" target="Middle Ear">
      <data key="d6">8.0</data>
      <data key="d7">RAG Models generate definitions such as that of the middle ear, indicating their application in providing specific medical knowledge.</data>
      <data key="d8">contextual accuracy,knowledge generation</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866569</data>
    </edge>
    <edge source="RAG Models" target="Comparative Model Generations for Question Answering (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG Models belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866570</data>
    </edge>
    <edge source="SearchQA" target="BART Model">
      <data key="d6">7.0</data>
      <data key="d7">The BART Model is used in comparison with models developed using the SearchQA dataset for generating questions.</data>
      <data key="d8">dataset utilization,model comparison</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866242</data>
    </edge>
    <edge source="SearchQA" target="Eunsol Choi">
      <data key="d6">8.0</data>
      <data key="d7">Eunsol Choi worked on the SearchQA dataset focused on enhancing question answering capabilities."|&gt;"dataset development, research</data>
      <data key="d8">8</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866253</data>
    </edge>
    <edge source="FEVER" target="James H. Thorne">
      <data key="d6">8.0</data>
      <data key="d7">James H. Thorne has published works related to the FEVER dataset, which is focused on fact extraction and verification.</data>
      <data key="d8">dataset development,research contribution</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866304</data>
    </edge>
    <edge source="FEVER" target="RAG Performance Results Table (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity FEVER belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866553</data>
    </edge>
    <edge source="TQA Wiki test set" target="TQA">
      <data key="d6">8.0</data>
      <data key="d7">TQA utilizes the TQA Wiki test set for performance evaluation, which helps in assessing its effectiveness in answering questions.</data>
      <data key="d8">evaluation,performance measurement</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866244</data>
    </edge>
    <edge source="BART Model" target="SQuAD-tuned Q-BLEU-1 Metric">
      <data key="d6">8.0</data>
      <data key="d7">The SQuAD-tuned Q-BLEU-1 metric is used for evaluating the output of the BART Model in generating questions.</data>
      <data key="d8">evaluation metric,performance analysis</data>
      <data key="d9">chunk-9b9de140312f67e7f2d6598149a691f8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866244</data>
    </edge>
    <edge source="TQA" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity TQA belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866549</data>
    </edge>
    <edge source="TQA" target="Model Performance Comparison Table for RAG-based Architectures (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity TQA belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866608</data>
    </edge>
    <edge source="Jeopardy Question Generation" target="Task Instance Counts for Open-Domain QA Datasets (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy Question Generation belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866643</data>
    </edge>
    <edge source="Open-Domain QA Tasks" target="REALM">
      <data key="d6">7.0</data>
      <data key="d7">REALM's performance is evaluated in Open-Domain QA Tasks, demonstrating strengths in retrieval techniques compared to RAG models.</data>
      <data key="d8">model assessment,performance evaluation</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866534</data>
    </edge>
    <edge source="Open-Domain QA Tasks" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Open-Domain QA Tasks belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866544</data>
    </edge>
    <edge source="American Literature" target="A Farewell to Arms">
      <data key="d6">10.0</data>
      <data key="d7">A Farewell to Arms is categorized under American Literature as a significant literary work from the U.S.</data>
      <data key="d8">literary classification,significant work</data>
      <data key="d9">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866245</data>
    </edge>
    <edge source="Lost Generation" target="The Sun Also Rises">
      <data key="d6">9.0</data>
      <data key="d7">The Sun Also Rises is associated with the Lost Generation as it reflects the sentiments and experiences of this group of writers.</data>
      <data key="d8">cultural reference,literary classification</data>
      <data key="d9">chunk-d3fd620aa30bf6560c0452e3e22a5b82</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866246</data>
    </edge>
    <edge source="A Farewell to Arms" target="Doc 1">
      <data key="d6">8.0</data>
      <data key="d7">A Farewell to Arms is more prominent in Doc 1, suggesting a key focus within that document's context.</data>
      <data key="d8">document context,novel prominence</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866557</data>
    </edge>
    <edge source="A Farewell to Arms" target="RAG model">
      <data key="d6">9.0</data>
      <data key="d7">The RAG model also utilizes 'A Farewell to Arms' when constructing answers or sentences in its processes.</data>
      <data key="d8">document utilization,language model</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866558</data>
    </edge>
    <edge source="A Farewell to Arms" target="Document Generation Heatmap Visualization (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity A Farewell to Arms belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866562</data>
    </edge>
    <edge source="A Farewell to Arms" target="Hemingway">
      <data key="d6">9.0</data>
      <data key="d7">Hemingway is also the author of A Farewell to Arms, highlighting his significant contributions to literature.</data>
      <data key="d8">author,literary contribution</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866628</data>
    </edge>
    <edge source="A Farewell to Arms" target="Hemingway Sentence Evaluation Interface (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity A Farewell to Arms belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866632</data>
    </edge>
    <edge source="The Sun Also Rises" target="Doc 2">
      <data key="d6">8.0</data>
      <data key="d7">The Sun Also Rises appears with increased intensity in Doc 2, indicating its significant relevance in that context.</data>
      <data key="d8">document context,novel prominence</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866556</data>
    </edge>
    <edge source="The Sun Also Rises" target="RAG model">
      <data key="d6">9.0</data>
      <data key="d7">The RAG model leverages 'The Sun Also Rises' for language generation tasks, indicating its importance in memory operations.</data>
      <data key="d8">document utilization,language model</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866557</data>
    </edge>
    <edge source="The Sun Also Rises" target="Document Generation Heatmap Visualization (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity The Sun Also Rises belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866560</data>
    </edge>
    <edge source="The Sun Also Rises" target="Hemingway">
      <data key="d6">9.0</data>
      <data key="d7">Hemingway is the author of The Sun Also Rises, a key work in his literary career.</data>
      <data key="d8">authorship,literature</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866626</data>
    </edge>
    <edge source="The Sun Also Rises" target="Control Questions">
      <data key="d6">6.0</data>
      <data key="d7">The evaluation study potentially includes fact-checking related to The Sun Also Rises as part of the controlled tasks.</data>
      <data key="d8">fact-checking,literary evaluation</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866628</data>
    </edge>
    <edge source="The Sun Also Rises" target="Hemingway Sentence Evaluation Interface (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity The Sun Also Rises belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866631</data>
    </edge>
    <edge source="NQ" target="REALM">
      <data key="d6">7.0</data>
      <data key="d7">REALM's performance is quantified in the NQ metric, allowing for assessment against other retrieval-augmented models.</data>
      <data key="d8">model evaluation,performance analysis</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866539</data>
    </edge>
    <edge source="NQ" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity NQ belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866548</data>
    </edge>
    <edge source="NQ" target="Model Performance Comparison Table for RAG-based Architectures (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity NQ belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866606</data>
    </edge>
    <edge source="Kyunghyun Cho" target="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">Kyunghyun Cho's research contributions are reflected in the conference proceedings."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866264</data>
    </edge>
    <edge source="Kyunghyun Cho" target="AAAI Conference on Artificial Intelligence">
      <data key="d6">8.0</data>
      <data key="d7">Kyunghyun Cho contributed to the research presented at the AAAI Conference on Artificial Intelligence, 2018.</data>
      <data key="d8">conference participation,research collaboration</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866265</data>
    </edge>
    <edge source="Kyunghyun Cho" target="Passage re-ranking with BERT">
      <data key="d6">8.0</data>
      <data key="d7">Kyunghyun Cho contributed to the research on passage re-ranking using BERT."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866290</data>
    </edge>
    <edge source="NSF Graduate Research Fellowship" target="EP">
      <data key="d6">8.0</data>
      <data key="d7">EP has received support from the NSF Graduate Research Fellowship for their research work.</data>
      <data key="d8">academic support,fellowship</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866251</data>
    </edge>
    <edge source="FAIR PhD Program" target="PL">
      <data key="d6">8.0</data>
      <data key="d7">PL is supported by the FAIR PhD program in their research pursuits.</data>
      <data key="d8">academic support,fellowship</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866251</data>
    </edge>
    <edge source="Retrieve-and-Edit Approaches" target="Knowledge-Intensive Dialog">
      <data key="d6">7.0</data>
      <data key="d7">Knowledge-Intensive Dialog benefits from methods like Retrieve-and-Edit, which enhance the generation process by conditioning text retrieval.</data>
      <data key="d8">dialog systems,information processing</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866252</data>
    </edge>
    <edge source="Retrieve-and-Edit Approaches" target="TF-IDF">
      <data key="d6">6.0</data>
      <data key="d7">TF-IDF is cited as a method for retrieving text, contrasting with the end-to-end learned retrieval used in RAG Models.</data>
      <data key="d8">contrast,retrieval methods</data>
      <data key="d9">chunk-5f2c9353b0b8313cea8dd93521358493</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866253</data>
    </edge>
    <edge source="Danqi Chen" target="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">Danqi Chen authored a paper published in the proceedings of this conference."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866252</data>
    </edge>
    <edge source="Adam Fisch" target="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">Adam Fisch co-authored a paper published in the conference proceedings."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866253</data>
    </edge>
    <edge source="Jason Weston" target="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">Jason Weston co-authored research presented at the conference."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866255</data>
    </edge>
    <edge source="Jason Weston" target="Finding generalizable evidence">
      <data key="d6">8.0</data>
      <data key="d7">Jason Weston is cited for his contributions to Q&amp;A model research."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866293</data>
    </edge>
    <edge source="Antoine Bordes" target="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">Antoine Bordes contributed to a paper submitted at the conference."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866256</data>
    </edge>
    <edge source="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics" target="Association for Computational Linguistics">
      <data key="d6">10.0</data>
      <data key="d7">The Association for Computational Linguistics organizes and publishes the proceedings of this annual meeting."|&gt;"organization, conference</data>
      <data key="d8">10</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866257</data>
    </edge>
    <edge source="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics" target="Matthew Dunn">
      <data key="d6">9.0</data>
      <data key="d7">Matthew Dunn contributed to research published in the proceedings of the conference."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866259</data>
    </edge>
    <edge source="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics" target="Levent Sagun">
      <data key="d6">9.0</data>
      <data key="d7">Levent Sagun is associated with research presented at the conference."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866259</data>
    </edge>
    <edge source="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics" target="Mike Higgins">
      <data key="d6">9.0</data>
      <data key="d7">Mike Higgins contributed to research published in the conference proceedings."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866261</data>
    </edge>
    <edge source="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics" target="V. Ugur Guney">
      <data key="d6">9.0</data>
      <data key="d7">V. Ugur Guney is linked to research published at the conference."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866262</data>
    </edge>
    <edge source="Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics" target="Volkan Cirik">
      <data key="d6">9.0</data>
      <data key="d7">Volkan Cirik is associated with the research presented in the conference proceedings."|&gt;"authorship, conference papers</data>
      <data key="d8">9</data>
      <data key="d9">chunk-23a7f06b95f84637f32c50a9f98890ad</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866263</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="AAAI Conference on Artificial Intelligence">
      <data key="d6">9.0</data>
      <data key="d7">The AAAI Conference on Artificial Intelligence is associated with the Association for Computational Linguistics, an organization that organizes related conferences.</data>
      <data key="d8">academic collaboration,event organization</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866268</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="Kenton Lee">
      <data key="d6">9.0</data>
      <data key="d7">Kenton Lee has contributed to various research papers presented at conferences organized by the Association for Computational Linguistics.</data>
      <data key="d8">organization impact,research involvement</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866270</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="Transactions of the Association of Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">The Association for Computational Linguistics publishes significant research, such as found in the Transactions of the Association of Computational Linguistics.</data>
      <data key="d8">professional organization,publication</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866276</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="A diversity-promoting objective function for neural conversation models">
      <data key="d6">8.0</data>
      <data key="d7">The paper addresses methodologies discussed at the Association for Computational Linguistics, linking the two in the field of NLP.</data>
      <data key="d8">conference relevance,research impact</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866281</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="Robust neural machine translation with joint textual and phonetic embedding">
      <data key="d6">8.0</data>
      <data key="d7">This research aligns with topics explored at the Association for Computational Linguistics conference, emphasizing their relevance in current studies.</data>
      <data key="d8">conference relevance,research impact</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866282</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="Towards exploiting background knowledge for building conversation systems">
      <data key="d6">8.0</data>
      <data key="d7">The research on conversation systems is published under the auspices of the Association for Computational Linguistics."|&gt;"event publication, organizational support</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866301</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="Mitesh M. Khapra">
      <data key="d6">9.0</data>
      <data key="d7">Mitesh M. Khapra's work is associated with the activities of the Association for Computational Linguistics in various publications."|&gt;"research affiliation, academic organization</data>
      <data key="d8">9</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866302</data>
    </edge>
    <edge source="Association for Computational Linguistics" target="Rodrigo Nogueira">
      <data key="d6">9.0</data>
      <data key="d7">Rodrigo Nogueira's work on passage re-ranking is recognized by the Association for Computational Linguistics."|&gt;"research affiliation, academic organization</data>
      <data key="d8">9</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866303</data>
    </edge>
    <edge source="Noah Carter" target="AAAI Conference on Artificial Intelligence">
      <data key="d6">9.0</data>
      <data key="d7">Noah Carter's research was presented at the notable AI conference.</data>
      <data key="d8">AI research,academic presentation</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866317</data>
    </edge>
    <edge source="Jiatao Gu" target="AAAI Conference on Artificial Intelligence">
      <data key="d6">9.0</data>
      <data key="d7">Jiatao Gu presented research on search engine guided neural machine translation at the AAAI Conference on Artificial Intelligence, 2018.</data>
      <data key="d8">conference participation,research presentation</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866257</data>
    </edge>
    <edge source="Yong Wang" target="AAAI Conference on Artificial Intelligence">
      <data key="d6">8.0</data>
      <data key="d7">Yong Wang was a co-author of the paper presented at the AAAI Conference on Artificial Intelligence, 2018.</data>
      <data key="d8">conference participation,research collaboration</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866258</data>
    </edge>
    <edge source="Victor O.K. Li" target="AAAI Conference on Artificial Intelligence">
      <data key="d6">8.0</data>
      <data key="d7">Victor O.K. Li is a co-author of the paper presented at the AAAI Conference on Artificial Intelligence, 2018.</data>
      <data key="d8">conference participation,research collaboration</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866267</data>
    </edge>
    <edge source="Kelvin Guu" target="REALM">
      <data key="d6">9.0</data>
      <data key="d7">Kelvin Guu is associated with the development of the REALM methodology discussed in their paper, which aims to enhance pre-training of language models.</data>
      <data key="d8">model development,research contribution</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866261</data>
    </edge>
    <edge source="Kelvin Guu" target="Dense Passage Retrieval for Open-Domain Question Answering">
      <data key="d6">8.0</data>
      <data key="d7">Kelvin Guu is an author of research discussing dense passage retrieval, which supports improvements in question answering systems.</data>
      <data key="d8">information retrieval,research contribution</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866262</data>
    </edge>
    <edge source="Tatsunori B. Hashimoto" target="REALM">
      <data key="d6">9.0</data>
      <data key="d7">Tatsunori B. Hashimoto is a co-author of the paper that discusses the REALM method, providing insights into enhancing language model performance.</data>
      <data key="d8">model development,research contribution</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866263</data>
    </edge>
    <edge source="Yonatan Oren" target="REALM">
      <data key="d6">8.0</data>
      <data key="d7">Yonatan Oren contributed to the research on REALM, discussing methods for pre-training language models in their paper.</data>
      <data key="d8">model development,research contribution</data>
      <data key="d9">chunk-ef47fd07a7377b94f11ee0a4348cf1b1</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866264</data>
    </edge>
    <edge source="REALM" target="Open-Domain QA Test Scores (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity REALM belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866543</data>
    </edge>
    <edge source="Kenton Lee" target="Florence, Italy">
      <data key="d6">7.0</data>
      <data key="d7">Kenton Lee's work was presented at the Association for Computational Linguistics event held in Florence, indicating his active role in the research discussions there.</data>
      <data key="d8">conference presence,event participation</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866280</data>
    </edge>
    <edge source="Guillaume Lample" target="Large Memory Layers with Product Keys">
      <data key="d6">8.0</data>
      <data key="d7">Guillaume Lample is a co-author of the research paper discussing large memory layers, indicating his involvement in that area of study.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866277</data>
    </edge>
    <edge source="Alexandre Sablayrolles" target="Large Memory Layers with Product Keys">
      <data key="d6">8.0</data>
      <data key="d7">Alexandre Sablayrolles co-authored the paper on large memory layers, showcasing his research endeavors in machine learning.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866278</data>
    </edge>
    <edge source="Marc Aurelio Ranzato" target="Large Memory Layers with Product Keys">
      <data key="d6">8.0</data>
      <data key="d7">Marc’ Aurelio Ranzato participated in the research of large memory layers, reflecting his focus on neural networks.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866279</data>
    </edge>
    <edge source="Ludovic Denoyer" target="Large Memory Layers with Product Keys">
      <data key="d6">8.0</data>
      <data key="d7">Ludovic Denoyer contributed to the large memory layers research area, furthering his work in machine learning.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866280</data>
    </edge>
    <edge source="Herve Jegou" target="Large Memory Layers with Product Keys">
      <data key="d6">8.0</data>
      <data key="d7">Herve Jegou's involvement in the paper suggests his contributions to the advancement of memory layers in neural processing.</data>
      <data key="d8">authorship,research contribution</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866281</data>
    </edge>
    <edge source="Advances in Neural Information Processing Systems 32" target="Large Memory Layers with Product Keys">
      <data key="d6">9.0</data>
      <data key="d7">The paper on large memory layers was presented as part of the Advances in Neural Information Processing Systems 32, highlighting its significance in the research community.</data>
      <data key="d8">publication context,research significance</data>
      <data key="d9">chunk-6b046b3a3d5c9333bae80b4874d68e8a</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866283</data>
    </edge>
    <edge source="Gregory Diamos" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Gregory Diamos is a co-author cited in the paper discussing mixed precision training."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866282</data>
    </edge>
    <edge source="Erich Elsen" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Erich Elsen contributed to the mixed precision training research cited in ICLR, 2018."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866283</data>
    </edge>
    <edge source="David Garcia" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">David Garcia is recognized for his contributions to the mixed precision training work presented in ICLR, 2018."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866284</data>
    </edge>
    <edge source="Boris Ginsburg" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Boris Ginsburg is noted for his involvement in the mixed precision training paper presented at ICLR."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866285</data>
    </edge>
    <edge source="Michael Houston" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Michael Houston is cited as contributing to the mixed precision training research in ICLR."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866286</data>
    </edge>
    <edge source="Oleksii Kuchaiev" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Oleksii Kuchaiev's work is acknowledged in the context of the mixed precision training research."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866288</data>
    </edge>
    <edge source="Ganesh Venkatesh" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Ganesh Venkatesh is mentioned as a contributor in the mixed precision training paper presented at ICLR."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866289</data>
    </edge>
    <edge source="Hao Wu" target="Mixed precision training">
      <data key="d6">8.0</data>
      <data key="d7">Hao Wu is recognized for his work in the mixed precision training research discussed at ICLR."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866290</data>
    </edge>
    <edge source="Nikita Moghe" target="Towards exploiting background knowledge for building conversation systems">
      <data key="d6">8.0</data>
      <data key="d7">Nikita Moghe is a co-author cited in the conversation systems paper presented in 2018."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866284</data>
    </edge>
    <edge source="Siddhartha Arora" target="Towards exploiting background knowledge for building conversation systems">
      <data key="d6">8.0</data>
      <data key="d7">Siddhartha Arora contributed to the paper on conversation systems noted in the 2018 conference."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866286</data>
    </edge>
    <edge source="Suman Banerjee" target="Towards exploiting background knowledge for building conversation systems">
      <data key="d6">8.0</data>
      <data key="d7">Suman Banerjee is mentioned as a contributor to the conversation systems research presented in 2018."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866287</data>
    </edge>
    <edge source="Mitesh M. Khapra" target="Towards exploiting background knowledge for building conversation systems">
      <data key="d6">8.0</data>
      <data key="d7">Mitesh M. Khapra is cited for his role in the conversation systems paper from the 2018 conference."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866288</data>
    </edge>
    <edge source="Tri Nguyen" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Tri Nguyen contributed to the research regarding the machine reading comprehension dataset MS MARCO."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866286</data>
    </edge>
    <edge source="Mir Rosenberg" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Mir Rosenberg is acknowledged for his work related to the MS MARCO dataset."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866288</data>
    </edge>
    <edge source="Xia Song" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Xia Song is mentioned as a researcher involved in the study of the machine reading comprehension dataset."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866289</data>
    </edge>
    <edge source="Jianfeng Gao" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Jianfeng Gao contributed his expertise to the MS MARCO project focusing on machine reading comprehension."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866290</data>
    </edge>
    <edge source="Saurabh Tiwary" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Saurabh Tiwary is acknowledged for his contributions to the MS MARCO machine reading comprehension dataset."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866291</data>
    </edge>
    <edge source="Rangan Majumder" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Rangan Majumder's work is cited in the context of the MS MARCO machine reading comprehension efforts."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866292</data>
    </edge>
    <edge source="Li Deng" target="MS MARCO dataset">
      <data key="d6">8.0</data>
      <data key="d7">Li Deng is noted for contributing to the machine reading comprehension dataset MS MARCO."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866294</data>
    </edge>
    <edge source="Rodrigo Nogueira" target="Passage re-ranking with BERT">
      <data key="d6">8.0</data>
      <data key="d7">Rodrigo Nogueira is credited with co-authoring the paper on passage re-ranking with BERT."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866289</data>
    </edge>
    <edge source="Siddharth Karamcheti" target="Finding generalizable evidence">
      <data key="d6">8.0</data>
      <data key="d7">Siddharth Karamcheti is co-authoring the research on Q&amp;A model evidence extraction."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866291</data>
    </edge>
    <edge source="Rob Fergus" target="Finding generalizable evidence">
      <data key="d6">8.0</data>
      <data key="d7">Rob Fergus is acknowledged in the study focused on evidence for Q&amp;A systems."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866292</data>
    </edge>
    <edge source="Yuxiang Wu" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Yuxiang Wu's work on language models is noted in the context of knowledge base research."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866296</data>
    </edge>
    <edge source="Alexander Miller" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Alexander Miller's contributions to language models are acknowledged in the knowledge base exploration."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866298</data>
    </edge>
    <edge source="Noam Shazeer" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Noam Shazeer's research is discussed in relation to the limitations of language models."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866299</data>
    </edge>
    <edge source="Adam Roberts" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Adam Roberts is cited in discussions about the capabilities and limits of language models."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866300</data>
    </edge>
    <edge source="Katherine Lee" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Katherine Lee's involvement is noted in relation to studies on language model functionalities."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866301</data>
    </edge>
    <edge source="Sharan Narang" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Sharan Narang is recognized for contributions to research on language models."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866303</data>
    </edge>
    <edge source="Michael Matena" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Michael Matena is involved in research to understand the capabilities of language models."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866304</data>
    </edge>
    <edge source="Yanqi Zhou" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Yanqi Zhou's work on language models is acknowledged within the context of knowledge base research."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866305</data>
    </edge>
    <edge source="Wei Li" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Wei Li is mentioned for contributions regarding the understanding of language models."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866307</data>
    </edge>
    <edge source="Peter J. Liu" target="Language models as knowledge bases">
      <data key="d6">8.0</data>
      <data key="d7">Peter J. Liu's research in language models is part of the broader exploration of their factual capabilities."|&gt;"research contribution, academic collaboration</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866309</data>
    </edge>
    <edge source="ICLR" target="Mixed precision training">
      <data key="d6">10.0</data>
      <data key="d7">ICLR is the conference that published the research concerning mixed precision training."|&gt;"event publication, academic dissemination</data>
      <data key="d8">10</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866300</data>
    </edge>
    <edge source="Hong Kong" target="The 2019 Conference of the North American Chapter of the Association for Computational Linguistics">
      <data key="d6">9.0</data>
      <data key="d7">Hong Kong is the location where the 2019 conference was held."|&gt;"event location, conference organization</data>
      <data key="d8">9</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866301</data>
    </edge>
    <edge source="Brussels, Belgium" target="The 2018 Conference on Empirical Methods in Natural Language Processing">
      <data key="d6">9.0</data>
      <data key="d7">Brussels, Belgium is the city that hosted the 2018 NLP conference."|&gt;"event location, conference organization</data>
      <data key="d8">9</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866302</data>
    </edge>
    <edge source="fairseq" target="association for computational linguistics">
      <data key="d6">8.0</data>
      <data key="d7">fairseq is referenced in the context of academic demonstrations at the Association for Computational Linguistics."|&gt;"toolkit utilization, research showcase</data>
      <data key="d8">8</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866304</data>
    </edge>
    <edge source="MS MARCO" target="NIPS 2016">
      <data key="d6">7.0</data>
      <data key="d7">The MS MARCO dataset was presented in conjunction with the workshop held at the NIPS 2016 conference."|&gt;"event presentation, dataset introduction</data>
      <data key="d8">7</data>
      <data key="d9">chunk-88b6afd1a5461a754df54d609b370742</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866303</data>
    </edge>
    <edge source="R^3" target="Shuohang Wang">
      <data key="d6">9.0</data>
      <data key="d7">Shuohang Wang is involved in the development of systems like R^3, which utilize reinforced ranker-reader strategies for open-domain question answering.</data>
      <data key="d8">AI system development,question answering</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866304</data>
    </edge>
    <edge source="R^3" target="Mo Yu">
      <data key="d6">8.0</data>
      <data key="d7">Mo Yu contributes to the research surrounding the R^3 methodology for question-answering systems.</data>
      <data key="d8">AI research,question answering</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866305</data>
    </edge>
    <edge source="R^3" target="Xiaoxiao Guo">
      <data key="d6">7.0</data>
      <data key="d7">Xiaoxiao Guo is engaged in work related to R^3, contributing to advancements in AI-driven question-answering methodologies.</data>
      <data key="d8">AI methodology,language modeling</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866313</data>
    </edge>
    <edge source="R^3" target="Zhiguo Wang">
      <data key="d6">7.0</data>
      <data key="d7">Zhiguo Wang's work focuses on methodologies similar to R^3 in the context of question answering.</data>
      <data key="d8">AI contributions,research focus</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866315</data>
    </edge>
    <edge source="R^3" target="Wei Zhang">
      <data key="d6">6.0</data>
      <data key="d7">Wei Zhang is involved in supporting research efforts for the R^3 system, contributing to AI advancements.</data>
      <data key="d8">AI research,question-answering support</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866316</data>
    </edge>
    <edge source="R^3" target="Tim Klinger">
      <data key="d6">6.0</data>
      <data key="d7">Tim Klinger contributes knowledge to enhance the development of the R^3 model for question answering.</data>
      <data key="d8">AI development,collaborative effort</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866317</data>
    </edge>
    <edge source="R^3" target="Shiyu Chang">
      <data key="d6">7.0</data>
      <data key="d7">Shiyu Chang's research is aligned with the objectives of R^3, contributing to the enhancement of question-answering practices.</data>
      <data key="d8">AI research alignment,question-answering</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866318</data>
    </edge>
    <edge source="R^3" target="Gerry Tesauro">
      <data key="d6">8.0</data>
      <data key="d7">Gerry Tesauro's contributions to neural networks inform the strategies employed in the R^3 system.</data>
      <data key="d8">AI strategy,neural network contribution</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866319</data>
    </edge>
    <edge source="R^3" target="Bowen Zhou">
      <data key="d6">7.0</data>
      <data key="d7">Bowen Zhou is involved in AI research initiatives like R^3, focusing on improving question-answering mechanisms.</data>
      <data key="d8">AI improvement,question answering</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866320</data>
    </edge>
    <edge source="R^3" target="Jing Jiang">
      <data key="d6">7.0</data>
      <data key="d7">Jing Jiang's role in research supports the methodology employed by R^3 for effective question answering.</data>
      <data key="d8">AI support,question-answering system</data>
      <data key="d9">chunk-621349422796d54fe59c686c4614e2ce</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866322</data>
    </edge>
    <edge source="Shuohang Wang" target="Reinforced Ranker-Reader">
      <data key="d6">8.0</data>
      <data key="d7">Shuohang Wang is a co-author of the model known as the Reinforced Ranker-Reader.</data>
      <data key="d8">model development,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866315</data>
    </edge>
    <edge source="Shuohang Wang" target="Huggingfaces Transformers">
      <data key="d6">7.0</data>
      <data key="d7">Shuohang Wang's contributions relate to advancements discussed in the Huggingface’s Transformers.</data>
      <data key="d8">NLP development,research influence</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866316</data>
    </edge>
    <edge source="Mo Yu" target="Reinforced Ranker-Reader">
      <data key="d6">8.0</data>
      <data key="d7">Mo Yu is a co-author involved in the development of the Reinforced Ranker-Reader model.</data>
      <data key="d8">model development,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866316</data>
    </edge>
    <edge source="Gerry Tesauro" target="AAAI Symposium on Educational Advances in Artificial Intelligence">
      <data key="d6">7.0</data>
      <data key="d7">Gerry Tesauro's work was presented at the educational AI symposium.</data>
      <data key="d8">academic presentation,educational AI</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866320</data>
    </edge>
    <edge source="Jing Jiang" target="Memory Networks">
      <data key="d6">7.0</data>
      <data key="d7">Jing Jiang's work discusses concepts relevant to the architecture of Memory Networks.</data>
      <data key="d8">NLP architecture,research contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866323</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Wanjun Zhong">
      <data key="d6">8.0</data>
      <data key="d7">Wanjun Zhong's research contributes to methodologies discussed in Huggingface’s Transformers framework.</data>
      <data key="d8">NLP contribution,methodological development</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866317</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Thomas Wolf">
      <data key="d6">9.0</data>
      <data key="d7">Thomas Wolf is a contributor to the Huggingface’s Transformers project, which focuses on state-of-the-art NLP techniques.</data>
      <data key="d8">NLP,research contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866319</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Lysandre Debut">
      <data key="d6">8.0</data>
      <data key="d7">Lysandre Debut is part of the team that developed Huggingface’s Transformers, which are key tools in NLP.</data>
      <data key="d8">NLP,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866320</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Victor Sanh">
      <data key="d6">9.0</data>
      <data key="d7">Victor Sanh contributed to the advancement of Huggingface’s Transformers, which are significant in NLP research.</data>
      <data key="d8">NLP,research development</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866321</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Julien Chaumond">
      <data key="d6">8.0</data>
      <data key="d7">Julien Chaumond is involved in the creation of Huggingface’s Transformers, a project that impacts NLP technology.</data>
      <data key="d8">NLP,research involvement</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866323</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Clement Delangue">
      <data key="d6">8.0</data>
      <data key="d7">Clement Delangue is a contributing author to Huggingface’s Transformers, focusing on NLP advancements.</data>
      <data key="d8">NLP,research input</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866324</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Anthony Moi">
      <data key="d6">8.0</data>
      <data key="d7">Anthony Moi contributed to Huggingface’s Transformers, which play a vital role in NLP research.</data>
      <data key="d8">NLP,contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866325</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Pierric Cistac">
      <data key="d6">8.0</data>
      <data key="d7">Pierric Cistac is a contributor to the Huggingface's Transformers project, focusing on natural language processing.</data>
      <data key="d8">NLP,collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866326</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Tim Rault">
      <data key="d6">8.0</data>
      <data key="d7">Tim Rault is involved in the development of Huggingface’s Transformers, contributing to NLP solutions.</data>
      <data key="d8">NLP,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866327</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Rémi Louf">
      <data key="d6">8.0</data>
      <data key="d7">Rémi Louf's work on Huggingface’s Transformers enhances NLP capabilities.</data>
      <data key="d8">NLP,research impact</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866328</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Morgan Funtowicz">
      <data key="d6">8.0</data>
      <data key="d7">Morgan Funtowicz contributes to Huggingface’s Transformers, focusing on the development of NLP applications.</data>
      <data key="d8">NLP,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866329</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Joe Davison">
      <data key="d6">8.0</data>
      <data key="d7">Joe Davison's contributions are significant to the Huggingface’s Transformers project in natural language processing.</data>
      <data key="d8">NLP,research contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866330</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Sam Shleifer">
      <data key="d6">8.0</data>
      <data key="d7">Sam Shleifer has worked on Huggingface’s Transformers, enhancing natural language processing technologies.</data>
      <data key="d8">NLP,contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866331</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Patrick von Platen">
      <data key="d6">8.0</data>
      <data key="d7">Patrick von Platen is involved in the Huggingface’s Transformers project, impacting NLP methodology.</data>
      <data key="d8">NLP,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866332</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Clara Ma">
      <data key="d6">8.0</data>
      <data key="d7">Clara Ma's work on Huggingface’s Transformers contributes to advancements in natural language processing.</data>
      <data key="d8">NLP,research input</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866334</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Yacine Jernite">
      <data key="d6">8.0</data>
      <data key="d7">Yacine Jernite contributed to the development of Huggingface’s Transformers, enhancing NLP tools.</data>
      <data key="d8">NLP,research involvement</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866335</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Julien Plu">
      <data key="d6">8.0</data>
      <data key="d7">Julien Plu is a contributor to Huggingface’s Transformers, impacting natural language processing development.</data>
      <data key="d8">NLP,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866336</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Canwen Xu">
      <data key="d6">8.0</data>
      <data key="d7">Canwen Xu is involved in the Huggingface’s Transformers project, focusing on improving NLP capabilities.</data>
      <data key="d8">NLP,contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866338</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Teven Le Scao">
      <data key="d6">8.0</data>
      <data key="d7">Teven Le Scao contributes to the project of Huggingface’s Transformers, which are key in NLP research.</data>
      <data key="d8">NLP,research development</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866339</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Sylvain Gugger">
      <data key="d6">8.0</data>
      <data key="d7">Sylvain Gugger's work in Huggingface’s Transformers strengthens advancements in NLP technology.</data>
      <data key="d8">NLP,research contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866340</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Mariama Drame">
      <data key="d6">8.0</data>
      <data key="d7">Mariama Drame is a contributor to Huggingface’s Transformers, which enhance NLP methodologies.</data>
      <data key="d8">NLP,research involvement</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866341</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Quentin Lhoest">
      <data key="d6">8.0</data>
      <data key="d7">Quentin Lhoest's contributions to Huggingface’s Transformers impact natural language processing developments.</data>
      <data key="d8">NLP,research collaboration</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866342</data>
    </edge>
    <edge source="Huggingfaces Transformers" target="Alexander M. Rush">
      <data key="d6">8.0</data>
      <data key="d7">Alexander M. Rush is involved in the development of Huggingface’s Transformers, focusing on NLP applications.</data>
      <data key="d8">NLP,research contribution</data>
      <data key="d9">chunk-82335384732cb1d22a6f2ebb27ac180c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866343</data>
    </edge>
    <edge source="Fairseq" target="HuggingFace Transformers">
      <data key="d6">8.0</data>
      <data key="d7">Fairseq has been ported to HuggingFace Transformers to achieve similar performance but with an easier-to-use implementation.</data>
      <data key="d8">model implementation,open source</data>
      <data key="d9">chunk-b3e73eca6691f1d73f88752711bc074c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866336</data>
    </edge>
    <edge source="Retrieval Component Collapse" target="H Retrieval Collapse">
      <data key="d6">8.0</data>
      <data key="d7">H Retrieval Collapse is the broader phenomenon that encompasses the specific instance of Retrieval Component Collapse in models."|&gt;"retrieval performance, model efficiency</data>
      <data key="d8">8</data>
      <data key="d9">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866340</data>
    </edge>
    <edge source="Retrieval Component Collapse" target="story generation">
      <data key="d6">7.0</data>
      <data key="d7">The task of story generation is directly impacted by the retrieval component collapse, as it can lead to less informative outcomes."|&gt;"task impact, model performance</data>
      <data key="d8">7</data>
      <data key="d9">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866341</data>
    </edge>
    <edge source="Retrieval Component Collapse" target="Perez et al.">
      <data key="d6">9.0</data>
      <data key="d7">Perez et al. investigated issues related to the retrieval component collapse, highlighting its significance in model performance."|&gt;"research findings, model evaluation</data>
      <data key="d8">9</data>
      <data key="d9">chunk-d70c6f37764e4792ca46bea09a315724</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866342</data>
    </edge>
    <edge source="RAG System Process Diagram (image)" target="Retrieval-Augmented Generation (RAG) System">
      <data key="d6">10.0</data>
      <data key="d7">Entity Retrieval-Augmented Generation (RAG) System belongs to RAG System Process Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866493</data>
    </edge>
    <edge source="RAG System Process Diagram (image)" target="Visual Analysis">
      <data key="d6">10.0</data>
      <data key="d7">Entity Visual Analysis belongs to RAG System Process Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866494</data>
    </edge>
    <edge source="RAG System Process Diagram (image)" target="Image Content Analysis">
      <data key="d6">10.0</data>
      <data key="d7">Entity Image Content Analysis belongs to RAG System Process Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866495</data>
    </edge>
    <edge source="RAG System Process Diagram (image)" target="Query Encoder q(x)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Query Encoder q(x) belongs to RAG System Process Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866496</data>
    </edge>
    <edge source="RAG System Process Diagram (image)" target="Diagram">
      <data key="d6">10.0</data>
      <data key="d7">Entity Diagram belongs to RAG System Process Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866498</data>
    </edge>
    <edge source="RAG-Sequence Probability Equation (equation)" target="Natural Language Processing (NLP)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Natural Language Processing (NLP) belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866497</data>
    </edge>
    <edge source="RAG-Sequence Probability Equation (equation)" target="Bayesian Principles">
      <data key="d6">10.0</data>
      <data key="d7">Entity Bayesian Principles belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866499</data>
    </edge>
    <edge source="RAG-Sequence Probability Equation (equation)" target="Markov Processes">
      <data key="d6">10.0</data>
      <data key="d7">Entity Markov Processes belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866500</data>
    </edge>
    <edge source="RAG-Sequence Probability Equation (equation)" target="p _ { \mathrm { R A G . S e q u e n c e } } ( y | x ) ">
      <data key="d6">10.0</data>
      <data key="d7">Entity p _ { \mathrm { R A G . S e q u e n c e } } ( y | x )  belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866501</data>
    </edge>
    <edge source="RAG-Sequence Probability Equation (equation)" target="p_{\\theta}">
      <data key="d6">10.0</data>
      <data key="d7">Entity p_{\\theta} belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866504</data>
    </edge>
    <edge source="RAG-Sequence Probability Equation (equation)" target="p_{\\eta}">
      <data key="d6">10.0</data>
      <data key="d7">Entity p_{\\eta} belongs to RAG-Sequence Probability Equation (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866506</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Computational Linguistics">
      <data key="d6">10.0</data>
      <data key="d7">Entity Computational Linguistics belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866503</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="RAG-Ioken">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Ioken belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866504</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Document Index">
      <data key="d6">10.0</data>
      <data key="d7">Entity Document Index belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866505</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Query Answering">
      <data key="d6">10.0</data>
      <data key="d7">Entity Query Answering belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866510</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Sequence Generation">
      <data key="d6">10.0</data>
      <data key="d7">Entity Sequence Generation belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866511</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Bayesian Inference">
      <data key="d6">10.0</data>
      <data key="d7">Entity Bayesian Inference belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866513</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Retrieval-Augmented Generation">
      <data key="d6">10.0</data>
      <data key="d7">Entity Retrieval-Augmented Generation belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866514</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Probabilistic Model">
      <data key="d6">10.0</data>
      <data key="d7">Entity Probabilistic Model belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866515</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Seq2seq Generator">
      <data key="d6">10.0</data>
      <data key="d7">Entity Seq2seq Generator belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866516</data>
    </edge>
    <edge source="RAG-Token Probability Model (equation)" target="Knowledge Retrieval">
      <data key="d6">10.0</data>
      <data key="d7">Entity Knowledge Retrieval belongs to RAG-Token Probability Model (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866517</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="document z">
      <data key="d6">10.0</data>
      <data key="d7">Entity document z belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866517</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="input query x">
      <data key="d6">10.0</data>
      <data key="d7">Entity input query x belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866530</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="Retrieval-Augmented Generation (RAG) model">
      <data key="d6">10.0</data>
      <data key="d7">Entity Retrieval-Augmented Generation (RAG) model belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866532</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="maximum inner product search (MIPS)">
      <data key="d6">10.0</data>
      <data key="d7">Entity maximum inner product search (MIPS) belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866533</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="Conditional Probability">
      <data key="d6">10.0</data>
      <data key="d7">Entity Conditional Probability belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866534</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="Latent Space">
      <data key="d6">10.0</data>
      <data key="d7">Entity Latent Space belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866536</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="Exponential Function">
      <data key="d6">10.0</data>
      <data key="d7">Entity Exponential Function belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866537</data>
    </edge>
    <edge source="Conditional Document Retrieval Probability (equation)" target="Inner Product">
      <data key="d6">10.0</data>
      <data key="d7">Entity Inner Product belongs to Conditional Document Retrieval Probability (equation)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866538</data>
    </edge>
    <edge source="Open-Domain QA Test Scores (table)" target="Table 1: Open-Domain QA Test Scores">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table 1: Open-Domain QA Test Scores belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866545</data>
    </edge>
    <edge source="Open-Domain QA Test Scores (table)" target="WQ">
      <data key="d6">10.0</data>
      <data key="d7">Entity WQ belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866550</data>
    </edge>
    <edge source="Open-Domain QA Test Scores (table)" target="CT">
      <data key="d6">10.0</data>
      <data key="d7">Entity CT belongs to Open-Domain QA Test Scores (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-f81b9b5d1c9a7a4813270007967c2bf8</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866551</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="Question Generation Systems">
      <data key="d6">10.0</data>
      <data key="d7">Entity Question Generation Systems belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866556</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="Table 2">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table 2 belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866557</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="Structure">
      <data key="d6">10.0</data>
      <data key="d7">Entity Structure belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866559</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="Jeopardy B-1">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy B-1 belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866560</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="MSMARCO SotA">
      <data key="d6">10.0</data>
      <data key="d7">Entity MSMARCO SotA belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866561</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="FEVER-3">
      <data key="d6">10.0</data>
      <data key="d7">Entity FEVER-3 belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866562</data>
    </edge>
    <edge source="RAG Performance Results Table (table)" target="FEVER-2">
      <data key="d6">10.0</data>
      <data key="d7">Entity FEVER-2 belongs to RAG Performance Results Table (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866563</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="RAG model">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG model belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866564</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="Doc 1">
      <data key="d6">10.0</data>
      <data key="d7">Entity Doc 1 belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866565</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="Doc 2">
      <data key="d6">10.0</data>
      <data key="d7">Entity Doc 2 belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866566</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="Heatmap">
      <data key="d6">10.0</data>
      <data key="d7">Entity Heatmap belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866567</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="Language Generation">
      <data key="d6">10.0</data>
      <data key="d7">Entity Language Generation belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866568</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="Tokens">
      <data key="d6">10.0</data>
      <data key="d7">Entity Tokens belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866570</data>
    </edge>
    <edge source="Document Generation Heatmap Visualization (image)" target="Document Contexts">
      <data key="d6">10.0</data>
      <data key="d7">Entity Document Contexts belongs to Document Generation Heatmap Visualization (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866571</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Jeopardy Question">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy Question belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866574</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Scotland">
      <data key="d6">10.0</data>
      <data key="d7">Entity Scotland belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866575</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Middle Ear">
      <data key="d6">10.0</data>
      <data key="d7">Entity Middle Ear belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866576</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Table 3">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table 3 belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866578</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Task">
      <data key="d6">10.0</data>
      <data key="d7">Entity Task belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866579</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Input">
      <data key="d6">10.0</data>
      <data key="d7">Entity Input belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866580</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Model">
      <data key="d6">10.0</data>
      <data key="d7">Entity Model belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866581</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Generation">
      <data key="d6">10.0</data>
      <data key="d7">Entity Generation belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866582</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="Dante">
      <data key="d6">10.0</data>
      <data key="d7">Entity Dante belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866583</data>
    </edge>
    <edge source="Comparative Model Generations for Question Answering (table)" target="The Divine Comedy">
      <data key="d6">10.0</data>
      <data key="d7">Entity The Divine Comedy belongs to Comparative Model Generations for Question Answering (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866584</data>
    </edge>
    <edge source="Human Assessments for Jeopardy Question Generation (table)" target="Jeopardy Question Generation Task">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy Question Generation Task belongs to Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866584</data>
    </edge>
    <edge source="Human Assessments for Jeopardy Question Generation (table)" target="Table 4">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table 4 belongs to Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866589</data>
    </edge>
    <edge source="Human Assessments for Jeopardy Question Generation (table)" target="Factuality">
      <data key="d6">10.0</data>
      <data key="d7">Entity Factuality belongs to Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866591</data>
    </edge>
    <edge source="Human Assessments for Jeopardy Question Generation (table)" target="Specificity">
      <data key="d6">10.0</data>
      <data key="d7">Entity Specificity belongs to Human Assessments for Jeopardy Question Generation (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866592</data>
    </edge>
    <edge source="Tri-gram Diversity Ratios in Generation Tasks (table)" target="MSMARCO">
      <data key="d6">10.0</data>
      <data key="d7">Entity MSMARCO belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866592</data>
    </edge>
    <edge source="Tri-gram Diversity Ratios in Generation Tasks (table)" target="Jeopardy QGen">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy QGen belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866593</data>
    </edge>
    <edge source="Tri-gram Diversity Ratios in Generation Tasks (table)" target="Gold">
      <data key="d6">10.0</data>
      <data key="d7">Entity Gold belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866594</data>
    </edge>
    <edge source="Tri-gram Diversity Ratios in Generation Tasks (table)" target="Distinction Ratio">
      <data key="d6">10.0</data>
      <data key="d7">Entity Distinction Ratio belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866598</data>
    </edge>
    <edge source="Tri-gram Diversity Ratios in Generation Tasks (table)" target="Performance Metrics">
      <data key="d6">10.0</data>
      <data key="d7">Entity Performance Metrics belongs to Tri-gram Diversity Ratios in Generation Tasks (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866599</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="RAG-Token-BM25">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Token-BM25 belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866602</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="RAG-Sequence-BM25">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence-BM25 belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866604</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="WQ">
      <data key="d6">10.0</data>
      <data key="d7">Entity WQ belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866609</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="CT">
      <data key="d6">10.0</data>
      <data key="d7">Entity CT belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866610</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="Jeopardy-QGen">
      <data key="d6">10.0</data>
      <data key="d7">Entity Jeopardy-QGen belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866611</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="MSMarco">
      <data key="d6">10.0</data>
      <data key="d7">Entity MSMarco belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866612</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="RAG-Token-Frozen">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Token-Frozen belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866614</data>
    </edge>
    <edge source="Model Performance Comparison Table for RAG-based Architectures (table)" target="RAG-Sequence-Frozen">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Sequence-Frozen belongs to Model Performance Comparison Table for RAG-based Architectures (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866615</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="RAG-Tok">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Tok belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866617</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="RAG-Seq">
      <data key="d6">10.0</data>
      <data key="d7">Entity RAG-Seq belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866619</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Fixed DPR">
      <data key="d6">10.0</data>
      <data key="d7">Entity Fixed DPR belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866620</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="BM25">
      <data key="d6">10.0</data>
      <data key="d7">Entity BM25 belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866621</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="K Retrieved Docs">
      <data key="d6">10.0</data>
      <data key="d7">Entity K Retrieved Docs belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866622</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="NQ Exact Match">
      <data key="d6">10.0</data>
      <data key="d7">Entity NQ Exact Match belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866623</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="NQ Answer Recall @K">
      <data key="d6">10.0</data>
      <data key="d7">Entity NQ Answer Recall @K belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866624</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Bleu-1 / Rouge-L score">
      <data key="d6">10.0</data>
      <data key="d7">Entity Bleu-1 / Rouge-L score belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866625</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Solid Orange Line">
      <data key="d6">10.0</data>
      <data key="d7">Entity Solid Orange Line belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866626</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Dashed Teal Line">
      <data key="d6">10.0</data>
      <data key="d7">Entity Dashed Teal Line belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866627</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Turquoise Line">
      <data key="d6">10.0</data>
      <data key="d7">Entity Turquoise Line belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866628</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Dotted Purple Line">
      <data key="d6">10.0</data>
      <data key="d7">Entity Dotted Purple Line belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866630</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Long-Dashed Orange Line">
      <data key="d6">10.0</data>
      <data key="d7">Entity Long-Dashed Orange Line belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866631</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Densely Dashed Teal Line">
      <data key="d6">10.0</data>
      <data key="d7">Entity Densely Dashed Teal Line belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866632</data>
    </edge>
    <edge source="RAG Performance Metrics Image (image)" target="Minimalist Background">
      <data key="d6">10.0</data>
      <data key="d7">Entity Minimalist Background belongs to RAG Performance Metrics Image (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866633</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Havana, Cuba">
      <data key="d6">10.0</data>
      <data key="d7">Entity Havana, Cuba belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866633</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Control Questions">
      <data key="d6">10.0</data>
      <data key="d7">Entity Control Questions belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866634</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Human Evaluation Study">
      <data key="d6">10.0</data>
      <data key="d7">Entity Human Evaluation Study belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866636</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Sentence A">
      <data key="d6">10.0</data>
      <data key="d7">Entity Sentence A belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866637</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Sentence B">
      <data key="d6">10.0</data>
      <data key="d7">Entity Sentence B belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866639</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Hemingway">
      <data key="d6">10.0</data>
      <data key="d7">Entity Hemingway belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866640</data>
    </edge>
    <edge source="Hemingway Sentence Evaluation Interface (image)" target="Fact-Checking Interface">
      <data key="d6">10.0</data>
      <data key="d7">Entity Fact-Checking Interface belongs to Hemingway Sentence Evaluation Interface (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866641</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="FEVER-3-way">
      <data key="d6">10.0</data>
      <data key="d7">Entity FEVER-3-way belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866646</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="FEVER-2-way">
      <data key="d6">10.0</data>
      <data key="d7">Entity FEVER-2-way belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866647</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="Table 7">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table 7 belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866648</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="Open-domain Question Answering Tasks">
      <data key="d6">10.0</data>
      <data key="d7">Entity Open-domain Question Answering Tasks belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866649</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="Footnotes">
      <data key="d6">10.0</data>
      <data key="d7">Entity Footnotes belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866650</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="Table Analysis">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table Analysis belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866651</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="Data Preparation for QA Systems">
      <data key="d6">10.0</data>
      <data key="d7">Entity Data Preparation for QA Systems belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866652</data>
    </edge>
    <edge source="Task Instance Counts for Open-Domain QA Datasets (table)" target="Statistical Insights">
      <data key="d6">10.0</data>
      <data key="d7">Entity Statistical Insights belongs to Task Instance Counts for Open-Domain QA Datasets (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2005.11401v4.pdf</data>
      <data key="d11">1757866654</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG) System" target="Query Encoder q(x)">
      <data key="d6">8.0</data>
      <data key="d7">The 'Query Encoder q(x)' is a critical component of the RAG system that plays a role in the overall functioning of the architecture.</data>
      <data key="d8">component hierarchy,system architecture</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866492</data>
    </edge>
    <edge source="Retrieval-Augmented Generation (RAG) System" target="Diagram">
      <data key="d6">9.0</data>
      <data key="d7">The Diagram visually represents the components and flow of the Retrieval-Augmented Generation (RAG) system.</data>
      <data key="d8">system components,visual representation</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866494</data>
    </edge>
    <edge source="Image Content Analysis" target="Visual Analysis">
      <data key="d6">7.0</data>
      <data key="d7">Image Content Analysis involves the assessment and interpretation of images, which aligns with the goals of Visual Analysis.</data>
      <data key="d8">analysis process,image assessment</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866492</data>
    </edge>
    <edge source="Visual Analysis" target="Diagram">
      <data key="d6">8.0</data>
      <data key="d7">Visual Analysis focuses on interpreting the components displayed in the Diagram which outlines the RAG system.</data>
      <data key="d8">interpretation,system architecture</data>
      <data key="d9">chunk-3547e8b4b8c6d06e5c87ace847239e13</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866493</data>
    </edge>
    <edge source="p _ { \mathrm { R A G . S e q u e n c e } } ( y | x ) " target="p_{\\theta}">
      <data key="d6">8.0</data>
      <data key="d7">The expression p _ { \mathrm { R A G . S e q u e n c e } } ( y | x ) describes how output sequences are generated using the probability distribution p_{\\theta} in conjunction with retrieved documents.</data>
      <data key="d8">probability distribution,sequence generation</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866495</data>
    </edge>
    <edge source="p _ { \mathrm { R A G . S e q u e n c e } } ( y | x ) " target="p_{\\eta}">
      <data key="d6">8.0</data>
      <data key="d7">The mathematical expression indicates that the RAG-Sequence model's functionality relies on p_{\\eta}, representing the retriever’s probability distribution that governs document selection.</data>
      <data key="d8">probability dependency,retrieval mechanism</data>
      <data key="d9">chunk-ed49c26a398a6bba5d1b396a04a8fc38</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866497</data>
    </edge>
    <edge source="RAG-Ioken" target="Probabilistic Model">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Ioken employs probabilistic models to facilitate token generation in the context of RAG methodologies.</data>
      <data key="d8">model application,token generation</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866499</data>
    </edge>
    <edge source="RAG-Ioken" target="Document Index">
      <data key="d6">8.0</data>
      <data key="d7">The document index plays a vital role in operationalizing the RAG-Ioken framework by providing a source for relevant documents.</data>
      <data key="d8">framework support,retrieval mechanism</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866500</data>
    </edge>
    <edge source="RAG-Ioken" target="Knowledge Retrieval">
      <data key="d6">9.0</data>
      <data key="d7">Knowledge retrieval is a crucial component of the RAG-Ioken framework, enabling the integration of external information into token generation.</data>
      <data key="d8">framework component,information utilization</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866502</data>
    </edge>
    <edge source="Computational Linguistics" target="Probabilistic Model">
      <data key="d6">9.0</data>
      <data key="d7">Probabilistic models are crucial in computational linguistics for tasks such as summarization and question answering.</data>
      <data key="d8">field application,statistical methods</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866501</data>
    </edge>
    <edge source="Probabilistic Model" target="Query Answering">
      <data key="d6">9.0</data>
      <data key="d7">Probabilistic models aid in enhancing query answering by providing a framework to calculate the likelihood of correct answers.</data>
      <data key="d8">enhancing performance,information retrieval</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866500</data>
    </edge>
    <edge source="Probabilistic Model" target="Bayesian Inference">
      <data key="d6">7.0</data>
      <data key="d7">Bayesian inference is a fundamental concept in probabilistic models that helps quantify uncertainty in sequences.</data>
      <data key="d8">statistical framework,uncertainty modeling</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866502</data>
    </edge>
    <edge source="Probabilistic Model" target="Seq2seq Generator">
      <data key="d6">8.0</data>
      <data key="d7">The Seq2seq Generator utilizes probabilistic models to predict the likelihood of generating specific output sequences based on input sequences.</data>
      <data key="d8">model application,prediction</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866505</data>
    </edge>
    <edge source="Retrieval-Augmented Generation" target="Knowledge Retrieval">
      <data key="d6">8.0</data>
      <data key="d7">Retrieval-Augmented Generation employs knowledge retrieval techniques to improve the quality and accuracy of generated content.</data>
      <data key="d8">improving accuracy,information integration</data>
      <data key="d9">chunk-3cb3c70372c63f01c7e14e4ca3b06e1c</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866501</data>
    </edge>
    <edge source="document z" target="input query x">
      <data key="d6">9.0</data>
      <data key="d7">The relationship between document z and input query x is determined by their vector representations, impacting the retrieval likelihood in the equation.</data>
      <data key="d8">document-query relationship,retrieval likelihood</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866513</data>
    </edge>
    <edge source="document z" target="maximum inner product search (MIPS)">
      <data key="d6">9.0</data>
      <data key="d7">MIPS methodology is employed to efficiently retrieve document z based on its relationship to the input query x.</data>
      <data key="d8">document query similarity,efficient retrieval</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866514</data>
    </edge>
    <edge source="document z" target="Latent Space">
      <data key="d6">8.0</data>
      <data key="d7">Document z's representation exists within the latent space, and its retrieval likelihood is influenced by its relative position to input query x in this space.</data>
      <data key="d8">document representation,retrieval context</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866515</data>
    </edge>
    <edge source="document z" target="Inner Product">
      <data key="d6">9.0</data>
      <data key="d7">The inner product operation is used to calculate the similarity of document z with the input query x to inform retrieval likelihood.</data>
      <data key="d8">mathematical operation,similarity measure</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866516</data>
    </edge>
    <edge source="input query x" target="Latent Space">
      <data key="d6">8.0</data>
      <data key="d7">Input query x also exists in the latent space, and its relationship with document z dictates the retrieval probability based on their closeness.</data>
      <data key="d8">query representation,retrieval context</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866516</data>
    </edge>
    <edge source="input query x" target="Inner Product">
      <data key="d6">9.0</data>
      <data key="d7">The inner product relates input query x to document z by quantifying their similarity, which impacts retrieval outcomes.</data>
      <data key="d8">mathematical operation,similarity measure</data>
      <data key="d9">chunk-67a3cd875d9c37aecd1b5e13b208485f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866517</data>
    </edge>
    <edge source="Table 2" target="Jeopardy B-1">
      <data key="d6">8.0</data>
      <data key="d7">Table 2 includes a score for Jeopardy B-1, indicating the performance metric related to the question generation task.</data>
      <data key="d8">data presentation,performance metric</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866546</data>
    </edge>
    <edge source="Table 2" target="MSMARCO SotA">
      <data key="d6">8.0</data>
      <data key="d7">Table 2 summarizes the performance of various models in the MS-MARCO task, highlighting the SotA scores.</data>
      <data key="d8">benchmark evaluation,data presentation</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866547</data>
    </edge>
    <edge source="Table 2" target="FEVER-3">
      <data key="d6">8.0</data>
      <data key="d7">Table 2 presents classification test scores that include results from FEVER-3, indicating its evaluation performance.</data>
      <data key="d8">benchmark evaluation,data presentation</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866549</data>
    </edge>
    <edge source="Table 2" target="FEVER-2">
      <data key="d6">8.0</data>
      <data key="d7">Table 2 shows the results for FEVER-2, contributing to the understanding of model performance in fact verification tasks.</data>
      <data key="d8">benchmark evaluation,data presentation</data>
      <data key="d9">chunk-e677e8584c8111e2fbb38897fae32287</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866550</data>
    </edge>
    <edge source="RAG model" target="Heatmap">
      <data key="d6">8.0</data>
      <data key="d7">The heatmap illustrates how the RAG model uses parametric knowledge to aid in language generation, showcasing patterns of token importance.</data>
      <data key="d8">model application,visual analysis</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866559</data>
    </edge>
    <edge source="RAG model" target="Language Generation">
      <data key="d6">9.0</data>
      <data key="d7">Language generation is performed by the RAG model utilizing document contexts to facilitate sentence completion and answer generation.</data>
      <data key="d8">model function,text generation</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866560</data>
    </edge>
    <edge source="RAG model" target="Document Contexts">
      <data key="d6">9.0</data>
      <data key="d7">Document contexts provide the background knowledge the RAG model leverages when generating language responses.</data>
      <data key="d8">knowledge retrieval,model function</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866562</data>
    </edge>
    <edge source="Heatmap" target="Tokens">
      <data key="d6">7.0</data>
      <data key="d7">Tokens are represented in the heatmap, indicating their weight in terms of importance for language generation tasks.</data>
      <data key="d8">analysis,text representation</data>
      <data key="d9">chunk-0e88be2ccc273f5476f809546920b89f</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866560</data>
    </edge>
    <edge source="Jeopardy Question" target="Scotland">
      <data key="d6">7.0</data>
      <data key="d7">Scotland is referenced in a Jeopardy Question context regarding currency, linking it to the task type.</data>
      <data key="d8">geographical relevance,inquiry context</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866569</data>
    </edge>
    <edge source="Input" target="Model">
      <data key="d6">7.0</data>
      <data key="d7">Input is associated with different models as the specific questions posed to generate corresponding outputs.</data>
      <data key="d8">model usage,query association</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866568</data>
    </edge>
    <edge source="Model" target="Generation">
      <data key="d6">8.0</data>
      <data key="d7">Different models are responsible for producing the generation, which refers to the outputs for the posed inputs.</data>
      <data key="d8">model output,response generation</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866569</data>
    </edge>
    <edge source="Dante" target="The Divine Comedy">
      <data key="d6">9.0</data>
      <data key="d7">Dante is the author of The Divine Comedy, indicating his key role in the creation of this literary work.</data>
      <data key="d8">authorship,literature</data>
      <data key="d9">chunk-5a0294c30c4299ee3e2c0f5a634e94c0</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866569</data>
    </edge>
    <edge source="Table 4" target="Factuality">
      <data key="d6">8.0</data>
      <data key="d7">Table 4 includes specific percentages that measure the factuality of the outputs produced by BART and RAG.</data>
      <data key="d8">data representation,performance metric</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866581</data>
    </edge>
    <edge source="Table 4" target="Specificity">
      <data key="d6">8.0</data>
      <data key="d7">Table 4 presents percentages that evaluate the specificity of the outputs produced by BART and RAG.</data>
      <data key="d8">data representation,performance metric</data>
      <data key="d9">chunk-9602588f9a41c6c9eaeca67413aaf7ae</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866585</data>
    </edge>
    <edge source="MSMARCO" target="Gold">
      <data key="d6">9.0</data>
      <data key="d7">Gold model serves as a benchmark for evaluating the performance of other models on the MSMARCO task.</data>
      <data key="d8">benchmarking,model evaluation</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866586</data>
    </edge>
    <edge source="Jeopardy QGen" target="Gold">
      <data key="d6">9.0</data>
      <data key="d7">Gold achieved the highest ratio in the Jeopardy QGen task, establishing a standard for comparison.</data>
      <data key="d8">benchmarking,performance metrics</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866587</data>
    </edge>
    <edge source="Gold" target="Performance Metrics">
      <data key="d6">9.0</data>
      <data key="d7">The performance of the Gold model is evaluated through the use of performance metrics across the two tasks, MSMARCO and Jeopardy QGen.</data>
      <data key="d8">model evaluation,performance measurement</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866589</data>
    </edge>
    <edge source="Gold" target="Distinction Ratio">
      <data key="d6">9.0</data>
      <data key="d7">The distinction ratio for the Gold model shows it achieved the highest measure across both tasks, making it a strong benchmark.</data>
      <data key="d8">benchmarking,statistical measure</data>
      <data key="d9">chunk-1dd05d174cc46f951f0f9378efa364a9</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866592</data>
    </edge>
    <edge source="RAG-Token-BM25" target="RAG-Sequence-BM25">
      <data key="d6">6.0</data>
      <data key="d7">RAG-Token-BM25 and RAG-Sequence-BM25 are both tested models in performance comparisons for NLP tasks.</data>
      <data key="d8">model comparison,performance analysis</data>
      <data key="d9">chunk-0dc5f0a2ca0f99aef13c5f054b56fd98</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866597</data>
    </edge>
    <edge source="RAG-Tok" target="NQ Exact Match">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Tok's performance in exact match results is depicted in the 'NQ Exact Match' graph, showcasing its capabilities in retrieval models.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866610</data>
    </edge>
    <edge source="RAG-Tok" target="NQ Answer Recall @K">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Tok's recall performance is illustrated in the 'NQ Answer Recall @K' graph, correlating with the number of retrieved documents.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866611</data>
    </edge>
    <edge source="RAG-Tok" target="Bleu-1 / Rouge-L score">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Tok's performance metrics related to Bleu-1 and Rouge-L scores are indicated in the third graph, highlighting response quality dynamics.</data>
      <data key="d8">evaluation metrics,response quality</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866613</data>
    </edge>
    <edge source="RAG-Tok" target="Solid Orange Line">
      <data key="d6">7.0</data>
      <data key="d7">The Solid Orange Line illustrates RAG-Tok's performance metrics for exact matches, visually representing its results.</data>
      <data key="d8">data visualization,performance metrics</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866614</data>
    </edge>
    <edge source="RAG-Tok" target="Long-Dashed Orange Line">
      <data key="d6">7.0</data>
      <data key="d7">The Long-Dashed Orange Line tracks RAG-Tok's Rouge-L score, providing insights into response quality at various retrieved documents.</data>
      <data key="d8">performance evaluation,response quality</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866615</data>
    </edge>
    <edge source="RAG-Seq" target="NQ Exact Match">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Seq's metrics for exact matches are plotted alongside RAG-Tok in the 'NQ Exact Match' graph for comparative analysis.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866611</data>
    </edge>
    <edge source="RAG-Seq" target="NQ Answer Recall @K">
      <data key="d6">8.0</data>
      <data key="d7">RAG-Seq's results for recall at different K values are represented in the same graph as RAG-Tok for comparison.</data>
      <data key="d8">model comparison,performance evaluation</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866613</data>
    </edge>
    <edge source="RAG-Seq" target="Bleu-1 / Rouge-L score">
      <data key="d6">8.0</data>
      <data key="d7">The performance of RAG-Seq regarding Bleu-1 and Rouge-L scores is tracked in the same graph as RAG-Tok for comparative purposes.</data>
      <data key="d8">evaluation metrics,response quality</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866615</data>
    </edge>
    <edge source="RAG-Seq" target="Dashed Teal Line">
      <data key="d6">7.0</data>
      <data key="d7">The Dashed Teal Line correlates with RAG-Seq's performance in the 'NQ Exact Match' metrics, highlighting its results in contrast to RAG-Tok.</data>
      <data key="d8">data visualization,performance metrics</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866616</data>
    </edge>
    <edge source="RAG-Seq" target="Densely Dashed Teal Line">
      <data key="d6">7.0</data>
      <data key="d7">The Densely Dashed Teal Line measures RAG-Seq's Bleu-1 score, revealing its performance in relation to document retrieval quantity.</data>
      <data key="d8">performance evaluation,response quality</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866618</data>
    </edge>
    <edge source="Fixed DPR" target="Turquoise Line">
      <data key="d6">6.0</data>
      <data key="d7">The Turquoise Line represents the Fixed DPR performance in recall metrics, allowing for comparative analysis with RAG models.</data>
      <data key="d8">data comparison,model evaluation</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866615</data>
    </edge>
    <edge source="BM25" target="NQ Answer Recall @K">
      <data key="d6">7.0</data>
      <data key="d7">BM25's performance in recall is evaluated in the same context as RAG models, indicating a competitive analysis.</data>
      <data key="d8">model evaluation,performance comparison</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866615</data>
    </edge>
    <edge source="BM25" target="Dotted Purple Line">
      <data key="d6">6.0</data>
      <data key="d7">The Dotted Purple Line depicts BM25 performance metrics in the recall evaluation, indicating its standing among other models.</data>
      <data key="d8">data comparison,model evaluation</data>
      <data key="d9">chunk-4987aa3e480b586e707cdca6ecf793c5</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866616</data>
    </edge>
    <edge source="Hemingway" target="Havana, Cuba">
      <data key="d6">8.0</data>
      <data key="d7">Hemingway's background includes being born in Havana, Cuba, linking him to his cultural origins.</data>
      <data key="d8">biography,cultural background</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866629</data>
    </edge>
    <edge source="Hemingway" target="Sentence A">
      <data key="d6">7.0</data>
      <data key="d7">Sentence A describes a work by Hemingway, establishing a direct connection to his literary contributions.</data>
      <data key="d8">authorship,work description</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866631</data>
    </edge>
    <edge source="Hemingway" target="Sentence B">
      <data key="d6">8.0</data>
      <data key="d7">Sentence B provides biographical information about Hemingway, relating to his birthplace.</data>
      <data key="d8">authorship,biographical information</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866632</data>
    </edge>
    <edge source="Control Questions" target="Human Evaluation Study">
      <data key="d6">10.0</data>
      <data key="d7">Control questions are integral to the Human Evaluation Study to maintain quality and accuracy in responses.</data>
      <data key="d8">quality assurance,study structure</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866629</data>
    </edge>
    <edge source="Human Evaluation Study" target="Fact-Checking Interface">
      <data key="d6">9.0</data>
      <data key="d7">The Fact-Checking Interface is utilized in the context of the Human Evaluation Study to assess the validity of statements regarding authors.</data>
      <data key="d8">accuracy assessment,evaluation tool</data>
      <data key="d9">chunk-497ebdf7aed01bdfbf8a90a7f8a88d97</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866630</data>
    </edge>
    <edge source="FEVER-3-way" target="FEVER-2-way">
      <data key="d6">7.0</data>
      <data key="d7">Both FEVER datasets are used in QA with significant differences in their number of training instances.</data>
      <data key="d8">QA usage,dataset similarity</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866636</data>
    </edge>
    <edge source="Table 7" target="Open-domain Question Answering Tasks">
      <data key="d6">10.0</data>
      <data key="d7">Table 7 summarizes and presents the number of instances from various datasets pertinent to open-domain question answering tasks.</data>
      <data key="d8">data analysis,dataset evaluation</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866637</data>
    </edge>
    <edge source="Table 7" target="Footnotes">
      <data key="d6">5.0</data>
      <data key="d7">Footnotes would help provide context to the data presented in Table 7, enhancing understanding of the listed instances.</data>
      <data key="d8">contextual references,data understanding</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866638</data>
    </edge>
    <edge source="Footnotes" target="Table Analysis">
      <data key="d6">6.0</data>
      <data key="d7">Footnotes enhance the clarity and understanding of the data showcased in the Table Analysis.</data>
      <data key="d8">data clarification,reference enhancement</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866637</data>
    </edge>
    <edge source="Data Preparation for QA Systems" target="Statistical Insights">
      <data key="d6">8.0</data>
      <data key="d7">Statistical insights derived from the datasets underscore the necessity for thorough data preparation in optimizing QA systems.</data>
      <data key="d8">QA optimization,data importance</data>
      <data key="d9">chunk-fcc8a31ee693dbfc5b99acc3539c58ca</data>
      <data key="d10">2005.11401v4.pdf</data>
      <data key="d11">1757866637</data>
    </edge>
  </graph>
</graphml>
