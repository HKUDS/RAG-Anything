<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d11" for="edge" attr.name="created_at" attr.type="long" />
  <key id="d10" for="edge" attr.name="file_path" attr.type="string" />
  <key id="d9" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d8" for="edge" attr.name="keywords" attr.type="string" />
  <key id="d7" for="edge" attr.name="description" attr.type="string" />
  <key id="d6" for="edge" attr.name="weight" attr.type="double" />
  <key id="d5" for="node" attr.name="created_at" attr.type="long" />
  <key id="d4" for="node" attr.name="file_path" attr.type="string" />
  <key id="d3" for="node" attr.name="source_id" attr.type="string" />
  <key id="d2" for="node" attr.name="description" attr.type="string" />
  <key id="d1" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d0" for="node" attr.name="entity_id" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="ChartCitor">
      <data key="d0">ChartCitor</data>
      <data key="d1">organization</data>
      <data key="d2">ChartCitor is a multi-agent framework designed for providing fine-grained bounding box citations in chart question-answering tasks, enhancing the reliability and explainability of responses generated by large language models.&lt;SEP&gt;ChartCitor is a multimodal language model application used for converting data tables into visual charts and enabling complex visual tasks.&lt;SEP&gt;ChartCitor is a reasoning-based zero-shot segmentation model designed to generate masks from complex textual queries for visual chart understanding.&lt;SEP&gt;ChartCitor is a multi-agent framework designed for precise chart answer citations, featuring various interconnected agents for workflow optimization.&lt;SEP&gt;ChartCitor is an advanced system for object detection in chart images, achieving the highest IoU score of 27.4 among tested methods.&lt;SEP&gt;ChartCitor is a system being evaluated for its accuracy in comparison to GPT-4o, particularly regarding chart-based question answering.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72&lt;SEP&gt;chunk-24173160be3c2d0e4ba1d7ee9d1e07cc&lt;SEP&gt;chunk-b839fa86d69937abbbfac9da3a686d58&lt;SEP&gt;chunk-674ae697ba691bf3c9f7514577fa45ad&lt;SEP&gt;chunk-8db71158bc09d23d20250cfb7def0530&lt;SEP&gt;chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="Kanika Goswami">
      <data key="d0">Kanika Goswami</data>
      <data key="d1">person</data>
      <data key="d2">Kanika Goswami is affiliated with IGDTUW, Delhi, India, and is one of the authors of the work discussing ChartCitor.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907665</data>
    </node>
    <node id="Puneet Mathur">
      <data key="d0">Puneet Mathur</data>
      <data key="d1">person</data>
      <data key="d2">Puneet Mathur works at Adobe Research in the USA and is a co-author of the paper on ChartCitor.&lt;SEP&gt;Puneet Mathur is a co-author working on multi-agent table structure attribution research.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad&lt;SEP&gt;chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907665</data>
    </node>
    <node id="Ryan Rossi">
      <data key="d0">Ryan Rossi</data>
      <data key="d1">person</data>
      <data key="d2">Ryan Rossi is associated with Adobe Research in the USA and contributed to the development of ChartCitor.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907665</data>
    </node>
    <node id="Franck Dernoncourt">
      <data key="d0">Franck Dernoncourt</data>
      <data key="d1">person</data>
      <data key="d2">Franck Dernoncourt is part of Adobe Research in the USA and is one of the authors involved in the ChartCitor project.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907665</data>
    </node>
    <node id="Llama-3.2">
      <data key="d0">Llama-3.2</data>
      <data key="d1">category</data>
      <data key="d2">Llama-3.2 is a large language model known for effective utilization of in-context learning and visual prompting.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907665</data>
    </node>
    <node id="Claude-3.5 Sonnet">
      <data key="d0">Claude-3.5 Sonnet</data>
      <data key="d1">category</data>
      <data key="d2">Claude-3.5 Sonnet is another large language model capable of performing context-rich tasks including chart interpretation.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907665</data>
    </node>
    <node id="GPT-4V">
      <data key="d0">GPT-4V</data>
      <data key="d1">organization</data>
      <data key="d2">GPT-4V is a large language model that excels in interpreting and reasoning over chart images, playing a critical role in ChartCitor.&lt;SEP&gt;GPT-4V is a variant of the GPT-4 model used for generating predictions related to bounding boxes and visual interpretation of data.&lt;SEP&gt;GPT-4V is an object detection method using Direct Bbox Decoding, scoring 12.5 IoU in the analysis.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72&lt;SEP&gt;chunk-674ae697ba691bf3c9f7514577fa45ad&lt;SEP&gt;chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907760</data>
    </node>
    <node id="Fine-grained Structured Chart Attribution">
      <data key="d0">Fine-grained Structured Chart Attribution</data>
      <data key="d1">event</data>
      <data key="d2">Fine-grained Structured Chart Attribution is a task that involves identifying graph elements supporting claims in text responses to user queries.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907666</data>
    </node>
    <node id="Information Systems">
      <data key="d0">Information Systems</data>
      <data key="d1">category</data>
      <data key="d2">Information Systems refers to the discipline focused on the collection, organization, storage, and communication of information, playing a critical role in data extraction processes.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907666</data>
    </node>
    <node id="Visual Fact Checking">
      <data key="d0">Visual Fact Checking</data>
      <data key="d1">category</data>
      <data key="d2">Visual Fact Checking is a method used to verify the accuracy of information presented visually, especially in the context of chart data.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907666</data>
    </node>
    <node id="Multimodal Retrieval">
      <data key="d0">Multimodal Retrieval</data>
      <data key="d1">category</data>
      <data key="d2">Multimodal Retrieval involves extracting information from multiple forms of media, including text, images, and charts, to enhance understanding and verification of data.</data>
      <data key="d3">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907667</data>
    </node>
    <node id="GPT-4o">
      <data key="d0">GPT-4o</data>
      <data key="d1">organization</data>
      <data key="d2">GPT-4o is a language model utilized for various tasks including table cell captioning and evidence extraction.&lt;SEP&gt;GPT-4o is a system that is being compared to ChartCitor for its accuracy in processing chart-based questions.</data>
      <data key="d3">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc&lt;SEP&gt;chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907761</data>
    </node>
    <node id="LLM Pre-filtering Agent">
      <data key="d0">LLM Pre-filtering Agent</data>
      <data key="d1">organization</data>
      <data key="d2">The LLM Pre-filtering Agent uses chain-of-thought prompting techniques to filter irrelevant rows and columns from tables.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907667</data>
    </node>
    <node id="LLM Re-ranking Agent">
      <data key="d0">LLM Re-ranking Agent</data>
      <data key="d1">category</data>
      <data key="d2">The LLM Re-ranking Agent is responsible for re-ranking extracted table cells to ensure they are relevant to answer claims.&lt;SEP&gt;The LLM Re-ranking Agent involves a selection process that improves the ranking of generated responses or answers.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58&lt;SEP&gt;chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="Table Cell Retrieval">
      <data key="d0">Table Cell Retrieval</data>
      <data key="d1">event</data>
      <data key="d2">The Table Cell Retrieval event involves identifying relevant table cells through a two-step retrieval and ranking process.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907667</data>
    </node>
    <node id="TabCite benchmark">
      <data key="d0">TabCite benchmark</data>
      <data key="d1">category</data>
      <data key="d2">The TabCite benchmark is a dataset used for evaluating performance in converting data tables into visual formats.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907667</data>
    </node>
    <node id="Visual Intersection over Union (IoU)">
      <data key="d0">Visual Intersection over Union (IoU)</data>
      <data key="d1">category</data>
      <data key="d2">Visual Intersection over Union (IoU) is a metric used to evaluate the performance of chart attribution tasks.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907668</data>
    </node>
    <node id="ChatGPT">
      <data key="d0">ChatGPT</data>
      <data key="d1">organization</data>
      <data key="d2">ChatGPT is the base multimodal language model employed in the ChartCitor project.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907668</data>
    </node>
    <node id="Kosmos-2">
      <data key="d0">Kosmos-2</data>
      <data key="d1">organization</data>
      <data key="d2">Kosmos-2 is a multimodal language model with text-to-visual grounding capabilities for generating bounding boxes.&lt;SEP&gt;Kosmos-2 is one of the tested models in the evaluation of visual chart understanding, known for its low performance in handling complex geometrical proportions.&lt;SEP&gt;Kosmos-2 is an object detection algorithm that scored 3.89 IoU, indicating limitations in handling complex visual reasoning tasks.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58&lt;SEP&gt;chunk-9af5c81195bb45458709701521978b72&lt;SEP&gt;chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907759</data>
    </node>
    <node id="LISA">
      <data key="d0">LISA</data>
      <data key="d1">organization</data>
      <data key="d2">LISA is a reasoning-based model that generates segmentation masks from complex textual queries.&lt;SEP&gt;LISA is another tested model that performed poorly in the evaluation compared to ChartCitor, especially in terms of visual and numerical reasoning.&lt;SEP&gt;LISA is another object detection algorithm that scored 4.34 IoU, suggesting its inefficacy compared to advanced models.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58&lt;SEP&gt;chunk-9af5c81195bb45458709701521978b72&lt;SEP&gt;chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907760</data>
    </node>
    <node id="Captioning Agent">
      <data key="d0">Captioning Agent</data>
      <data key="d1">organization</data>
      <data key="d2">The Captioning Agent is responsible for describing the importance of each cell in the context of its associated row and column headers.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907668</data>
    </node>
    <node id="Cell Captioning">
      <data key="d0">Cell Captioning</data>
      <data key="d1">event</data>
      <data key="d2">Cell Captioning is a process involving the generation of descriptions for individual cells in a table based on their context within rows and columns.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907668</data>
    </node>
    <node id="Retrieve-then-rank approach">
      <data key="d0">Retrieve-then-rank approach</data>
      <data key="d1">category</data>
      <data key="d2">The Retrieve-then-rank approach is a method used to identify the most relevant table cells by first filtering then ranking them.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907668</data>
    </node>
    <node id="LLM-based pre-filtering">
      <data key="d0">LLM-based pre-filtering</data>
      <data key="d1">category</data>
      <data key="d2">LLM-based pre-filtering is a technique used to filter out irrelevant rows and columns to enhance the relevance of data retrieved.</data>
      <data key="d3">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907669</data>
    </node>
    <node id="User Study">
      <data key="d0">User Study</data>
      <data key="d1">event</data>
      <data key="d2">The user study involved participants evaluating the citation accuracy and perceived utility of fine-grained chart attribution provided by ChartCitor against GPT-4o.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907669</data>
    </node>
    <node id="Participants">
      <data key="d0">Participants</data>
      <data key="d1">person</data>
      <data key="d2">Participants in the user study evaluated 250 question-answer pairs and their associated chart images, contributing to the assessment of ChartCitor's effectiveness.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907669</data>
    </node>
    <node id="Chart-Based Question Answering">
      <data key="d0">Chart-Based Question Answering</data>
      <data key="d1">category</data>
      <data key="d2">Chart-based question answering refers to the process of generating answers based on data visualized in charts, evaluated in the context of user study.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907669</data>
    </node>
    <node id="Documentation on Chart Attribution">
      <data key="d0">Documentation on Chart Attribution</data>
      <data key="d1">category</data>
      <data key="d2">Documentation on chart attribution discusses the methodology and results related to the citations provided by different models in the study.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907669</data>
    </node>
    <node id="LLMs">
      <data key="d0">LLMs</data>
      <data key="d1">category</data>
      <data key="d2">LLMs refer to large language models that are used in various tasks, including generating answers to questions and providing citations.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907669</data>
    </node>
    <node id="Fine-Grained Chart Attribution">
      <data key="d0">Fine-Grained Chart Attribution</data>
      <data key="d1">category</data>
      <data key="d2">Fine-grained chart attribution relates to the detailed referencing and context provided for elements within charts used in data representation.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Bounding Boxes">
      <data key="d0">Bounding Boxes</data>
      <data key="d1">category</data>
      <data key="d2">Bounding boxes are rectangular areas used to identify and segment specific elements within visual data representations like charts.</data>
      <data key="d3">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="ale Fung">
      <data key="d0">ale Fung</data>
      <data key="d1">person</data>
      <data key="d2">ale Fung is an author of a survey regarding hallucination in natural language generation.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Ehsan Kamalloo">
      <data key="d0">Ehsan Kamalloo</data>
      <data key="d1">person</data>
      <data key="d2">Ehsan Kamalloo is a co-author of a dataset for generative information-seeking with attribution.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Aref Jafari">
      <data key="d0">Aref Jafari</data>
      <data key="d1">person</data>
      <data key="d2">Aref Jafari is a co-author working alongside Ehsan Kamalloo on a collaborative dataset in generative information-seeking.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Xinyu Zhang">
      <data key="d0">Xinyu Zhang</data>
      <data key="d1">person</data>
      <data key="d2">Xinyu Zhang is a contributor involved in the HAGRID dataset project for generative information-seeking.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Nandan Thakur">
      <data key="d0">Nandan Thakur</data>
      <data key="d1">person</data>
      <data key="d2">Nandan Thakur is among the authors of the Human-LLM Collaborative Dataset for Generative Information-Seeking.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Jimmy Lin">
      <data key="d0">Jimmy Lin</data>
      <data key="d1">person</data>
      <data key="d2">Jimmy Lin is a co-author associated with the HAGRID dataset and its research.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907670</data>
    </node>
    <node id="Xin Lai">
      <data key="d0">Xin Lai</data>
      <data key="d1">person</data>
      <data key="d2">Xin Lai is a researcher and co-author on a paper discussing reasoning segmentation via large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Zhuotao Tian">
      <data key="d0">Zhuotao Tian</data>
      <data key="d1">person</data>
      <data key="d2">Zhuotao Tian is a co-author involved in the research on reasoning segmentation with large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Yukang Chen">
      <data key="d0">Yukang Chen</data>
      <data key="d1">person</data>
      <data key="d2">Yukang Chen is a contributor to the research on reasoning segmentation via large language model applications.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Yanwei Li">
      <data key="d0">Yanwei Li</data>
      <data key="d1">person</data>
      <data key="d2">Yanwei Li is a co-author on the paper concerning reasoning segmentation.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Yuhui Yuan">
      <data key="d0">Yuhui Yuan</data>
      <data key="d1">person</data>
      <data key="d2">Yuhui Yuan is involved in the research detailing large language model-based reasoning segmentation.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Shu Liu">
      <data key="d0">Shu Liu</data>
      <data key="d1">person</data>
      <data key="d2">Shu Liu is a contributing author in the research on reasoning segmentation linked with large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Jiaya Jia">
      <data key="d0">Jiaya Jia</data>
      <data key="d1">person</data>
      <data key="d2">Jiaya Jia is a co-author of the paper regarding reasoning segmentation using language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Alexa Siu">
      <data key="d0">Alexa Siu</data>
      <data key="d1">person</data>
      <data key="d2">Alexa Siu is a researcher and co-author of the MATSA project focusing on multi-agent table structure attribution.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907671</data>
    </node>
    <node id="Nedim Lipka">
      <data key="d0">Nedim Lipka</data>
      <data key="d1">person</data>
      <data key="d2">Nedim Lipka is involved as a co-author in the MATSA project regarding table structure attribution.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907672</data>
    </node>
    <node id="Tong Sun">
      <data key="d0">Tong Sun</data>
      <data key="d1">person</data>
      <data key="d2">Tong Sun is a co-author participating in the research on multi-agent table structure attribution.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907672</data>
    </node>
    <node id="Baharan Nouriinanloo">
      <data key="d0">Baharan Nouriinanloo</data>
      <data key="d1">person</data>
      <data key="d2">Baharan Nouriinanloo is a co-author of a study investigating pre-filtering for re-ranking with large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907672</data>
    </node>
    <node id="Maxime Lamothe">
      <data key="d0">Maxime Lamothe</data>
      <data key="d1">person</data>
      <data key="d2">Maxime Lamothe is a co-author on the research dealing with re-ranking steps and large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907672</data>
    </node>
    <node id="Zhiliang Peng">
      <data key="d0">Zhiliang Peng</data>
      <data key="d1">person</data>
      <data key="d2">Zhiliang Peng is a co-author on a paper discussing the grounding of multimodal large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907672</data>
    </node>
    <node id="Wenhui Wang">
      <data key="d0">Wenhui Wang</data>
      <data key="d1">person</data>
      <data key="d2">Wenhui Wang is involved in the study concerning the grounding and practicality of multimodal models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907672</data>
    </node>
    <node id="Li Dong">
      <data key="d0">Li Dong</data>
      <data key="d1">person</data>
      <data key="d2">Li Dong is a contributor to research on grounding multimodal large language models in real-world contexts.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907673</data>
    </node>
    <node id="Yaru Hao">
      <data key="d0">Yaru Hao</data>
      <data key="d1">person</data>
      <data key="d2">Yaru Hao is part of the research team focusing on grounding for multimodal applications.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907673</data>
    </node>
    <node id="Shaohan Huang">
      <data key="d0">Shaohan Huang</data>
      <data key="d1">person</data>
      <data key="d2">Shaohan Huang is a co-author in the work pertaining to multimodal grounding in large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907673</data>
    </node>
    <node id="Shuming Ma">
      <data key="d0">Shuming Ma</data>
      <data key="d1">person</data>
      <data key="d2">Shuming Ma is a researcher contributing to the study of large language models and their grounding techniques.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907673</data>
    </node>
    <node id="Furu Wei">
      <data key="d0">Furu Wei</data>
      <data key="d1">person</data>
      <data key="d2">Furu Wei is a co-author associated with grounding techniques for multimodal large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907674</data>
    </node>
    <node id="Noah Shinn">
      <data key="d0">Noah Shinn</data>
      <data key="d1">person</data>
      <data key="d2">Noah Shinn is a co-author of research on autonomous agents with dynamic memory and self-reflection.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907674</data>
    </node>
    <node id="Beck Labash">
      <data key="d0">Beck Labash</data>
      <data key="d1">person</data>
      <data key="d2">Beck Labash is a contributor working alongside Noah Shinn on autonomous agents.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907674</data>
    </node>
    <node id="Ashwin Gopinath">
      <data key="d0">Ashwin Gopinath</data>
      <data key="d1">person</data>
      <data key="d2">Ashwin Gopinath is involved in the research on autonomous agents focusing on dynamic memory.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907674</data>
    </node>
    <node id="Ben Snyder">
      <data key="d0">Ben Snyder</data>
      <data key="d1">person</data>
      <data key="d2">Ben Snyder is a co-author working on early detection of hallucinations in factual question answering.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907674</data>
    </node>
    <node id="Marius Moisescu">
      <data key="d0">Marius Moisescu</data>
      <data key="d1">person</data>
      <data key="d2">Marius Moisescu is a contributor involved in the study of hallucinations and factual answering.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907674</data>
    </node>
    <node id="Muhammad Bilal Zafar">
      <data key="d0">Muhammad Bilal Zafar</data>
      <data key="d1">person</data>
      <data key="d2">Muhammad Bilal Zafar is a co-author in the research on hallucination detection.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907675</data>
    </node>
    <node id="Weiwei Sun">
      <data key="d0">Weiwei Sun</data>
      <data key="d1">person</data>
      <data key="d2">Weiwei Sun is a co-author studying the performance of chat models in search and re-ranking roles.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907675</data>
    </node>
    <node id="Lingyong Yan">
      <data key="d0">Lingyong Yan</data>
      <data key="d1">person</data>
      <data key="d2">Lingyong Yan is involved in the ChatGPT research evaluating its search capabilities.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907675</data>
    </node>
    <node id="Xinyu Ma">
      <data key="d0">Xinyu Ma</data>
      <data key="d1">person</data>
      <data key="d2">Xinyu Ma is a contributor in the study of large language models as re-ranking agents.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907675</data>
    </node>
    <node id="Shuaiqiang Wang">
      <data key="d0">Shuaiqiang Wang</data>
      <data key="d1">person</data>
      <data key="d2">Shuaiqiang Wang is a co-author in research examining the efficacy of chat models in search.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907675</data>
    </node>
    <node id="Pengjie Ren">
      <data key="d0">Pengjie Ren</data>
      <data key="d1">person</data>
      <data key="d2">Pengjie Ren is involved in the ChatGPT study regarding its search performance.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907675</data>
    </node>
    <node id="Zhumin Chen">
      <data key="d0">Zhumin Chen</data>
      <data key="d1">person</data>
      <data key="d2">Zhumin Chen is a contributor to the research on ChatGPT's searching and re-ranking efficacy.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907676</data>
    </node>
    <node id="Dawei Yin">
      <data key="d0">Dawei Yin</data>
      <data key="d1">person</data>
      <data key="d2">Dawei Yin is involved in the study evaluating ChatGPT as a re-ranking agent.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907676</data>
    </node>
    <node id="Zhaochun Ren">
      <data key="d0">Zhaochun Ren</data>
      <data key="d1">person</data>
      <data key="d2">Zhaochun Ren is a co-author examining ChatGPT's performance in search-related tasks.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907676</data>
    </node>
    <node id="Hugo Touvron">
      <data key="d0">Hugo Touvron</data>
      <data key="d1">person</data>
      <data key="d2">Hugo Touvron is a co-author of a paper regarding efficient foundation language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Thibaut Lavril">
      <data key="d0">Thibaut Lavril</data>
      <data key="d1">person</data>
      <data key="d2">Thibaut Lavril is involved in the research on open and efficient foundation language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Gautier Izacard">
      <data key="d0">Gautier Izacard</data>
      <data key="d1">person</data>
      <data key="d2">Gautier Izacard is a co-author contributing to the research on foundation language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Xavier Martinet">
      <data key="d0">Xavier Martinet</data>
      <data key="d1">person</data>
      <data key="d2">Xavier Martinet is involved in the study focused on open foundation models in language processing.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Marie-Anne Lachaux">
      <data key="d0">Marie-Anne Lachaux</data>
      <data key="d1">person</data>
      <data key="d2">Marie-Anne Lachaux is a co-author studying efficient language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Timothée Lacroix">
      <data key="d0">Timothée Lacroix</data>
      <data key="d1">person</data>
      <data key="d2">Timothée Lacroix is involved as a contributor to research on foundation language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Baptiste Rozière">
      <data key="d0">Baptiste Rozière</data>
      <data key="d1">person</data>
      <data key="d2">Baptiste Rozière is a co-author working on innovative approaches in language model efficiency.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907677</data>
    </node>
    <node id="Naman Goyal">
      <data key="d0">Naman Goyal</data>
      <data key="d1">person</data>
      <data key="d2">Naman Goyal is involved in the research on foundation language models and their efficiency.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Eric Hambro">
      <data key="d0">Eric Hambro</data>
      <data key="d1">person</data>
      <data key="d2">Eric Hambro is a contributor to the study on open language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Faisal Azhar">
      <data key="d0">Faisal Azhar</data>
      <data key="d1">person</data>
      <data key="d2">Faisal Azhar is involved in researching efficient approaches to foundation language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Lei Wang">
      <data key="d0">Lei Wang</data>
      <data key="d1">person</data>
      <data key="d2">Lei Wang is a co-author engaged in the study on prompt improvement for reasoning by language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Wanyu Xu">
      <data key="d0">Wanyu Xu</data>
      <data key="d1">person</data>
      <data key="d2">Wanyu Xu is part of the research team focusing on zero-shot reasoning using language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Yihuai Lan">
      <data key="d0">Yihuai Lan</data>
      <data key="d1">person</data>
      <data key="d2">Yihuai Lan is a contributor to the study examining prompt improvement for large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Zhiqiang Hu">
      <data key="d0">Zhiqiang Hu</data>
      <data key="d1">person</data>
      <data key="d2">Zhiqiang Hu is involved in enhancing reasoning capabilities of language models through prompting.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Yunshi Lan">
      <data key="d0">Yunshi Lan</data>
      <data key="d1">person</data>
      <data key="d2">Yunshi Lan is a co-author of research aimed at improving reasoning in language model outputs.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907678</data>
    </node>
    <node id="Roy Ka-Wei Lee">
      <data key="d0">Roy Ka-Wei Lee</data>
      <data key="d1">person</data>
      <data key="d2">Roy Ka-Wei Lee is involved in research focusing on large language models and reasoning.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907679</data>
    </node>
    <node id="Ee-Peng Lim">
      <data key="d0">Ee-Peng Lim</data>
      <data key="d1">person</data>
      <data key="d2">Ee-Peng Lim is a co-author engaged in the study on prompt-based reasoning techniques.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907679</data>
    </node>
    <node id="Jason Wei">
      <data key="d0">Jason Wei</data>
      <data key="d1">person</data>
      <data key="d2">Jason Wei is a co-author on research that prompts reasoning in large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907679</data>
    </node>
    <node id="Xuezhi Wang">
      <data key="d0">Xuezhi Wang</data>
      <data key="d1">person</data>
      <data key="d2">Xuezhi Wang is involved as a contributor to the research on reasoning prompting in language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907679</data>
    </node>
    <node id="Dale Schuurmans">
      <data key="d0">Dale Schuurmans</data>
      <data key="d1">person</data>
      <data key="d2">Dale Schuurmans is a co-author participating in the reasoning prompting study.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907679</data>
    </node>
    <node id="Maarten Bosma">
      <data key="d0">Maarten Bosma</data>
      <data key="d1">person</data>
      <data key="d2">Maarten Bosma is involved in the research on prompting for reasoning in language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907680</data>
    </node>
    <node id="Ed Huai hsin Chi">
      <data key="d0">Ed Huai hsin Chi</data>
      <data key="d1">person</data>
      <data key="d2">Ed Huai hsin Chi is a co-author contributing to the findings on reasoning prompting.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907680</data>
    </node>
    <node id="F. Xia">
      <data key="d0">F. Xia</data>
      <data key="d1">person</data>
      <data key="d2">F. Xia is involved in research focused on reasoning prompting in large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907680</data>
    </node>
    <node id="Quoc Le">
      <data key="d0">Quoc Le</data>
      <data key="d1">person</data>
      <data key="d2">Quoc Le is a co-author studying prompting techniques for reasoning in language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907681</data>
    </node>
    <node id="Denny Zhou">
      <data key="d0">Denny Zhou</data>
      <data key="d1">person</data>
      <data key="d2">Denny Zhou is involved in advancing methodologies in reasoning prompting for language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907681</data>
    </node>
    <node id="Ziwei Xu">
      <data key="d0">Ziwei Xu</data>
      <data key="d1">person</data>
      <data key="d2">Ziwei Xu is a co-author studying hallucinations as an innate limitation of large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907681</data>
    </node>
    <node id="Sanjay Jain">
      <data key="d0">Sanjay Jain</data>
      <data key="d1">person</data>
      <data key="d2">Sanjay Jain is involved in the research examining hallucinations in language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907681</data>
    </node>
    <node id="Mohan S. Kankanhalli">
      <data key="d0">Mohan S. Kankanhalli</data>
      <data key="d1">person</data>
      <data key="d2">Mohan S. Kankanhalli is a co-author of the study discussing hallucination limitations in LLMs.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907682</data>
    </node>
    <node id="Jianwei Yang">
      <data key="d0">Jianwei Yang</data>
      <data key="d1">person</data>
      <data key="d2">Jianwei Yang is a co-author focusing on innovative prompting techniques for large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907682</data>
    </node>
    <node id="Hao Zhang">
      <data key="d0">Hao Zhang</data>
      <data key="d1">person</data>
      <data key="d2">Hao Zhang is involved in research concerning advanced prompting methodologies for LLMs.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907682</data>
    </node>
    <node id="Feng Li">
      <data key="d0">Feng Li</data>
      <data key="d1">person</data>
      <data key="d2">Feng Li is a contributor to studies on innovative prompting in large language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907683</data>
    </node>
    <node id="Xueyan Zou">
      <data key="d0">Xueyan Zou</data>
      <data key="d1">person</data>
      <data key="d2">Xueyan Zou is co-authoring research focused on creative prompting for LLM performance.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907683</data>
    </node>
    <node id="Chunyu Li">
      <data key="d0">Chunyu Li</data>
      <data key="d1">person</data>
      <data key="d2">Chunyu Li is involved in the research centered on prompting strategies for language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="Jianfeng Gao">
      <data key="d0">Jianfeng Gao</data>
      <data key="d1">person</data>
      <data key="d2">Jianfeng Gao is a co-author studying prompt-based reasoning improvements in language models.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="Chain of Thought Prompting">
      <data key="d0">Chain of Thought Prompting</data>
      <data key="d1">category</data>
      <data key="d2">Chain of Thought Prompting is a method aimed at eliciting reasoning in large language models by guiding their thought processes.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="Early Detection of Hallucinations">
      <data key="d0">Early Detection of Hallucinations</data>
      <data key="d1">category</data>
      <data key="d2">Early Detection of Hallucinations refers to methods and research focusing on identifying hallucinations in factual question answering systems.</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="ArXiv">
      <data key="d0">ArXiv</data>
      <data key="d1">organization</data>
      <data key="d2">ArXiv is a repository of electronic preprints in various scientific fields where researchers can share their work.</data>
      <data key="d3">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="2023">
      <data key="d0">2023</data>
      <data key="d1">event</data>
      <data key="d2">The year 2023 is mentioned, indicating the context in which the document or data entry is relevant.</data>
      <data key="d3">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="266149987">
      <data key="d0">266149987</data>
      <data key="d1">category</data>
      <data key="d2">This number appears to be an identifier for a specific document or research entry in the Semantics Scholar database.</data>
      <data key="d3">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907684</data>
    </node>
    <node id="Semantics Scholar">
      <data key="d0">Semantics Scholar</data>
      <data key="d1">organization</data>
      <data key="d2">Semantics Scholar is a research tool that provides access to scholarly articles, helping researchers find relevant literature and citations.</data>
      <data key="d3">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907685</data>
    </node>
    <node id="Corpus ID: 266149987">
      <data key="d0">Corpus ID: 266149987</data>
      <data key="d1">category</data>
      <data key="d2">Corpus ID: 266149987 serves as a unique identifier for a specific research entry in the Semantics Scholar database.</data>
      <data key="d3">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907686</data>
    </node>
    <node id="Survey of hallucination in natural language generation">
      <data key="d0">Survey of hallucination in natural language generation</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">The work authored by ale Fung focuses on hallucination in natural language generation."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907719</data>
    </node>
    <node id="HAGRID Dataset">
      <data key="d0">HAGRID Dataset</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Ehsan Kamalloo is a co-author of the HAGRID dataset research, contributing to collaborative data initiatives."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907721</data>
    </node>
    <node id="MATSA Project">
      <data key="d0">MATSA Project</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Puneet Mathur is involved in the creation of the MATSA project focused on multi-agent table structure attribution."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907721</data>
    </node>
    <node id="ChatGPT Performance Study">
      <data key="d0">ChatGPT Performance Study</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Weiwei Sun studies the effectiveness of ChatGPT as a re-ranking agent in search tasks."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907722</data>
    </node>
    <node id="Foundation Language Models">
      <data key="d0">Foundation Language Models</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Hugo Touvron contributes to research focused on the efficiency and openness of foundation language models."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907722</data>
    </node>
    <node id="Prompting Techniques">
      <data key="d0">Prompting Techniques</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Jason Wei's research investigates the effectiveness of prompting techniques in eliciting reasoning within language models."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907722</data>
    </node>
    <node id="Hallucination Limitations">
      <data key="d0">Hallucination Limitations</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Ziwei Xu's work discusses hallucination as an innate limitation in large language models."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907723</data>
    </node>
    <node id="MATSA: MultiAgent Table Structure Attribution">
      <data key="d0">MATSA: MultiAgent Table Structure Attribution</data>
      <data key="d3">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d2">Puneet Mathur's involvement in the MATSA project revolves around developing techniques for multi-agent structured data attribution."|</data>
      <data key="d1">UNKNOWN</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907723</data>
    </node>
    <node id="ChartCitor Workflow Diagram (image)">
      <data key="d0">ChartCitor Workflow Diagram (image)</data>
      <data key="d1">image</data>
      <data key="d2">The image is a diagram depicting the workflow of ChartCitor, a system for structured chart attribution. It visually breaks down the process into distinct agents: Table Extraction, Entity Captioning, Answer Reformulation, Prefiltering, Re-ranking, and Cell Localization, each linked in a logical, color-coded sequence geared towards providing detailed citations for chart data.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907742</data>
    </node>
    <node id="Chart Object Detection Performance Comparison (table)">
      <data key="d0">Chart Object Detection Performance Comparison (table)</data>
      <data key="d1">table</data>
      <data key="d2">This table compares the IoU scores of various chart detection methods. ChartCitor leads with an IoU of 27.4, significantly outperforming others, thus illustrating the effectiveness of enhanced LLM techniques in visual data interpretation.</data>
      <data key="d3">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907742</data>
    </node>
    <node id="Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)">
      <data key="d0">Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)</data>
      <data key="d1">image</data>
      <data key="d2">A bar chart visualizes the comparison of perceived accuracy between ChartCitor and GPT-4o in user evaluations. It shows higher complete accuracy for ChartCitor, while GPT-4o appears more often as completely inaccurate, reflecting the documented user study context for chart question-answering performance assessments.</data>
      <data key="d3">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907742</data>
    </node>
    <node id="Table Extraction Agent">
      <data key="d0">Table Extraction Agent</data>
      <data key="d1">category</data>
      <data key="d2">The Table Extraction Agent is a component of ChartCitor that processes input charts into HTML format using self-reflection and examples.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="Entity Captioning Agent">
      <data key="d0">Entity Captioning Agent</data>
      <data key="d1">category</data>
      <data key="d2">The Entity Captioning Agent generates captions for different chart elements, such as row, column, and cell captions, linked to an HTML Table.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="Answer Reformulation Agent">
      <data key="d0">Answer Reformulation Agent</data>
      <data key="d1">category</data>
      <data key="d2">The Answer Reformulation Agent breaks down answers into atomic facts for clarity and accuracy.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="LLM Prefiltering Agent">
      <data key="d0">LLM Prefiltering Agent</data>
      <data key="d1">category</data>
      <data key="d2">The LLM Prefiltering Agent uses a score filter mechanism to assign relevance scores to rows and columns of data.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="Cell Localization Agent">
      <data key="d0">Cell Localization Agent</data>
      <data key="d1">category</data>
      <data key="d2">The Cell Localization Agent utilizes 'DETR' for mapping elements of charts, aiding in accurate cell identification.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="HTML Table">
      <data key="d0">HTML Table</data>
      <data key="d1">category</data>
      <data key="d2">The HTML Table is a structured format for displaying tabular data, utilized by various agents in the ChartCitor framework.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907757</data>
    </node>
    <node id="Score Filter">
      <data key="d0">Score Filter</data>
      <data key="d1">category</data>
      <data key="d2">The Score Filter is a mechanism employed by the LLM Prefiltering Agent to assess the relevance of data rows and columns.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907759</data>
    </node>
    <node id="Bounding Box Illustrations">
      <data key="d0">Bounding Box Illustrations</data>
      <data key="d1">category</data>
      <data key="d2">Bounding Box Illustrations are visuals used by the Cell Localization Agent to represent mapped chart elements for identification.</data>
      <data key="d3">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907759</data>
    </node>
    <node id="DETR">
      <data key="d0">DETR</data>
      <data key="d1">organization</data>
      <data key="d2">DETR is an object detection algorithm that, when combined with Set-of-Marks prompting, achieved an IoU score of 18.6.</data>
      <data key="d3">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907759</data>
    </node>
    <node id="Claude-3.5">
      <data key="d0">Claude-3.5</data>
      <data key="d1">organization</data>
      <data key="d2">Claude-3.5 employs Sonnet Direct Bbox Decoding and achieved an IoU score of 13.8 in the evaluations.</data>
      <data key="d3">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907760</data>
    </node>
    <node id="Intersection over Union (IoU)">
      <data key="d0">Intersection over Union (IoU)</data>
      <data key="d1">category</data>
      <data key="d2">Intersection over Union (IoU) is a metric used to quantify the accuracy of object detection algorithms based on their predicted and ground truth bounding boxes.</data>
      <data key="d3">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907761</data>
    </node>
    <node id="Set-of-Marks Prompting">
      <data key="d0">Set-of-Marks Prompting</data>
      <data key="d1">category</data>
      <data key="d2">Set-of-Marks Prompting is a technique used in conjunction with the DETR object detection method to enhance its performance, achieving an IoU score of 18.6.</data>
      <data key="d3">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907761</data>
    </node>
    <node id="Traditional Models">
      <data key="d0">Traditional Models</data>
      <data key="d1">category</data>
      <data key="d2">Traditional models refer to older object detection algorithms, such as Kosmos-2 and LISA, which exhibited lower performance in IoU metrics compared to more advanced techniques.</data>
      <data key="d3">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907761</data>
    </node>
    <node id="Accuracy Comparison">
      <data key="d0">Accuracy Comparison</data>
      <data key="d1">event</data>
      <data key="d2">Accuracy Comparison refers to the evaluative process in which the perceived accuracy of ChartCitor and GPT-4o is assessed through visual representation in a bar chart.</data>
      <data key="d3">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907762</data>
    </node>
    <node id="Bar Chart">
      <data key="d0">Bar Chart</data>
      <data key="d1">category</data>
      <data key="d2">The Bar Chart is a visual representation that compares the accuracy perceptions of ChartCitor and GPT-4o across different categories of accuracy.</data>
      <data key="d3">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d4">2502.00989v1.pdf</data>
      <data key="d5">1757907762</data>
    </node>
    <edge source="ChartCitor" target="Kanika Goswami">
      <data key="d6">8.0</data>
      <data key="d7">Kanika Goswami is one of the authors who contributed to the development and presentation of the ChartCitor framework.</data>
      <data key="d8">author,contribution</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907700</data>
    </edge>
    <edge source="ChartCitor" target="Puneet Mathur">
      <data key="d6">8.0</data>
      <data key="d7">Puneet Mathur is a co-author involved in the ChartCitor project, contributing to its research and implementation.</data>
      <data key="d8">author,contribution</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907702</data>
    </edge>
    <edge source="ChartCitor" target="Ryan Rossi">
      <data key="d6">8.0</data>
      <data key="d7">Ryan Rossi's work at Adobe Research contributes to the development of the ChartCitor framework and its capabilities.</data>
      <data key="d8">author,contribution</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907703</data>
    </edge>
    <edge source="ChartCitor" target="Franck Dernoncourt">
      <data key="d6">8.0</data>
      <data key="d7">Franck Dernoncourt collaborates with other authors on the ChartCitor project, contributing to its research and findings.</data>
      <data key="d8">author,contribution</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907704</data>
    </edge>
    <edge source="ChartCitor" target="Fine-grained Structured Chart Attribution">
      <data key="d6">10.0</data>
      <data key="d7">ChartCitor addresses the Fine-grained Structured Chart Attribution challenge by providing targeted citations from charts.</data>
      <data key="d8">solution,task focus</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907706</data>
    </edge>
    <edge source="ChartCitor" target="Information Systems">
      <data key="d6">7.0</data>
      <data key="d7">ChartCitor functions within the realm of Information Systems by providing mechanisms to extract and validate information from charts.</data>
      <data key="d8">data extraction,validation</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907707</data>
    </edge>
    <edge source="ChartCitor" target="Visual Fact Checking">
      <data key="d6">9.0</data>
      <data key="d7">ChartCitor enhances Visual Fact Checking capabilities by providing reliable citations for generated answers grounded in chart images.</data>
      <data key="d8">fact verification,reliability</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907709</data>
    </edge>
    <edge source="ChartCitor" target="Multimodal Retrieval">
      <data key="d6">8.0</data>
      <data key="d7">ChartCitor engages in Multimodal Retrieval by sourcing data from visual components of charts and integrating them with text responses.</data>
      <data key="d8">data integration,multimodal approach</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907710</data>
    </edge>
    <edge source="ChartCitor" target="GPT-4o">
      <data key="d6">17.0</data>
      <data key="d7">ChartCitor utilizes GPT-4o for various tasks, including generating captions for table cells and chart attribution.&lt;SEP&gt;ChartCitor and GPT-4o are being directly compared regarding their perceived accuracy in the bar chart analysis.</data>
      <data key="d8">accuracy assessment,application,system comparison,utilization</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc&lt;SEP&gt;chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907800</data>
    </edge>
    <edge source="ChartCitor" target="Table Cell Retrieval">
      <data key="d6">8.0</data>
      <data key="d7">The Table Cell Retrieval event is an integral part of the ChartCitor project's process for extracting and processing data.</data>
      <data key="d8">data processing,integration</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907713</data>
    </edge>
    <edge source="ChartCitor" target="Visual Intersection over Union (IoU)">
      <data key="d6">7.0</data>
      <data key="d7">Visual Intersection over Union (IoU) is a metric used to evaluate the effectiveness of the ChartCitor in visual tasks.</data>
      <data key="d8">evaluation,performance metric</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907714</data>
    </edge>
    <edge source="ChartCitor" target="Kosmos-2">
      <data key="d6">16.0</data>
      <data key="d7">Kosmos-2 is compared to ChartCitor in the context of evaluating visual grounding capabilities.&lt;SEP&gt;ChartCitor shows a profound improvement over the traditional model Kosmos-2, which scored low in IoU.</data>
      <data key="d8">comparison,performance advantage,performance evaluation,traditional vs. advanced</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58&lt;SEP&gt;chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907793</data>
    </edge>
    <edge source="ChartCitor" target="LISA">
      <data key="d6">15.0</data>
      <data key="d7">LISA is benchmarked against ChartCitor in generating segmentation masks for visual grounding tasks.&lt;SEP&gt;ChartCitor's IoU is markedly higher than that of LISA, indicating its advanced capabilities.</data>
      <data key="d8">algorithm comparison,benchmarking,performance advantage,performance assessment</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58&lt;SEP&gt;chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907794</data>
    </edge>
    <edge source="ChartCitor" target="User Study">
      <data key="d6">8.0</data>
      <data key="d7">The user study aims to evaluate the effectiveness of ChartCitor in providing accurate citations and utility in chart-based question answering.</data>
      <data key="d8">effectiveness,evaluation</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907723</data>
    </edge>
    <edge source="ChartCitor" target="LLMs">
      <data key="d6">8.0</data>
      <data key="d7">ChartCitor is designed to work with LLMs to improve the accuracy of quality assurance responses regarding charts and visual data.</data>
      <data key="d8">collaboration,model enhancement</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907725</data>
    </edge>
    <edge source="ChartCitor" target="Fine-Grained Chart Attribution">
      <data key="d6">9.0</data>
      <data key="d7">ChartCitor aims to enhance fine-grained chart attribution for improved citation accuracy and utility in chart-based question answering.</data>
      <data key="d8">attribution improvement,citation accuracy</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907726</data>
    </edge>
    <edge source="ChartCitor" target="Bounding Boxes">
      <data key="d6">7.0</data>
      <data key="d7">ChartCitor utilizes bounding boxes to provide better segmentation of visual chart elements for analysis and data understanding.</data>
      <data key="d8">data analysis,segmentation technique</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907727</data>
    </edge>
    <edge source="ChartCitor" target="Table Extraction Agent">
      <data key="d6">9.0</data>
      <data key="d7">The Table Extraction Agent is a fundamental part of the ChartCitor framework, handling initial chart data processing.</data>
      <data key="d8">component relationship,function</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907778</data>
    </edge>
    <edge source="ChartCitor" target="Entity Captioning Agent">
      <data key="d6">9.0</data>
      <data key="d7">The Entity Captioning Agent operates within ChartCitor to enhance data presentation by generating captions for chart elements.</data>
      <data key="d8">component relationship,function</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907779</data>
    </edge>
    <edge source="ChartCitor" target="Answer Reformulation Agent">
      <data key="d6">9.0</data>
      <data key="d7">The Answer Reformulation Agent is part of the ChartCitor workflow, focusing on refining user-generated answers.</data>
      <data key="d8">component relationship,function</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907781</data>
    </edge>
    <edge source="ChartCitor" target="LLM Prefiltering Agent">
      <data key="d6">9.0</data>
      <data key="d7">The LLM Prefiltering Agent contributes to the ChartCitor's efficiency by filtering and scoring relevant data.</data>
      <data key="d8">component relationship,function</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907782</data>
    </edge>
    <edge source="ChartCitor" target="LLM Re-ranking Agent">
      <data key="d6">9.0</data>
      <data key="d7">The LLM Re-ranking Agent is integrated within ChartCitor for improving the quality of answers generated.</data>
      <data key="d8">component relationship,function</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907783</data>
    </edge>
    <edge source="ChartCitor" target="Cell Localization Agent">
      <data key="d6">9.0</data>
      <data key="d7">The Cell Localization Agent plays a crucial role in ChartCitor by ensuring accurate mapping of chart components.</data>
      <data key="d8">component relationship,function</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907784</data>
    </edge>
    <edge source="ChartCitor" target="ChartCitor Workflow Diagram (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity ChartCitor belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907790</data>
    </edge>
    <edge source="ChartCitor" target="DETR">
      <data key="d6">9.0</data>
      <data key="d7">ChartCitor's performance significantly surpasses that of DETR combined with Set-of-Marks prompting in object detection.</data>
      <data key="d8">object detection,performance comparison</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907791</data>
    </edge>
    <edge source="ChartCitor" target="Chart Object Detection Performance Comparison (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity ChartCitor belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907795</data>
    </edge>
    <edge source="ChartCitor" target="Accuracy Comparison">
      <data key="d6">8.0</data>
      <data key="d7">ChartCitor is one of the systems being assessed in the Accuracy Comparison event, indicating its role in the analysis.</data>
      <data key="d8">comparative analysis,system evaluation</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907798</data>
    </edge>
    <edge source="ChartCitor" target="Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity ChartCitor belongs to Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907802</data>
    </edge>
    <edge source="ChartCitor" target="Bar Chart">
      <data key="d6">8.0</data>
      <data key="d7">ChartCitor is displayed in the Bar Chart, showing its perceived accuracy compared to GPT-4o.</data>
      <data key="d8">data representation,system evaluation</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907803</data>
    </edge>
    <edge source="Puneet Mathur" target="MATSA Project">
      <data key="d6">7.0</data>
      <data key="d7">Puneet Mathur is involved in the creation of the MATSA project focused on multi-agent table structure attribution."|</data>
      <data key="d8">project involvement</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907721</data>
    </edge>
    <edge source="Puneet Mathur" target="MATSA: MultiAgent Table Structure Attribution">
      <data key="d6">8.0</data>
      <data key="d7">Puneet Mathur's involvement in the MATSA project revolves around developing techniques for multi-agent structured data attribution."|</data>
      <data key="d8">project collaboration</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907723</data>
    </edge>
    <edge source="Llama-3.2" target="Fine-grained Structured Chart Attribution">
      <data key="d6">9.0</data>
      <data key="d7">Llama-3.2 is used in the Fine-grained Structured Chart Attribution task to enhance model capabilities in extracting evidence from charts.</data>
      <data key="d8">model application,task relevance</data>
      <data key="d9">chunk-674ae697ba691bf3c9f7514577fa45ad</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907700</data>
    </edge>
    <edge source="GPT-4V" target="User Study">
      <data key="d6">7.0</data>
      <data key="d7">The user study also compared ChartCitor to GPT-4V, assessing both for citation accuracy in responses to chart-based queries.</data>
      <data key="d8">comparison,evaluation</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907711</data>
    </edge>
    <edge source="GPT-4V" target="Claude-3.5">
      <data key="d6">7.0</data>
      <data key="d7">Both GPT-4V and Claude-3.5 are advanced object detection methods but fall short when compared to ChartCitor.</data>
      <data key="d8">advanced methods,comparative performance</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907788</data>
    </edge>
    <edge source="GPT-4V" target="Chart Object Detection Performance Comparison (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity GPT-4V belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907800</data>
    </edge>
    <edge source="GPT-4o" target="Accuracy Comparison">
      <data key="d6">8.0</data>
      <data key="d7">GPT-4o is evaluated alongside ChartCitor in the Accuracy Comparison event, highlighting its significance in the analysis.</data>
      <data key="d8">comparative analysis,system evaluation</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907799</data>
    </edge>
    <edge source="GPT-4o" target="Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity GPT-4o belongs to Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907803</data>
    </edge>
    <edge source="GPT-4o" target="Bar Chart">
      <data key="d6">8.0</data>
      <data key="d7">GPT-4o is also depicted in the Bar Chart, highlighting its perceived accuracy in comparison to ChartCitor.</data>
      <data key="d8">data representation,system evaluation</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907804</data>
    </edge>
    <edge source="LLM Pre-filtering Agent" target="LLM Re-ranking Agent">
      <data key="d6">9.0</data>
      <data key="d7">The LLM Pre-filtering Agent and LLM Re-ranking Agent are sequential steps in the overall process for citation retrieval.</data>
      <data key="d8">process flow,structured approach</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907703</data>
    </edge>
    <edge source="LLM Re-ranking Agent" target="ChartCitor Workflow Diagram (image)">
      <data key="d6">10.0</data>
      <data key="d7">Entity LLM Re-ranking Agent belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907785</data>
    </edge>
    <edge source="Kosmos-2" target="User Study">
      <data key="d6">6.0</data>
      <data key="d7">Kosmos-2 was evaluated in the user study, highlighting its weaknesses in handling the context of chart-based question answering.</data>
      <data key="d8">evaluation,performance</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907713</data>
    </edge>
    <edge source="Kosmos-2" target="Traditional Models">
      <data key="d6">7.0</data>
      <data key="d7">Kosmos-2 is classified among traditional models that scored poorly, indicating a general limitation among older object detection algorithms.</data>
      <data key="d8">algorithm classification,performance limitation</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907790</data>
    </edge>
    <edge source="Kosmos-2" target="Chart Object Detection Performance Comparison (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Kosmos-2 belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907798</data>
    </edge>
    <edge source="LISA" target="User Study">
      <data key="d6">6.0</data>
      <data key="d7">LISA's performance was also evaluated in the user study, reflecting issues in its ability to process visual chart information.</data>
      <data key="d8">evaluation,performance</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907718</data>
    </edge>
    <edge source="LISA" target="Traditional Models">
      <data key="d6">7.0</data>
      <data key="d7">LISA is also categorized as a traditional model, which demonstrates limitations in its performance metrics.</data>
      <data key="d8">algorithm classification,performance limitation</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907791</data>
    </edge>
    <edge source="LISA" target="Chart Object Detection Performance Comparison (table)">
      <data key="d6">10.0</data>
      <data key="d7">Entity LISA belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907799</data>
    </edge>
    <edge source="Captioning Agent" target="Cell Captioning">
      <data key="d6">8.0</data>
      <data key="d7">The Captioning Agent executes the Cell Captioning process to provide context for each table cell.</data>
      <data key="d8">contextualization,process implementation</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907709</data>
    </edge>
    <edge source="Retrieve-then-rank approach" target="LLM-based pre-filtering">
      <data key="d6">9.0</data>
      <data key="d7">LLM-based pre-filtering is a component of the Retrieve-then-rank approach to improve relevance in table data extraction.</data>
      <data key="d8">data relevance improvement,methodology</data>
      <data key="d9">chunk-b839fa86d69937abbbfac9da3a686d58</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907710</data>
    </edge>
    <edge source="User Study" target="Participants">
      <data key="d6">9.0</data>
      <data key="d7">Participants provided feedback in the user study, contributing to the assessment of the citation accuracy of ChartCitor and GPT-4o.</data>
      <data key="d8">assessment,feedback</data>
      <data key="d9">chunk-9af5c81195bb45458709701521978b72</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907719</data>
    </edge>
    <edge source="ale Fung" target="Survey of hallucination in natural language generation">
      <data key="d6">7.0</data>
      <data key="d7">The work authored by ale Fung focuses on hallucination in natural language generation."|</data>
      <data key="d8">research work</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907719</data>
    </edge>
    <edge source="Ehsan Kamalloo" target="HAGRID Dataset">
      <data key="d6">8.0</data>
      <data key="d7">Ehsan Kamalloo is a co-author of the HAGRID dataset research, contributing to collaborative data initiatives."|</data>
      <data key="d8">dataset research</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907721</data>
    </edge>
    <edge source="Weiwei Sun" target="ChatGPT Performance Study">
      <data key="d6">8.0</data>
      <data key="d7">Weiwei Sun studies the effectiveness of ChatGPT as a re-ranking agent in search tasks."|</data>
      <data key="d8">research focus</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907722</data>
    </edge>
    <edge source="Hugo Touvron" target="Foundation Language Models">
      <data key="d6">9.0</data>
      <data key="d7">Hugo Touvron contributes to research focused on the efficiency and openness of foundation language models."|</data>
      <data key="d8">model efficiency</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907722</data>
    </edge>
    <edge source="Hugo Touvron" target="Chain of Thought Prompting">
      <data key="d6">7.0</data>
      <data key="d7">Hugo Touvron's work on foundation language models may incorporate chain of thought prompting methodologies to boost performance."|</data>
      <data key="d8">prompting methodology</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907723</data>
    </edge>
    <edge source="Jason Wei" target="Prompting Techniques">
      <data key="d6">9.0</data>
      <data key="d7">Jason Wei's research investigates the effectiveness of prompting techniques in eliciting reasoning within language models."|</data>
      <data key="d8">prompting research</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907722</data>
    </edge>
    <edge source="Jason Wei" target="Early Detection of Hallucinations">
      <data key="d6">6.0</data>
      <data key="d7">Jason Wei's research on prompting techniques includes elements related to the early detection of hallucinations."|</data>
      <data key="d8">research intersection</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907723</data>
    </edge>
    <edge source="Ziwei Xu" target="Hallucination Limitations">
      <data key="d6">7.0</data>
      <data key="d7">Ziwei Xu's work discusses hallucination as an innate limitation in large language models."|</data>
      <data key="d8">research limitations</data>
      <data key="d9">chunk-30a776bce427dd986de9cf5abd6e011f</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907723</data>
    </edge>
    <edge source="ArXiv" target="266149987">
      <data key="d6">9.0</data>
      <data key="d7">ArXiv hosts the document identified by the number 266149987, linking the organization to the specific research entry.</data>
      <data key="d8">repository,research entry</data>
      <data key="d9">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907724</data>
    </edge>
    <edge source="ArXiv" target="Semantics Scholar">
      <data key="d6">8.0</data>
      <data key="d7">ArXiv is linked with Semantics Scholar as the document is accessible through the Semantics Scholar database, indicating its reliance on the organization for dissemination.</data>
      <data key="d8">accessibility,research dissemination</data>
      <data key="d9">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907726</data>
    </edge>
    <edge source="2023" target="266149987">
      <data key="d6">7.0</data>
      <data key="d7">The document identified by 266149987 is related to the year 2023 as it was published or referenced during that year.</data>
      <data key="d8">publication year,relevance</data>
      <data key="d9">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907725</data>
    </edge>
    <edge source="Semantics Scholar" target="Corpus ID: 266149987">
      <data key="d6">9.0</data>
      <data key="d7">The Corpus ID: 266149987 represents the specific article available through Semantics Scholar, establishing a relationship between the identifier and the organization.</data>
      <data key="d8">document identification,research organization</data>
      <data key="d9">chunk-b7255d18a8df30a4afaa5abde11b9392</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907724</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="Table Extraction Agent">
      <data key="d6">10.0</data>
      <data key="d7">Entity Table Extraction Agent belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907781</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="Entity Captioning Agent">
      <data key="d6">10.0</data>
      <data key="d7">Entity Entity Captioning Agent belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907782</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="Answer Reformulation Agent">
      <data key="d6">10.0</data>
      <data key="d7">Entity Answer Reformulation Agent belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907783</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="LLM Prefiltering Agent">
      <data key="d6">10.0</data>
      <data key="d7">Entity LLM Prefiltering Agent belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907784</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="HTML Table">
      <data key="d6">10.0</data>
      <data key="d7">Entity HTML Table belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907787</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="Score Filter">
      <data key="d6">10.0</data>
      <data key="d7">Entity Score Filter belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907788</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="Cell Localization Agent">
      <data key="d6">10.0</data>
      <data key="d7">Entity Cell Localization Agent belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907791</data>
    </edge>
    <edge source="ChartCitor Workflow Diagram (image)" target="Bounding Box Illustrations">
      <data key="d6">10.0</data>
      <data key="d7">Entity Bounding Box Illustrations belongs to ChartCitor Workflow Diagram (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907793</data>
    </edge>
    <edge source="Chart Object Detection Performance Comparison (table)" target="DETR">
      <data key="d6">10.0</data>
      <data key="d7">Entity DETR belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907796</data>
    </edge>
    <edge source="Chart Object Detection Performance Comparison (table)" target="Claude-3.5">
      <data key="d6">10.0</data>
      <data key="d7">Entity Claude-3.5 belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907802</data>
    </edge>
    <edge source="Chart Object Detection Performance Comparison (table)" target="Intersection over Union (IoU)">
      <data key="d6">10.0</data>
      <data key="d7">Entity Intersection over Union (IoU) belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907803</data>
    </edge>
    <edge source="Chart Object Detection Performance Comparison (table)" target="Set-of-Marks Prompting">
      <data key="d6">10.0</data>
      <data key="d7">Entity Set-of-Marks Prompting belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907805</data>
    </edge>
    <edge source="Chart Object Detection Performance Comparison (table)" target="Traditional Models">
      <data key="d6">10.0</data>
      <data key="d7">Entity Traditional Models belongs to Chart Object Detection Performance Comparison (table)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907806</data>
    </edge>
    <edge source="Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)" target="Accuracy Comparison">
      <data key="d6">10.0</data>
      <data key="d7">Entity Accuracy Comparison belongs to Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907804</data>
    </edge>
    <edge source="Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)" target="Bar Chart">
      <data key="d6">10.0</data>
      <data key="d7">Entity Bar Chart belongs to Accuracy Comparison Bar Chart for ChartCitor and GPT-4o (image)</data>
      <data key="d8">belongs_to,contained_in,part_of</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">/Users/gozachary/Downloads/Data-2/RAG-Anything/example_doc/2502.00989v1.pdf</data>
      <data key="d11">1757907806</data>
    </edge>
    <edge source="Table Extraction Agent" target="HTML Table">
      <data key="d6">8.0</data>
      <data key="d7">The Table Extraction Agent processes charts into an HTML Table format, facilitating data communication in ChartCitor.</data>
      <data key="d8">data processing,format conversion</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907779</data>
    </edge>
    <edge source="LLM Prefiltering Agent" target="Score Filter">
      <data key="d6">7.0</data>
      <data key="d7">The LLM Prefiltering Agent utilizes the Score Filter to evaluate and rank data based on relevance scores.</data>
      <data key="d8">data relevance,evaluation mechanism</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907778</data>
    </edge>
    <edge source="Cell Localization Agent" target="Bounding Box Illustrations">
      <data key="d6">8.0</data>
      <data key="d7">Bounding Box Illustrations are used by the Cell Localization Agent to visually map and identify elements of charts.</data>
      <data key="d8">data mapping,visual representation</data>
      <data key="d9">chunk-edc341eaef83ca5ab02b33a17aaef5d5</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907785</data>
    </edge>
    <edge source="DETR" target="Set-of-Marks Prompting">
      <data key="d6">8.0</data>
      <data key="d7">DETR's performance is enhanced by employing Set-of-Marks Prompting, indicating a direct relationship between the method and the prompting technique.</data>
      <data key="d8">method enhancement,performance boost</data>
      <data key="d9">chunk-8db71158bc09d23d20250cfb7def0530</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907790</data>
    </edge>
    <edge source="Accuracy Comparison" target="Bar Chart">
      <data key="d6">8.0</data>
      <data key="d7">The Accuracy Comparison is represented visually through the Bar Chart, which illustrates the differences in perceived accuracy between the two systems.</data>
      <data key="d8">evaluative process,visual representation</data>
      <data key="d9">chunk-24173160be3c2d0e4ba1d7ee9d1e07cc</data>
      <data key="d10">2502.00989v1.pdf</data>
      <data key="d11">1757907800</data>
    </edge>
  </graph>
</graphml>
